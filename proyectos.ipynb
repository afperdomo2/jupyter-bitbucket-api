{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280a8149",
   "metadata": {},
   "source": [
    "# Proyectos bitbucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205ddc3",
   "metadata": {},
   "source": [
    "## 📦Obtener los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a631e",
   "metadata": {},
   "source": [
    "#### Repositorios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3bbc1",
   "metadata": {},
   "source": [
    "Consultar los repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Configura tus credenciales\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"BITBUCKET_USERNAME\")\n",
    "app_password = os.getenv(\"BITBUCKET_APP_PASSWORD\")\n",
    "workspace = os.getenv(\"BITBUCKET_WORKSPACE\")\n",
    "\n",
    "\n",
    "url_repos = f\"https://api.bitbucket.org/2.0/repositories/{workspace}\"\n",
    "\n",
    "response = requests.get(url_repos, auth=(username, app_password))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    repositorios = response.json()\n",
    "    print(f\"Repositorios en {workspace}:\")\n",
    "    repos_data = []\n",
    "    for repo in repositorios.get(\"values\", []):\n",
    "        repos_data.append(\n",
    "            {\n",
    "                \"Nombre\": repo.get(\"name\"),\n",
    "                \"URL\": repo.get(\"links\", {}).get(\"html\", {}).get(\"href\"),\n",
    "            }\n",
    "        )\n",
    "    repos_df = pd.DataFrame(repos_data)\n",
    "    repos_df = repos_df.sort_values(\n",
    "        by=\"Nombre\"\n",
    "    )  # Ordenar por nombre del repositorio en ascendente\n",
    "    # print(repos_df)\n",
    "else:\n",
    "    print(\"Error al obtener repositorios:\", response.status_code, response.text)\n",
    "\n",
    "# Almacenar los repositorios en una variable para uso posterior\n",
    "repositorios = [\n",
    "    repo[\"Nombre\"]\n",
    "    for repo in repos_data\n",
    "    if repo[\"Nombre\"] not in [\"pgp\", \"Pruebas_erp\", \"Inventario\", \"b2c\", \"efi\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f3c4e",
   "metadata": {},
   "source": [
    "Listado de repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaf0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df = pd.DataFrame(repositorios, columns=[\"Repositorio\"])\n",
    "display(repos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573fe9b",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener todos los elementos paginados\n",
    "def get_all_items(url, params=None):\n",
    "    items = []\n",
    "    response = requests.get(url, params=params, auth=(username, app_password))\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return items\n",
    "    data = response.json()\n",
    "    items.extend(data.get(\"values\", []))\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50436680",
   "metadata": {},
   "source": [
    "#### Pull requests y commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529fef7",
   "metadata": {},
   "source": [
    "Consultar todos los estados de PR's.\n",
    "\n",
    "Filtrar 50 registros por páginas, 3 páginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_paginas = 4\n",
    "registros_por_pagina = 50  # Creo que no soporta más de 50 registros por página\n",
    "\n",
    "# Obtener pull requests\n",
    "pull_requests = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests\"\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        pull_requests.extend(\n",
    "            get_all_items(\n",
    "                pr_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina, \"state\": \"ALL\"},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo pull requests, repositorio: '{repo_slug}' - página: {page}\")\n",
    "\n",
    "print(f\"✅Total de pull requests: {len(pull_requests)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f619f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener commits\n",
    "commits = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    commits_url = (\n",
    "        f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/commits\"\n",
    "    )\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        commits.extend(\n",
    "            get_all_items(\n",
    "                commits_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo commits, repositorio: '{repo_slug}' - página: {page}\")\n",
    "\n",
    "print(f\"✅Total de commits: {len(commits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be812d19",
   "metadata": {},
   "source": [
    "### ⚠️Se van a listar los pull requests de los últimos **120 días**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d64cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_dias = 120\n",
    "\n",
    "\n",
    "print(f\"\\nTotal pull requests: {len(pull_requests)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "pull_requests = [\n",
    "    pr for pr in pull_requests if pd.to_datetime(pr[\"created_on\"]) >= fecha_limite\n",
    "]\n",
    "print(f\"Registros de los últimos {cantidad_dias} días: {len(pull_requests)}\\n\")\n",
    "\n",
    "\n",
    "print(f\"\\nTotal commits: {len(commits)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "commits = [\n",
    "    commit\n",
    "    for commit in commits\n",
    "    if pd.to_datetime(commit[\"date\"]) >= fecha_limite\n",
    "    # and \"Resolve:\" in commit.get(\"message\", \"\")\n",
    "]\n",
    "print(\n",
    "    f\"Registros de los últimos {cantidad_dias} días y con 'Resolve:' en el mensaje: {len(commits)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0cab1",
   "metadata": {},
   "source": [
    "Limpiar **pull requests**:\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40846f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in pull_requests:\n",
    "    if \"author\" in pr and \"nickname\" in pr[\"author\"]:\n",
    "        pr[\"author\"] = pr[\"author\"][\"nickname\"]\n",
    "    if \"source\" in pr and \"branch\" in pr[\"source\"] and \"name\" in pr[\"source\"][\"branch\"]:\n",
    "        pr[\"branch\"] = pr[\"source\"][\"branch\"][\"name\"]\n",
    "        pr[\"type_branch\"] = (\n",
    "            pr[\"branch\"].split(\"/\")[0] if \"/\" in pr[\"branch\"] else \"unknown\"\n",
    "        )\n",
    "    if (\n",
    "        \"source\" in pr\n",
    "        and \"repository\" in pr[\"source\"]\n",
    "        and \"name\" in pr[\"source\"][\"repository\"]\n",
    "    ):\n",
    "        pr[\"repository\"] = pr[\"source\"][\"repository\"][\"name\"]\n",
    "    if pr.get(\"merge_commit\") and \"hash\" in pr[\"merge_commit\"]:\n",
    "        pr[\"merge_commit\"] = pr[\"merge_commit\"][\"hash\"]\n",
    "\n",
    "    # Calculate days_open based on the PR state\n",
    "    if \"state\" in pr and \"created_on\" in pr:\n",
    "        created_on = pd.to_datetime(pr[\"created_on\"])\n",
    "        if pr[\"state\"] == \"OPEN\":\n",
    "            # For open PRs: days between created_on and now\n",
    "            days_open = (\n",
    "                pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        elif pr[\"state\"] == \"MERGED\" and \"updated_on\" in pr:\n",
    "            # For merged PRs: days between created_on and updated_on\n",
    "            updated_on = pd.to_datetime(pr[\"updated_on\"])\n",
    "            days_open = (\n",
    "                updated_on.tz_convert(\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        else:\n",
    "            days_open = 0\n",
    "        pr[\"days_open\"] = days_open\n",
    "\n",
    "\n",
    "df_pr = pd.DataFrame(pull_requests)\n",
    "\n",
    "print(pull_requests[0])\n",
    "\n",
    "# Sort by created_on in descending order to show most recent records first\n",
    "df_pr = df_pr.sort_values(by=\"created_on\", ascending=False)\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "# df_pr = df_pr.drop(\n",
    "#     columns=[\n",
    "#         \"type\",\n",
    "#         \"title\",\n",
    "#         \"description\",\n",
    "#         \"reason\",\n",
    "#         \"destination\",\n",
    "#         \"summary\",\n",
    "#         \"closed_by\",\n",
    "#         \"links\",\n",
    "#         \"source\",\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f82a69",
   "metadata": {},
   "source": [
    "Limpiar **commits**\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e52ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm in commits:\n",
    "    # Extract author name from nested dictionary\n",
    "    if \"author\" in cm and \"user\" in cm[\"author\"] and \"nickname\" in cm[\"author\"][\"user\"]:\n",
    "        cm[\"author\"] = cm[\"author\"][\"user\"][\"nickname\"]\n",
    "    if \"repository\" in cm and \"name\" in cm[\"repository\"]:\n",
    "        cm[\"repository\"] = cm[\"repository\"][\"name\"]\n",
    "\n",
    "\n",
    "df_commits = pd.DataFrame(commits)\n",
    "\n",
    "\n",
    "# Sort by date in descending order to show most recent records first\n",
    "df_commits = df_commits.sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e0bbd",
   "metadata": {},
   "source": [
    "Imprimir **pull requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb85e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_pr))\n",
    "print(f\"Cantidad de registros: {len(df_pr)}\")\n",
    "display(df_pr.head(3))\n",
    "# display(df_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0343ec",
   "metadata": {},
   "source": [
    "Imprimir **commits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef10544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_commits))\n",
    "print(f\"Cantidad de registros: {len(df_commits)}\")\n",
    "display(df_commits.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2302",
   "metadata": {},
   "source": [
    "## 📈Reportes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c351d6",
   "metadata": {},
   "source": [
    "### 1. Actividad de commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c9094",
   "metadata": {},
   "source": [
    "#### Procesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install matplotlib if needed\n",
    "%pip install matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to import seaborn\n",
    "try:\n",
    "    import seaborn as sns\n",
    "\n",
    "    has_seaborn = True\n",
    "except ImportError:\n",
    "    has_seaborn = False\n",
    "    print(\"Seaborn no instalado. Algunas visualizaciones serán simplificadas.\")\n",
    "\n",
    "# Make sure author is a string, not a dictionary\n",
    "df_commits[\"author\"] = df_commits[\"author\"].astype(str)\n",
    "\n",
    "# Convert date to datetime\n",
    "df_commits[\"date\"] = pd.to_datetime(df_commits[\"date\"])\n",
    "\n",
    "# Extract time periods\n",
    "df_commits[\"day\"] = df_commits[\"date\"].dt.date\n",
    "df_commits[\"week\"] = df_commits[\"date\"].dt.isocalendar().week\n",
    "df_commits[\"month\"] = df_commits[\"date\"].dt.month\n",
    "df_commits[\"year\"] = df_commits[\"date\"].dt.year\n",
    "\n",
    "# Create year-month field\n",
    "df_commits[\"year_month\"] = df_commits[\"date\"].dt.strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbf813",
   "metadata": {},
   "source": [
    "#### Análisis de actividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5ccce",
   "metadata": {},
   "source": [
    "### 3. Pull Requests (PR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2bec7",
   "metadata": {},
   "source": [
    "#### 3.1 Cantidades y tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2df90e",
   "metadata": {},
   "source": [
    "##### Procesar los datos y graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da054156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# Análisis de Pull Requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar los estados disponibles en los PRs\n",
    "pr_states = df_pr[\"state\"].value_counts().reset_index()\n",
    "pr_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# Analizar PR por autor\n",
    "pr_by_author = df_pr.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"MERGED\" in pr_by_author.columns:\n",
    "    pr_by_author[\"total\"] = pr_by_author.sum(axis=1)\n",
    "    pr_by_author = pr_by_author.sort_values(\"total\", ascending=False)\n",
    "    pr_by_author = pr_by_author.drop(columns=[\"total\"])\n",
    "\n",
    "# Calcular tiempos promedio\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "df_pr[\"updated_on\"] = pd.to_datetime(df_pr[\"updated_on\"])\n",
    "\n",
    "# Métricas de tiempo para PRs cerrados/mergeados\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "if not merged_prs.empty:\n",
    "    merged_prs[\"time_to_merge_days\"] = (\n",
    "        merged_prs[\"updated_on\"] - merged_prs[\"created_on\"]\n",
    "    ).dt.total_seconds() / 86400\n",
    "    avg_merge_time = merged_prs[\"time_to_merge_days\"].mean()\n",
    "    median_merge_time = merged_prs[\"time_to_merge_days\"].median()\n",
    "    max_merge_time = merged_prs[\"time_to_merge_days\"].max()\n",
    "\n",
    "# Extraer tipos de ramas de los PRs\n",
    "branch_types = df_pr[\"type_branch\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 📈 1. Estado de los PRs\n",
    "axes[0, 0].bar(pr_states[\"Estado\"], pr_states[\"Cantidad\"], color=\"skyblue\")\n",
    "axes[0, 0].set_title(\"Estado de Pull Requests\")\n",
    "axes[0, 0].set_xlabel(\"Estado\")\n",
    "axes[0, 0].set_ylabel(\"Cantidad\")\n",
    "\n",
    "# 📈 2. PRs por autor\n",
    "pr_by_author.plot(kind=\"bar\", stacked=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Pull Requests por Autor\")\n",
    "axes[0, 1].set_xlabel(\"Autor\")\n",
    "axes[0, 1].set_ylabel(\"Cantidad\")\n",
    "axes[0, 1].legend(title=\"Estado\")\n",
    "\n",
    "\n",
    "# 📈 3. Tiempo de resolución de PRs\n",
    "if not merged_prs.empty:\n",
    "    merged_prs.boxplot(column=\"time_to_merge_days\", ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Tiempo para Merge (días)\")\n",
    "    axes[1, 0].set_ylabel(\"Días\")\n",
    "\n",
    "    # Añadir una línea para el promedio\n",
    "    axes[1, 0].axhline(\n",
    "        y=avg_merge_time,\n",
    "        color=\"red\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Promedio: {avg_merge_time:.1f} días\",\n",
    "    )\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 📈 4. Tipos de ramas\n",
    "axes[1, 1].pie(branch_types[\"Cantidad\"], labels=branch_types[\"Tipo\"], autopct=\"%1.1f%%\")\n",
    "axes[1, 1].set_title(\"Distribución de Tipos de Ramas\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Métricas adicionales\n",
    "print(\"\\n=== Métricas de Pull Requests ===\")\n",
    "print(f\"Total de PRs analizados: {len(df_pr)}\")\n",
    "print(f\"PRs por estado: {dict(pr_states.values)}\")\n",
    "if not merged_prs.empty:\n",
    "    print(f\"\\nTiempo promedio hasta merge: {avg_merge_time:.1f} días\")\n",
    "    print(f\"Tiempo mediano hasta merge: {median_merge_time:.1f} días\")\n",
    "    print(f\"Tiempo máximo hasta merge: {max_merge_time:.1f} días\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 📊 Análisis de eficiencia de PRs\n",
    "if not merged_prs.empty:\n",
    "    author_efficiency = (\n",
    "        merged_prs.groupby(\"author\")[\"time_to_merge_days\"]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    author_efficiency.columns = [\"Tiempo promedio (días)\", \"PRs mergeados\"]\n",
    "\n",
    "    # Crear tres gráficas para visualizar la eficiencia de los autores\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # 📈 Gráfica 1: Tiempo promedio hasta merge\n",
    "    author_efficiency[\"Tiempo promedio (días)\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"skyblue\",\n",
    "        ax=ax1,\n",
    "        title=\"Tiempo promedio hasta merge por autor\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"Autor\")\n",
    "    ax1.set_ylabel(\"Días\")\n",
    "    for i, v in enumerate(author_efficiency[\"Tiempo promedio (días)\"]):\n",
    "        ax1.text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 📈 Gráfica 2: Cantidad de PRs mergeados\n",
    "    author_efficiency[\"PRs mergeados\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"lightgreen\",\n",
    "        ax=ax2,\n",
    "        title=\"Cantidad de PRs mergeados por autor\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"Autor\")\n",
    "    ax2.set_ylabel(\"Cantidad\")\n",
    "    for i, v in enumerate(author_efficiency[\"PRs mergeados\"]):\n",
    "        ax2.text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "    # 📈 Gráfica 3: Eficiencia general de los autores\n",
    "    scatter = ax3.scatter(\n",
    "        author_efficiency[\"Tiempo promedio (días)\"],\n",
    "        author_efficiency[\"PRs mergeados\"],\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        c=author_efficiency[\"Tiempo promedio (días)\"],\n",
    "        cmap=\"coolwarm_r\",\n",
    "    )\n",
    "\n",
    "    # Añadir etiquetas a cada punto\n",
    "    for i, author in enumerate(author_efficiency.index):\n",
    "        ax3.annotate(\n",
    "            author,\n",
    "            (\n",
    "                author_efficiency[\"Tiempo promedio (días)\"][i],\n",
    "                author_efficiency[\"PRs mergeados\"][i],\n",
    "            ),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    ax3.set_title(\"Eficiencia de autores\")\n",
    "    ax3.set_xlabel(\"Tiempo promedio (días)\")\n",
    "    ax3.set_ylabel(\"PRs mergeados\")\n",
    "    ax3.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Añadir colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label(\"Tiempo promedio (días)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n=== Eficiencia de autores (tiempo promedio hasta merge) ===\")\n",
    "    print(author_efficiency.to_string(float_format=lambda x: f\"{x:.1f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e885a0",
   "metadata": {},
   "source": [
    "#### 3.2 Comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff35cd",
   "metadata": {},
   "source": [
    "##### PRs más largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar PRs con tiempos de revisión largos y comentarios numerosos\n",
    "if \"comment_count\" in df_pr.columns:\n",
    "    high_discussion = df_pr.sort_values(\"comment_count\", ascending=False).head(5)\n",
    "    print(\"\\n=== PRs con más discusión (mayor número de comentarios) ===\")\n",
    "    high_discussion[\"formatted_date\"] = high_discussion[\"created_on\"].dt.strftime(\n",
    "        \"%d-%m-%Y\"\n",
    "    )\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Título\": high_discussion[\"title\"],\n",
    "                \"Autor\": high_discussion[\"author\"],\n",
    "                \"Comentarios\": high_discussion[\"comment_count\"],\n",
    "                \"Estado\": high_discussion[\"state\"],\n",
    "                \"Fecha\": high_discussion[\"formatted_date\"],\n",
    "            }\n",
    "        ).to_string()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb76a",
   "metadata": {},
   "source": [
    "##### Procesar los datos (primeras 3 gráficas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parámetro configurable: número de días a analizar\n",
    "num_days_to_analyze = 30\n",
    "# Calcular fecha límite\n",
    "today = pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "date_limit = today - pd.Timedelta(days=num_days_to_analyze)\n",
    "\n",
    "# Asegurar que la columna de fecha está en el formato correcto\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "\n",
    "# Filtrar PRs por fecha\n",
    "recent_prs = df_pr[df_pr[\"created_on\"] >= date_limit]\n",
    "\n",
    "# Crear una lista de todas las fechas en el rango analizado\n",
    "date_range = pd.date_range(start=date_limit, end=today, freq=\"D\")\n",
    "date_range = [d.date() for d in date_range]\n",
    "\n",
    "# Contar PRs por día\n",
    "prs_by_day = recent_prs.groupby(recent_prs[\"created_on\"].dt.date).size()\n",
    "\n",
    "# Asegurar que tenemos todas las fechas (incluso las que no tienen PRs)\n",
    "prs_by_day = prs_by_day.reindex(date_range, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e6b5c",
   "metadata": {},
   "source": [
    "##### Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37582fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# 📈 3. Gráfico comparativo entre desarrolladores\n",
    "dev_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Desarrollador\": developers,\n",
    "        \"Total PRs\": [\n",
    "            len(recent_prs[recent_prs[\"author\"] == dev]) for dev in developers\n",
    "        ],\n",
    "    }\n",
    ").sort_values(\"Total PRs\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    dev_comparison[\"Desarrollador\"], dev_comparison[\"Total PRs\"], color=\"teal\"\n",
    ")\n",
    "\n",
    "# Añadir etiquetas de valor sobre cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Comparación de PRs creados por desarrollador (últimos {num_days_to_analyze} días)\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a764a",
   "metadata": {},
   "source": [
    "### Actividad en Ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3607b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# Análisis de Actividad en Ramas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraer información de ramas de los PRs\n",
    "branches_info = []\n",
    "\n",
    "# Obtener información de las ramas desde los PR\n",
    "for pr in df_pr.to_dict(\"records\"):\n",
    "    # Solo procesamos si tenemos información de rama\n",
    "    if \"branch\" in pr and \"type_branch\" in pr:\n",
    "        # Extraer tipo de rama (feature, bugfix, etc)\n",
    "        branch_type = pr[\"type_branch\"]\n",
    "        # Nombre de la rama\n",
    "        branch_name = pr[\"branch\"]\n",
    "        # Repositorio\n",
    "        repo = pr[\"repository\"]\n",
    "        # Fecha de creación (estimada desde la PR)\n",
    "        created_date = pr[\"created_on\"]\n",
    "        # Fecha de cierre (si está cerrada)\n",
    "        closed_date = pr[\"updated_on\"] if pr[\"state\"] != \"OPEN\" else None\n",
    "        # Estado actual\n",
    "        state = pr[\"state\"]\n",
    "        # Autor de la rama (asumimos que es el mismo que el de la PR)\n",
    "        author = pr[\"author\"]\n",
    "\n",
    "        # Agregar a la lista\n",
    "        branches_info.append(\n",
    "            {\n",
    "                \"branch_name\": branch_name,\n",
    "                \"branch_type\": branch_type,\n",
    "                \"repository\": repo,\n",
    "                \"author\": author,\n",
    "                \"created_date\": created_date,\n",
    "                \"closed_date\": closed_date,\n",
    "                \"state\": state,\n",
    "                \"days_active\": (pd.Timestamp.now(tz=\"UTC\") - created_date).days\n",
    "                if state == \"OPEN\"\n",
    "                else (closed_date - created_date).days\n",
    "                if closed_date\n",
    "                else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Crear DataFrame con la información de ramas\n",
    "df_branches = pd.DataFrame(branches_info)\n",
    "\n",
    "# 1. Análisis general de ramas\n",
    "branch_states = df_branches[\"state\"].value_counts().reset_index()\n",
    "branch_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# 2. Análisis por tipo de rama\n",
    "branch_types = df_branches[\"branch_type\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author = df_branches.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"OPEN\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"OPEN\"] = 0\n",
    "if \"MERGED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"MERGED\"] = 0\n",
    "if \"DECLINED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"DECLINED\"] = 0\n",
    "\n",
    "# 4. Tiempo activo de las ramas\n",
    "branch_lifetime = (\n",
    "    df_branches.dropna(subset=[\"days_active\"])\n",
    "    .groupby([\"branch_type\", \"state\"])[\"days_active\"]\n",
    "    .agg([\"mean\", \"median\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5. Ramas abiertas vs cerradas por repositorio\n",
    "branches_by_repo = (\n",
    "    df_branches.groupby([\"repository\", \"state\"]).size().unstack().fillna(0)\n",
    ")\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Estado de las ramas\n",
    "sns.barplot(\n",
    "    x=\"Estado\", y=\"Cantidad\", data=branch_states, ax=axes[0, 0], palette=\"viridis\"\n",
    ")\n",
    "axes[0, 0].set_title(\"Estado de las Ramas\", fontsize=14)\n",
    "for i, v in enumerate(branch_states[\"Cantidad\"]):\n",
    "    axes[0, 0].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 2. Tipos de ramas\n",
    "sns.barplot(x=\"Tipo\", y=\"Cantidad\", data=branch_types, ax=axes[0, 1], palette=\"muted\")\n",
    "axes[0, 1].set_title(\"Distribución por Tipo de Rama\", fontsize=14)\n",
    "for i, v in enumerate(branch_types[\"Cantidad\"]):\n",
    "    axes[0, 1].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author.plot(kind=\"bar\", stacked=True, ax=axes[1, 0], colormap=\"tab10\")\n",
    "axes[1, 0].set_title(\"Ramas por Autor y Estado\", fontsize=14)\n",
    "axes[1, 0].set_xlabel(\"Autor\")\n",
    "axes[1, 0].set_ylabel(\"Número de Ramas\")\n",
    "axes[1, 0].legend(title=\"Estado\")\n",
    "\n",
    "# 4. Tiempo promedio de las ramas abiertas\n",
    "open_branches = df_branches[df_branches[\"state\"] == \"OPEN\"]\n",
    "if not open_branches.empty:\n",
    "    sns.boxplot(x=\"branch_type\", y=\"days_active\", data=open_branches, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Tiempo de Ramas Abiertas por Tipo\", fontsize=14)\n",
    "    axes[1, 1].set_xlabel(\"Tipo de Rama\")\n",
    "    axes[1, 1].set_ylabel(\"Días Activa\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Gráfico adicional: Evolución de ramas a lo largo del tiempo\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Crear fechas para el período analizado\n",
    "start_date = df_branches[\"created_date\"].min().date()\n",
    "end_date = pd.Timestamp.now(tz=\"UTC\").date()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "# Contar ramas creadas por día\n",
    "df_branches[\"created_day\"] = df_branches[\"created_date\"].dt.date\n",
    "\n",
    "\n",
    "# Imprimir estadísticas\n",
    "print(\"\\n===== ANÁLISIS DE ACTIVIDAD EN RAMAS =====\")\n",
    "print(f\"Total de ramas analizadas: {len(df_branches)}\")\n",
    "print(f\"Ramas por estado: {dict(branch_states.values)}\")\n",
    "print(f\"Ramas por tipo: {dict(branch_types.values)}\")\n",
    "print(\"\\nRamas abiertas por tiempo:\")\n",
    "if not open_branches.empty:\n",
    "    open_by_time = (\n",
    "        open_branches.groupby(\"branch_type\")[\"days_active\"]\n",
    "        .agg([\"count\", \"mean\", \"median\", \"max\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in open_by_time.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_type']}: {row['count']} ramas, promedio {row['mean']:.1f} días, máximo {row['max']} días\"\n",
    "        )\n",
    "\n",
    "# Detectar ramas potencialmente abandonadas (abiertas por más de 30 días)\n",
    "abandoned = open_branches[open_branches[\"days_active\"] > 30].sort_values(\n",
    "    \"days_active\", ascending=False\n",
    ")\n",
    "if not abandoned.empty:\n",
    "    print(\"\\nRamas potencialmente abandonadas (>30 días abiertas):\")\n",
    "    for _, row in abandoned.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_name']} ({row['repository']}): {row['days_active']} días, autor: {row['author']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\nNo hay ramas potencialmente abandonadas.\")\n",
    "\n",
    "# Analizar patrones de creación de ramas por autor\n",
    "author_patterns = (\n",
    "    df_branches.groupby(\"author\")[\"branch_type\"].value_counts().unstack().fillna(0)\n",
    ")\n",
    "print(\"\\nPatrones de creación de ramas por autor:\")\n",
    "print(author_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e785e2",
   "metadata": {},
   "source": [
    "### Frecuencia de Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurar que las fechas están en formato datetime\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "\n",
    "# Agrupar por mes/semana y estado\n",
    "# Decidir si agrupar por semana o mes según la cantidad de datos\n",
    "date_range = (df_pr[\"created_on\"].max() - df_pr[\"created_on\"].min()).days\n",
    "\n",
    "# Si el rango de datos es mayor a 90 días, agrupar por mes, de lo contrario por semana\n",
    "if date_range > 90:\n",
    "    # Agrupar por mes\n",
    "    df_pr[\"period\"] = df_pr[\"created_on\"].dt.strftime(\"%Y-%m\")\n",
    "    period_name = \"Mes\"\n",
    "else:\n",
    "    # Agrupar por semana\n",
    "    df_pr[\"period\"] = df_pr[\"created_on\"].dt.strftime(\"%Y-%U\")\n",
    "    period_name = \"Semana\"\n",
    "\n",
    "# Contar PRs por período y estado\n",
    "pr_counts = df_pr.groupby([\"period\", \"state\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Asegurar que tenemos todas las posibles columnas de estado\n",
    "all_states = [\"OPEN\", \"MERGED\", \"DECLINED\"]\n",
    "for state in all_states:\n",
    "    if state not in pr_counts.columns:\n",
    "        pr_counts[state] = 0\n",
    "\n",
    "# Ordenar por período (implícitamente por fecha)\n",
    "pr_counts = pr_counts.sort_index()\n",
    "\n",
    "# Calcular el tiempo promedio hasta el cierre por período\n",
    "merged_pr = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "if not merged_pr.empty:\n",
    "    merged_pr[\"period\"] = merged_pr[\"created_on\"].dt.strftime(\n",
    "        \"%Y-%m\" if date_range > 90 else \"%Y-%U\"\n",
    "    )\n",
    "    avg_time_to_merge = merged_pr.groupby(\"period\")[\"days_open\"].mean()\n",
    "\n",
    "# Crear el gráfico\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Paleta de colores para los estados\n",
    "colors = {\"OPEN\": \"#5DA5DA\", \"MERGED\": \"#60BD68\", \"DECLINED\": \"#F15854\"}\n",
    "\n",
    "# Crear el gráfico de barras apiladas\n",
    "pr_counts[all_states].plot(\n",
    "    kind=\"bar\", stacked=True, ax=ax1, color=[colors[s] for s in all_states], width=0.7\n",
    ")\n",
    "\n",
    "# Configurar el eje primario (barras)\n",
    "ax1.set_xlabel(f\"{period_name}\", fontsize=12)\n",
    "ax1.set_ylabel(\"Cantidad de Pull Requests\", fontsize=12)\n",
    "ax1.set_title(f\"Estado de Pull Requests por {period_name}\", fontsize=16, pad=20)\n",
    "ax1.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Rotar etiquetas del eje x para mejor visualización\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Añadir leyenda para las barras\n",
    "bars_legend = [plt.Rectangle((0, 0), 1, 1, color=colors[state]) for state in all_states]\n",
    "ax1.legend(\n",
    "    bars_legend, [\"Abierto\", \"Fusionado\", \"Rechazado\"], loc=\"upper left\", title=\"Estado\"\n",
    ")\n",
    "\n",
    "# Añadir un segundo eje para el tiempo promedio hasta merge\n",
    "if not merged_pr.empty:\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(\n",
    "        range(len(pr_counts)),\n",
    "        avg_time_to_merge.reindex(pr_counts.index).fillna(0),\n",
    "        marker=\"o\",\n",
    "        color=\"#F17CB0\",\n",
    "        linewidth=2,\n",
    "        label=\"Tiempo hasta merge\",\n",
    "    )\n",
    "    ax2.set_ylabel(\"Días promedio hasta merge\", fontsize=12, color=\"#F17CB0\")\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=\"#F17CB0\")\n",
    "    ax2.grid(False)\n",
    "\n",
    "    # Añadir leyenda para la línea\n",
    "    line_legend = plt.Line2D([0], [0], color=\"#F17CB0\", linewidth=2, marker=\"o\")\n",
    "    ax2.legend([line_legend], [\"Tiempo promedio hasta merge\"], loc=\"upper right\")\n",
    "\n",
    "# Ajustar para que solo muestre enteros en el eje y\n",
    "ax1.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "# Añadir valores sobre las barras para total por período\n",
    "for i, total in enumerate(pr_counts.sum(axis=1)):\n",
    "    ax1.text(i, total + 0.3, str(int(total)), ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "# Añadir un cuadro de texto con guía de interpretación\n",
    "plt.figtext(\n",
    "    0.5,\n",
    "    -0.05,\n",
    "    \"CÓMO INTERPRETAR ESTE GRÁFICO:\\n\"\n",
    "    \"• Las barras apiladas muestran la cantidad de PRs en cada estado por período\\n\"\n",
    "    \"• La línea rosa muestra el tiempo promedio de revisión hasta el merge\\n\"\n",
    "    \"• Un incremento en la proporción de PRs abiertos puede indicar retrasos en las revisiones\\n\"\n",
    "    \"• Un aumento en los PRs rechazados podría señalar problemas de calidad de código\\n\"\n",
    "    \"• El tiempo promedio de revisión es un indicador clave de eficiencia del equipo\",\n",
    "    ha=\"center\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(facecolor=\"lightyellow\", alpha=0.5, boxstyle=\"round,pad=0.5\"),\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.08, 1, 0.95])\n",
    "\n",
    "# Calcular algunas métricas para mostrar en el título\n",
    "total_prs = len(df_pr)\n",
    "merged_pct = (df_pr[\"state\"] == \"MERGED\").mean() * 100\n",
    "open_pct = (df_pr[\"state\"] == \"OPEN\").mean() * 100\n",
    "avg_time_to_merge_total = merged_pr[\"days_open\"].mean() if not merged_pr.empty else 0\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Resumen: {total_prs} PRs totales | {merged_pct:.1f}% fusionados | {open_pct:.1f}% abiertos | \"\n",
    "    f\"Tiempo promedio hasta merge: {avg_time_to_merge_total:.1f} días\",\n",
    "    fontsize=12,\n",
    "    y=0.98,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Realizar análisis de los PRs con revisiones más lentas\n",
    "print(\"\\n===== ANÁLISIS DE PRs CON REVISIONES LENTAS =====\")\n",
    "print(f\"Se encontraron {len(slow_reviews)} PRs con tiempo de revisión mayor a 7 días\")\n",
    "\n",
    "# Calcular estadísticas por autor\n",
    "author_counts = slow_reviews[\"author\"].value_counts()\n",
    "print(\"\\nDistribución por autor:\")\n",
    "for author, count in author_counts.items():\n",
    "    percentage = count / len(slow_reviews) * 100\n",
    "    print(f\"- {author}: {count} PRs lentos ({percentage:.1f}% del total)\")\n",
    "\n",
    "# Calcular estadísticas por repositorio\n",
    "repo_counts = slow_reviews[\"repository\"].value_counts()\n",
    "print(\"\\nDistribución por repositorio:\")\n",
    "for repo, count in repo_counts.items():\n",
    "    percentage = count / len(slow_reviews) * 100\n",
    "    print(f\"- {repo}: {count} PRs lentos ({percentage:.1f}% del total)\")\n",
    "\n",
    "# Calcular estadísticas por tipo de rama\n",
    "branch_counts = slow_reviews[\"type_branch\"].value_counts()\n",
    "print(\"\\nDistribución por tipo de rama:\")\n",
    "for branch_type, count in branch_counts.items():\n",
    "    percentage = count / len(slow_reviews) * 100\n",
    "    print(f\"- {branch_type}: {count} PRs lentos ({percentage:.1f}% del total)\")\n",
    "\n",
    "# Estadísticas de tiempo\n",
    "avg_time = slow_reviews[\"time_to_close_days\"].mean()\n",
    "max_time = slow_reviews[\"time_to_close_days\"].max()\n",
    "min_time = slow_reviews[\"time_to_close_days\"].min()\n",
    "\n",
    "print(f\"\\nTiempo promedio de revisión: {avg_time:.1f} días\")\n",
    "print(f\"Tiempo máximo de revisión: {max_time:.1f} días\")\n",
    "print(f\"Tiempo mínimo de revisión: {min_time:.1f} días\")\n",
    "\n",
    "# Conclusiones\n",
    "print(\"\\n===== CONCLUSIONES Y RECOMENDACIONES =====\")\n",
    "print(\n",
    "    \"1. Los PRs lentos representan un punto de fricción importante en el proceso de desarrollo\"\n",
    ")\n",
    "print(\n",
    "    f\"2. El repositorio {repo_counts.index[0]} tiene la mayor cantidad de PRs lentos ({repo_counts.iloc[0]} PRs)\"\n",
    ")\n",
    "print(\n",
    "    f\"3. {author_counts.index[0]} es el autor con más PRs que han tenido revisiones largas\"\n",
    ")\n",
    "print(\"4. Factores posibles que contribuyen a revisiones lentas:\")\n",
    "print(\"   - Complejidad del código (PRs grandes)\")\n",
    "print(\"   - Falta de revisores disponibles\")\n",
    "print(\"   - Dependencias con otros PRs o tareas\")\n",
    "print(\"   - Prioridades cambiantes en el equipo\")\n",
    "print(\"\\nRecomendaciones para mejorar:\")\n",
    "print(\"1. Establecer SLAs para revisión de código (por ejemplo, máximo 3 días)\")\n",
    "print(\"2. Implementar revisiones por pares rotativas\")\n",
    "print(\"3. Dividir PRs grandes en cambios más pequeños y manejables\")\n",
    "print(\"4. Realizar sesiones de revisión de código programadas\")\n",
    "print(\"5. Monitorear y analizar tendencias de tiempo de revisión\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
