{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280a8149",
   "metadata": {},
   "source": [
    "# Proyectos bitbucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205ddc3",
   "metadata": {},
   "source": [
    "## 游닍Obtener los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a631e",
   "metadata": {},
   "source": [
    "#### Repositorios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3bbc1",
   "metadata": {},
   "source": [
    "Consultar los repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Configura tus credenciales\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"BITBUCKET_USERNAME\")\n",
    "app_password = os.getenv(\"BITBUCKET_APP_PASSWORD\")\n",
    "workspace = os.getenv(\"BITBUCKET_WORKSPACE\")\n",
    "\n",
    "\n",
    "url_repos = f\"https://api.bitbucket.org/2.0/repositories/{workspace}\"\n",
    "\n",
    "response = requests.get(url_repos, auth=(username, app_password))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    repositorios = response.json()\n",
    "    print(f\"Repositorios en {workspace}:\")\n",
    "    repos_data = []\n",
    "    for repo in repositorios.get(\"values\", []):\n",
    "        repos_data.append(\n",
    "            {\n",
    "                \"Nombre\": repo.get(\"name\"),\n",
    "                \"URL\": repo.get(\"links\", {}).get(\"html\", {}).get(\"href\"),\n",
    "            }\n",
    "        )\n",
    "    repos_df = pd.DataFrame(repos_data)\n",
    "    repos_df = repos_df.sort_values(\n",
    "        by=\"Nombre\"\n",
    "    )  # Ordenar por nombre del repositorio en ascendente\n",
    "    # print(repos_df)\n",
    "else:\n",
    "    print(\"Error al obtener repositorios:\", response.status_code, response.text)\n",
    "\n",
    "# Almacenar los repositorios en una variable para uso posterior\n",
    "repositorios = [\n",
    "    repo[\"Nombre\"]\n",
    "    for repo in repos_data\n",
    "    if repo[\"Nombre\"] not in [\"pgp\", \"Pruebas_erp\", \"Inventario\", \"b2c\", \"efi\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f3c4e",
   "metadata": {},
   "source": [
    "Listado de repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaf0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df = pd.DataFrame(repositorios, columns=[\"Repositorio\"])\n",
    "display(repos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573fe9b",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci칩n para obtener todos los elementos paginados\n",
    "def get_all_items(url, params=None):\n",
    "    items = []\n",
    "    response = requests.get(url, params=params, auth=(username, app_password))\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return items\n",
    "    data = response.json()\n",
    "    items.extend(data.get(\"values\", []))\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50436680",
   "metadata": {},
   "source": [
    "#### Pull requests y commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529fef7",
   "metadata": {},
   "source": [
    "Consultar todos los estados de PR's.\n",
    "\n",
    "Filtrar 50 registros por p치ginas, 3 p치ginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_paginas = 4\n",
    "registros_por_pagina = 50  # Creo que no soporta m치s de 50 registros por p치gina\n",
    "\n",
    "# Obtener pull requests\n",
    "pull_requests = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests\"\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        pull_requests.extend(\n",
    "            get_all_items(\n",
    "                pr_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina, \"state\": \"ALL\"},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo pull requests, repositorio: '{repo_slug}' - p치gina: {page}\")\n",
    "\n",
    "print(f\"九Total de pull requests: {len(pull_requests)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f619f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener commits\n",
    "commits = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    commits_url = (\n",
    "        f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/commits\"\n",
    "    )\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        commits.extend(\n",
    "            get_all_items(\n",
    "                commits_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo commits, repositorio: '{repo_slug}' - p치gina: {page}\")\n",
    "\n",
    "print(f\"九Total de commits: {len(commits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6718731",
   "metadata": {},
   "source": [
    "Filtrar registros de m치s de 120 d칤as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d64cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_dias = 120\n",
    "\n",
    "\n",
    "print(f\"\\nTotal pull requests: {len(pull_requests)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "pull_requests = [\n",
    "    pr for pr in pull_requests if pd.to_datetime(pr[\"created_on\"]) >= fecha_limite\n",
    "]\n",
    "print(f\"Registros de los 칰ltimos {cantidad_dias} d칤as: {len(pull_requests)}\\n\")\n",
    "\n",
    "\n",
    "print(f\"\\nTotal commits: {len(commits)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "commits = [\n",
    "    commit\n",
    "    for commit in commits\n",
    "    if pd.to_datetime(commit[\"date\"]) >= fecha_limite\n",
    "    # and \"Resolve:\" in commit.get(\"message\", \"\")\n",
    "]\n",
    "print(\n",
    "    f\"Registros de los 칰ltimos {cantidad_dias} d칤as y con 'Resolve:' en el mensaje: {len(commits)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0cab1",
   "metadata": {},
   "source": [
    "Limpiar **pull requests**:\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40846f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in pull_requests:\n",
    "    if \"author\" in pr and \"nickname\" in pr[\"author\"]:\n",
    "        pr[\"author\"] = pr[\"author\"][\"nickname\"]\n",
    "    if \"source\" in pr and \"branch\" in pr[\"source\"] and \"name\" in pr[\"source\"][\"branch\"]:\n",
    "        pr[\"branch\"] = pr[\"source\"][\"branch\"][\"name\"]\n",
    "        pr[\"type_branch\"] = (\n",
    "            pr[\"branch\"].split(\"/\")[0] if \"/\" in pr[\"branch\"] else \"unknown\"\n",
    "        )\n",
    "    if (\n",
    "        \"source\" in pr\n",
    "        and \"repository\" in pr[\"source\"]\n",
    "        and \"name\" in pr[\"source\"][\"repository\"]\n",
    "    ):\n",
    "        pr[\"repository\"] = pr[\"source\"][\"repository\"][\"name\"]\n",
    "    if pr.get(\"merge_commit\") and \"hash\" in pr[\"merge_commit\"]:\n",
    "        pr[\"merge_commit\"] = pr[\"merge_commit\"][\"hash\"]\n",
    "\n",
    "    # Calculate days_open based on the PR state\n",
    "    if \"state\" in pr and \"created_on\" in pr:\n",
    "        created_on = pd.to_datetime(pr[\"created_on\"])\n",
    "        if pr[\"state\"] == \"OPEN\":\n",
    "            # For open PRs: days between created_on and now\n",
    "            days_open = (\n",
    "                pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        elif pr[\"state\"] == \"MERGED\" and \"updated_on\" in pr:\n",
    "            # For merged PRs: days between created_on and updated_on\n",
    "            updated_on = pd.to_datetime(pr[\"updated_on\"])\n",
    "            days_open = (\n",
    "                updated_on.tz_convert(\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        else:\n",
    "            days_open = 0\n",
    "        pr[\"days_open\"] = days_open\n",
    "\n",
    "\n",
    "df_pr = pd.DataFrame(pull_requests)\n",
    "\n",
    "print(pull_requests[0])\n",
    "\n",
    "# Sort by created_on in descending order to show most recent records first\n",
    "df_pr = df_pr.sort_values(by=\"created_on\", ascending=False)\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "# df_pr = df_pr.drop(\n",
    "#     columns=[\n",
    "#         \"type\",\n",
    "#         \"title\",\n",
    "#         \"description\",\n",
    "#         \"reason\",\n",
    "#         \"destination\",\n",
    "#         \"summary\",\n",
    "#         \"closed_by\",\n",
    "#         \"links\",\n",
    "#         \"source\",\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f82a69",
   "metadata": {},
   "source": [
    "Limpiar **commits**\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e52ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm in commits:\n",
    "    # Extract author name from nested dictionary\n",
    "    if \"author\" in cm and \"user\" in cm[\"author\"] and \"nickname\" in cm[\"author\"][\"user\"]:\n",
    "        cm[\"author\"] = cm[\"author\"][\"user\"][\"nickname\"]\n",
    "    if \"repository\" in cm and \"name\" in cm[\"repository\"]:\n",
    "        cm[\"repository\"] = cm[\"repository\"][\"name\"]\n",
    "\n",
    "\n",
    "df_commits = pd.DataFrame(commits)\n",
    "\n",
    "\n",
    "# Sort by date in descending order to show most recent records first\n",
    "df_commits = df_commits.sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e0bbd",
   "metadata": {},
   "source": [
    "Imprimir **pull requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb85e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_pr))\n",
    "print(f\"Cantidad de registros: {len(df_pr)}\")\n",
    "display(df_pr.head(3))\n",
    "# display(df_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0343ec",
   "metadata": {},
   "source": [
    "Imprimir **commits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef10544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_commits))\n",
    "print(f\"Cantidad de registros: {len(df_commits)}\")\n",
    "display(df_commits.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2302",
   "metadata": {},
   "source": [
    "## 游늳Reportes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c351d6",
   "metadata": {},
   "source": [
    "### 1. Actividad de commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c9094",
   "metadata": {},
   "source": [
    "#### Procesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar matplotlib si es necesario\n",
    "%pip install matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Intentar importar seaborn\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    has_seaborn = True\n",
    "except ImportError:\n",
    "    has_seaborn = False\n",
    "    print(\"Seaborn no instalado. Algunas visualizaciones ser치n simplificadas.\")\n",
    "\n",
    "# Asegurar que author es una cadena, no un diccionario\n",
    "df_commits[\"author\"] = df_commits[\"author\"].astype(str)\n",
    "\n",
    "# Convertir fecha a datetime\n",
    "df_commits[\"date\"] = pd.to_datetime(df_commits[\"date\"])\n",
    "\n",
    "# Extraer per칤odos de tiempo\n",
    "df_commits[\"day\"] = df_commits[\"date\"].dt.date\n",
    "df_commits[\"week\"] = df_commits[\"date\"].dt.isocalendar().week\n",
    "df_commits[\"month\"] = df_commits[\"date\"].dt.month\n",
    "df_commits[\"year\"] = df_commits[\"date\"].dt.year\n",
    "\n",
    "# Crear campo a침o-mes\n",
    "df_commits[\"year_month\"] = df_commits[\"date\"].dt.strftime(\"%Y-%m\")\n",
    "\n",
    "# 1. Commits diarios por autor\n",
    "daily_commits = df_commits.groupby([\"author\", \"day\"]).size().reset_index(name=\"commits\")\n",
    "daily_avg = (\n",
    "    daily_commits.groupby(\"author\")[\"commits\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "daily_avg.columns = [\"author\", \"avg_daily_commits\"]\n",
    "\n",
    "# 2. Commits semanales por autor\n",
    "weekly_commits = (\n",
    "    df_commits.groupby([\"author\", \"year\", \"week\"]).size().reset_index(name=\"commits\")\n",
    ")\n",
    "weekly_avg = (\n",
    "    weekly_commits.groupby(\"author\")[\"commits\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "weekly_avg.columns = [\"author\", \"avg_weekly_commits\"]\n",
    "\n",
    "# 3. Commits mensuales por autor\n",
    "monthly_commits = (\n",
    "    df_commits.groupby([\"author\", \"year_month\"]).size().reset_index(name=\"commits\")\n",
    ")\n",
    "monthly_avg = (\n",
    "    monthly_commits.groupby(\"author\")[\"commits\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index()\n",
    ")\n",
    "monthly_avg.columns = [\"author\", \"avg_monthly_commits\"]\n",
    "\n",
    "# 4. Total de commits por autor\n",
    "total_commits = df_commits.groupby(\"author\").size().reset_index(name=\"total_commits\")\n",
    "total_commits = total_commits.sort_values(\"total_commits\", ascending=False)\n",
    "\n",
    "# 5. Commits por repositorio para cada autor\n",
    "repo_commits = (\n",
    "    df_commits.groupby([\"author\", \"repository\"]).size().reset_index(name=\"commits\")\n",
    ")\n",
    "repo_commits = (\n",
    "    repo_commits.pivot(index=\"author\", columns=\"repository\", values=\"commits\")\n",
    "    .fillna(0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Combinar toda la informaci칩n\n",
    "commit_stats = pd.merge(total_commits, daily_avg, on=\"author\")\n",
    "commit_stats = pd.merge(commit_stats, weekly_avg, on=\"author\")\n",
    "commit_stats = pd.merge(commit_stats, monthly_avg, on=\"author\")\n",
    "\n",
    "# Calcular porcentaje del total de commits\n",
    "commit_stats[\"percentage\"] = (\n",
    "    commit_stats[\"total_commits\"] / commit_stats[\"total_commits\"].sum() * 100\n",
    ").round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbf813",
   "metadata": {},
   "source": [
    "#### An치lisis de actividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ccb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las estad칤sticas resumidas\n",
    "print(\"An치lisis de Actividad de Commits\")\n",
    "print(\"=======================\")\n",
    "display(commit_stats)\n",
    "\n",
    "# 1. Distribuci칩n de commits por autor (tres gr치ficas circulares para los 칰ltimos tres meses)\n",
    "recent_date = df_commits[\"date\"].max()\n",
    "three_months_ago = recent_date - pd.DateOffset(months=3)\n",
    "\n",
    "# Dividir el dataframe por meses\n",
    "df_month1 = df_commits[\n",
    "    (df_commits[\"date\"] >= three_months_ago)\n",
    "    & (df_commits[\"date\"] < three_months_ago + pd.DateOffset(months=1))\n",
    "]\n",
    "df_month2 = df_commits[\n",
    "    (df_commits[\"date\"] >= three_months_ago + pd.DateOffset(months=1))\n",
    "    & (df_commits[\"date\"] < three_months_ago + pd.DateOffset(months=2))\n",
    "]\n",
    "df_month3 = df_commits[\n",
    "    (df_commits[\"date\"] >= three_months_ago + pd.DateOffset(months=2))\n",
    "]\n",
    "\n",
    "\n",
    "# Funci칩n para generar estad칤sticas mensuales y graficar\n",
    "def plot_monthly_pie(df_month, month_offset):\n",
    "    month_date = recent_date - pd.DateOffset(months=month_offset - 1)\n",
    "    month_name = month_date.strftime(\"%B %Y\")\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    if len(df_month) == 0:\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            f\"No hay commits\\nen {month_name}\",\n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            fontsize=12,\n",
    "        )\n",
    "        plt.axis(\"off\")\n",
    "    else:\n",
    "        # Calcular commits por autor\n",
    "        author_commits = (\n",
    "            df_month.groupby(\"author\").size().reset_index(name=\"total_commits\")\n",
    "        )\n",
    "\n",
    "        # Ordenar de mayor a menor\n",
    "        author_commits = author_commits.sort_values(\"total_commits\", ascending=False)\n",
    "\n",
    "        # Graficar pie chart\n",
    "        plt.pie(\n",
    "            author_commits[\"total_commits\"],\n",
    "            labels=author_commits[\"author\"],\n",
    "            autopct=\"%1.1f%%\",\n",
    "        )\n",
    "        plt.title(f\"Distribuci칩n de Commits - {month_name}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Graficar cada mes individualmente\n",
    "plot_monthly_pie(df_month3, 1)\n",
    "plot_monthly_pie(df_month2, 2)\n",
    "plot_monthly_pie(df_month1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e28cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Commits por autor y repositorio\n",
    "plt.figure(figsize=(10, 6))\n",
    "repo_commits_plot = (\n",
    "    df_commits.groupby([\"author\", \"repository\"]).size().unstack().fillna(0)\n",
    ")\n",
    "repo_commits_plot.plot(kind=\"bar\", stacked=True)\n",
    "plt.title(\"Commits por Autor y Repositorio\")\n",
    "plt.xlabel(\"Autor\")\n",
    "plt.ylabel(\"N칰mero de Commits\")\n",
    "plt.legend(title=\"Repositorio\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Mapa de calor de actividad diaria (d칤a de la semana vs. hora del d칤a)\n",
    "df_commits[\"day_of_week\"] = df_commits[\"date\"].dt.day_name()\n",
    "df_commits[\"hour\"] = df_commits[\"date\"].dt.hour\n",
    "\n",
    "day_hour = df_commits.groupby([\"day_of_week\", \"hour\"]).size().unstack().fillna(0)\n",
    "# Reordenar d칤as\n",
    "day_order = [\n",
    "    \"Monday\",\n",
    "    \"Tuesday\",\n",
    "    \"Wednesday\",\n",
    "    \"Thursday\",\n",
    "    \"Friday\",\n",
    "    \"Saturday\",\n",
    "    \"Sunday\",\n",
    "]\n",
    "day_hour = day_hour.reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "if has_seaborn:\n",
    "    sns.heatmap(day_hour, cmap=\"YlGnBu\", annot=True, fmt=\"g\")\n",
    "else:\n",
    "    # Mapa de calor alternativo usando matplotlib\n",
    "    plt.imshow(day_hour, cmap=\"YlGnBu\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Cantidad de Commits\")\n",
    "\n",
    "    # Agregar anotaciones\n",
    "    for i in range(day_hour.shape[0]):\n",
    "        for j in range(day_hour.shape[1]):\n",
    "            if not pd.isna(day_hour.iloc[i, j]) and day_hour.iloc[i, j] > 0:\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i,\n",
    "                    int(day_hour.iloc[i, j]),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "\n",
    "    plt.yticks(range(len(day_hour.index)), day_hour.index)\n",
    "    plt.xticks(range(len(day_hour.columns)), day_hour.columns)\n",
    "\n",
    "plt.title(\"Mapa de Calor de Actividad de Commits (D칤a de la Semana vs. Hora)\")\n",
    "plt.xlabel(\"Hora del D칤a\")\n",
    "plt.ylabel(\"D칤a de la Semana\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 칔ltimos 3 meses de actividad\n",
    "# (Se reutilizan las variables df_month1, df_month2 y df_month3 ya definidas arriba)\n",
    "\n",
    "# Crear estad칤sticas para cada mes\n",
    "print(\"\\nReportes de los 칰ltimos tres meses:\")\n",
    "for i, (df_month, month_offset) in enumerate(\n",
    "    [(df_month1, 3), (df_month2, 2), (df_month3, 1)]\n",
    "):\n",
    "    month_date = recent_date - pd.DateOffset(months=month_offset - 1)\n",
    "    month_name = month_date.strftime(\"%B %Y\")\n",
    "\n",
    "    print(f\"\\n{i + 1}. Reporte de {month_name}\")\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # Estad칤sticas b치sicas\n",
    "    total_commits = len(df_month)\n",
    "    if total_commits == 0:\n",
    "        print(f\"No hay commits en este periodo.\")\n",
    "        continue\n",
    "\n",
    "    # Top autor\n",
    "    autor_commits = df_month.groupby(\"author\").size().sort_values(ascending=False)\n",
    "    top_autor = autor_commits.index[0] if not autor_commits.empty else \"N/A\"\n",
    "    top_commits = autor_commits.iloc[0] if not autor_commits.empty else 0\n",
    "\n",
    "    # Top repo\n",
    "    repo_commits = df_month.groupby(\"repository\").size().sort_values(ascending=False)\n",
    "    top_repo = repo_commits.index[0] if not repo_commits.empty else \"N/A\"\n",
    "    top_repo_commits = repo_commits.iloc[0] if not repo_commits.empty else 0\n",
    "\n",
    "    # D칤as activos\n",
    "    dias_activos = df_month[\"day\"].nunique()\n",
    "    commits_por_dia = total_commits / dias_activos if dias_activos > 0 else 0\n",
    "\n",
    "    # Mostrar estad칤sticas\n",
    "    print(f\"- Total commits: {total_commits}\")\n",
    "    print(\n",
    "        f\"- Colaborador m치s activo: {top_autor} con {top_commits} commits ({top_commits / total_commits * 100:.1f}% del total)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"- Repositorio m치s activo: {top_repo} con {top_repo_commits} commits ({top_repo_commits / total_commits * 100:.1f}% del total)\"\n",
    "    )\n",
    "    print(f\"- D칤as con actividad: {dias_activos}\")\n",
    "    print(f\"- Promedio de commits por d칤a activo: {commits_por_dia:.2f}\")\n",
    "\n",
    "# Resumen general\n",
    "oldest_date = df_commits[\"date\"].min()\n",
    "analysis_period = (recent_date - oldest_date).days\n",
    "\n",
    "print(\"\\nPerspectivas Generales:\")\n",
    "print(\n",
    "    f\"- Per칤odo de an치lisis: {analysis_period} d칤as ({oldest_date.date()} a {recent_date.date()})\"\n",
    ")\n",
    "print(\n",
    "    f\"- Colaborador m치s activo: {commit_stats['author'].iloc[0]} con {commit_stats['total_commits'].iloc[0]} commits ({commit_stats['percentage'].iloc[0]}% del total)\"\n",
    ")\n",
    "print(f\"- Promedio de commits por d칤a: {df_commits.groupby('day').size().mean():.2f}\")\n",
    "print(f\"- El d칤a m치s activo tuvo {df_commits.groupby('day').size().max()} commits\")\n",
    "\n",
    "# Repositorio con m치s actividad\n",
    "repo_activity = df_commits.groupby(\"repository\").size().reset_index(name=\"commits\")\n",
    "most_active_repo = repo_activity.sort_values(\"commits\", ascending=False).iloc[0]\n",
    "print(\n",
    "    f\"- Repositorio m치s activo: {most_active_repo['repository']} con {most_active_repo['commits']} commits\"\n",
    ")\n",
    "\n",
    "# Calcular d칤as sin commits\n",
    "all_days = pd.date_range(start=oldest_date.date(), end=recent_date.date())\n",
    "commit_days = df_commits[\"day\"].unique()\n",
    "days_no_commits = len(all_days) - len(commit_days)\n",
    "print(\n",
    "    f\"- D칤as sin actividad de commits: {days_no_commits} ({days_no_commits / len(all_days) * 100:.1f}% de los d칤as)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e6d0f3",
   "metadata": {},
   "source": [
    "### 2. Tama침o de los Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extender el an치lisis de commits para incluir tama침o (l칤neas agregadas/eliminadas)\n",
    "\n",
    "# Verificar si las columnas necesarias existen en df_commits\n",
    "if \"message\" not in df_commits.columns:\n",
    "    print(\n",
    "        \"La columna 'message' no est치 disponible para analizar el contenido de los commits\"\n",
    "    )\n",
    "    # Podr칤amos intentar obtener estos datos con solicitudes adicionales\n",
    "\n",
    "# Crear categor칤as de tama침o basadas en heur칤sticas\n",
    "# 1. Extraer informaci칩n del tama침o de los mensajes (como aproximaci칩n)\n",
    "df_commits[\"msg_length\"] = df_commits[\"message\"].str.len()\n",
    "\n",
    "# 2. Clasificar los commits por tama침o estimado basado en el mensaje\n",
    "df_commits[\"size_category\"] = pd.cut(\n",
    "    df_commits[\"msg_length\"],\n",
    "    bins=[0, 50, 150, 500, float(\"inf\")],\n",
    "    labels=[\"Peque침o\", \"Medio\", \"Grande\", \"Muy Grande\"],\n",
    ")\n",
    "\n",
    "# 3. Analizar el tipo de commit basado en prefijos comunes\n",
    "pattern = r\"^(游룦游빍|游|九|游댢|游닇)\"\n",
    "df_commits[\"has_emoji_prefix\"] = df_commits[\"message\"].str.contains(pattern, regex=True)\n",
    "df_commits[\"commit_type\"] = \"Otro\"\n",
    "df_commits.loc[\n",
    "    df_commits[\"message\"].str.contains(r\"(?i)fix|游룊", na=False), \"commit_type\"\n",
    "] = \"Correcci칩n\"\n",
    "df_commits.loc[\n",
    "    df_commits[\"message\"].str.contains(r\"(?i)feat|游빍\", na=False), \"commit_type\"\n",
    "] = \"Funcionalidad\"\n",
    "df_commits.loc[\n",
    "    df_commits[\"message\"].str.contains(r\"(?i)refactor|游\", na=False), \"commit_type\"\n",
    "] = \"Refactorizaci칩n\"\n",
    "df_commits.loc[\n",
    "    df_commits[\"message\"].str.contains(r\"(?i)docs|游닇\", na=False), \"commit_type\"\n",
    "] = \"Documentaci칩n\"\n",
    "\n",
    "# 4. Analizar patrones de commits por autor\n",
    "size_by_author = (\n",
    "    df_commits.groupby([\"author\", \"size_category\"]).size().unstack().fillna(0)\n",
    ")\n",
    "type_by_author = (\n",
    "    df_commits.groupby([\"author\", \"commit_type\"]).size().unstack().fillna(0)\n",
    ")\n",
    "\n",
    "# 5. Visualizaci칩n de los resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = size_by_author.plot(kind=\"bar\", stacked=False)\n",
    "plt.title(\"Distribuci칩n de Tama침o de Commits por Autor\")\n",
    "plt.xlabel(\"Autor\")\n",
    "plt.ylabel(\"N칰mero de Commits\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Tama침o de Commit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Distribuci칩n de tipos de commits\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = type_by_author.plot(kind=\"bar\", stacked=False)\n",
    "plt.title(\"Tipos de Commits por Autor\")\n",
    "plt.xlabel(\"Autor\")\n",
    "plt.ylabel(\"N칰mero de Commits\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title=\"Tipo de Commit\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 7. Resumen estad칤stico\n",
    "print(\"\\nResumen del Tama침o de Commits:\")\n",
    "print(size_by_author.to_string())\n",
    "print(\"\\nDistribuci칩n por Tipo de Commit:\")\n",
    "print(type_by_author.to_string())\n",
    "\n",
    "# 8. Identificar commits extremadamente grandes o peque침os\n",
    "avg_length = df_commits[\"msg_length\"].mean()\n",
    "std_length = df_commits[\"msg_length\"].std()\n",
    "large_threshold = avg_length + 2 * std_length\n",
    "\n",
    "print(f\"\\nLongitud media de mensaje de commit: {avg_length:.1f} caracteres\")\n",
    "print(f\"Desviaci칩n est치ndar: {std_length:.1f} caracteres\")\n",
    "print(f\"Umbral para commits grandes: {large_threshold:.1f} caracteres\\n\")\n",
    "\n",
    "# Commits muy grandes (mensaje extenso puede indicar muchos cambios)\n",
    "large_commits = df_commits[df_commits[\"msg_length\"] > large_threshold].sort_values(\n",
    "    by=\"msg_length\", ascending=False\n",
    ")\n",
    "if not large_commits.empty:\n",
    "    print(\"Commits potencialmente grandes:\")\n",
    "    for _, row in large_commits.head(5).iterrows():\n",
    "        print(\n",
    "            f\"- Autor: {row['author']}, Mensaje: {row['message'][:50]}... ({row['msg_length']} caracteres)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5ccce",
   "metadata": {},
   "source": [
    "### 3. Pull Requests (PR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2bec7",
   "metadata": {},
   "source": [
    "#### 3.1 Cantidades y tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2df90e",
   "metadata": {},
   "source": [
    "##### Procesar los datos y graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da054156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# An치lisis de Pull Requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar los estados disponibles en los PRs\n",
    "pr_states = df_pr[\"state\"].value_counts().reset_index()\n",
    "pr_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# Analizar PR por autor\n",
    "pr_by_author = df_pr.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"MERGED\" in pr_by_author.columns:\n",
    "    pr_by_author[\"total\"] = pr_by_author.sum(axis=1)\n",
    "    pr_by_author = pr_by_author.sort_values(\"total\", ascending=False)\n",
    "    pr_by_author = pr_by_author.drop(columns=[\"total\"])\n",
    "\n",
    "# Calcular tiempos promedio\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "df_pr[\"updated_on\"] = pd.to_datetime(df_pr[\"updated_on\"])\n",
    "\n",
    "# M칠tricas de tiempo para PRs cerrados/mergeados\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "if not merged_prs.empty:\n",
    "    merged_prs[\"time_to_merge_days\"] = (\n",
    "        merged_prs[\"updated_on\"] - merged_prs[\"created_on\"]\n",
    "    ).dt.total_seconds() / 86400\n",
    "    avg_merge_time = merged_prs[\"time_to_merge_days\"].mean()\n",
    "    median_merge_time = merged_prs[\"time_to_merge_days\"].median()\n",
    "    max_merge_time = merged_prs[\"time_to_merge_days\"].max()\n",
    "\n",
    "# Extraer tipos de ramas de los PRs\n",
    "branch_types = df_pr[\"type_branch\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 游늳 1. Estado de los PRs\n",
    "axes[0, 0].bar(pr_states[\"Estado\"], pr_states[\"Cantidad\"], color=\"skyblue\")\n",
    "axes[0, 0].set_title(\"Estado de Pull Requests\")\n",
    "axes[0, 0].set_xlabel(\"Estado\")\n",
    "axes[0, 0].set_ylabel(\"Cantidad\")\n",
    "\n",
    "# 游늳 2. PRs por autor\n",
    "pr_by_author.plot(kind=\"bar\", stacked=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Pull Requests por Autor\")\n",
    "axes[0, 1].set_xlabel(\"Autor\")\n",
    "axes[0, 1].set_ylabel(\"Cantidad\")\n",
    "axes[0, 1].legend(title=\"Estado\")\n",
    "\n",
    "\n",
    "# 游늳 3. Tiempo de resoluci칩n de PRs\n",
    "if not merged_prs.empty:\n",
    "    merged_prs.boxplot(column=\"time_to_merge_days\", ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Tiempo para Merge (d칤as)\")\n",
    "    axes[1, 0].set_ylabel(\"D칤as\")\n",
    "\n",
    "    # A침adir una l칤nea para el promedio\n",
    "    axes[1, 0].axhline(\n",
    "        y=avg_merge_time,\n",
    "        color=\"red\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Promedio: {avg_merge_time:.1f} d칤as\",\n",
    "    )\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# 游늳 4. Tipos de ramas\n",
    "axes[1, 1].pie(branch_types[\"Cantidad\"], labels=branch_types[\"Tipo\"], autopct=\"%1.1f%%\")\n",
    "axes[1, 1].set_title(\"Distribuci칩n de Tipos de Ramas\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# M칠tricas adicionales\n",
    "print(\"\\n=== M칠tricas de Pull Requests ===\")\n",
    "print(f\"Total de PRs analizados: {len(df_pr)}\")\n",
    "print(f\"PRs por estado: {dict(pr_states.values)}\")\n",
    "if not merged_prs.empty:\n",
    "    print(f\"\\nTiempo promedio hasta merge: {avg_merge_time:.1f} d칤as\")\n",
    "    print(f\"Tiempo mediano hasta merge: {median_merge_time:.1f} d칤as\")\n",
    "    print(f\"Tiempo m치ximo hasta merge: {max_merge_time:.1f} d칤as\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 游늵 An치lisis de eficiencia de PRs\n",
    "if not merged_prs.empty:\n",
    "    author_efficiency = (\n",
    "        merged_prs.groupby(\"author\")[\"time_to_merge_days\"]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    author_efficiency.columns = [\"Tiempo promedio (d칤as)\", \"PRs mergeados\"]\n",
    "\n",
    "    # Crear tres gr치ficas para visualizar la eficiencia de los autores\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # 游늳 Gr치fica 1: Tiempo promedio hasta merge\n",
    "    author_efficiency[\"Tiempo promedio (d칤as)\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"skyblue\",\n",
    "        ax=ax1,\n",
    "        title=\"Tiempo promedio hasta merge por autor\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"Autor\")\n",
    "    ax1.set_ylabel(\"D칤as\")\n",
    "    for i, v in enumerate(author_efficiency[\"Tiempo promedio (d칤as)\"]):\n",
    "        ax1.text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 游늳 Gr치fica 2: Cantidad de PRs mergeados\n",
    "    author_efficiency[\"PRs mergeados\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"lightgreen\",\n",
    "        ax=ax2,\n",
    "        title=\"Cantidad de PRs mergeados por autor\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"Autor\")\n",
    "    ax2.set_ylabel(\"Cantidad\")\n",
    "    for i, v in enumerate(author_efficiency[\"PRs mergeados\"]):\n",
    "        ax2.text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "    # 游늳 Gr치fica 3: Eficiencia general de los autores\n",
    "    scatter = ax3.scatter(\n",
    "        author_efficiency[\"Tiempo promedio (d칤as)\"],\n",
    "        author_efficiency[\"PRs mergeados\"],\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        c=author_efficiency[\"Tiempo promedio (d칤as)\"],\n",
    "        cmap=\"coolwarm_r\",\n",
    "    )\n",
    "\n",
    "    # A침adir etiquetas a cada punto\n",
    "    for i, author in enumerate(author_efficiency.index):\n",
    "        ax3.annotate(\n",
    "            author,\n",
    "            (\n",
    "                author_efficiency[\"Tiempo promedio (d칤as)\"][i],\n",
    "                author_efficiency[\"PRs mergeados\"][i],\n",
    "            ),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    ax3.set_title(\"Eficiencia de autores\")\n",
    "    ax3.set_xlabel(\"Tiempo promedio (d칤as)\")\n",
    "    ax3.set_ylabel(\"PRs mergeados\")\n",
    "    ax3.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # A침adir colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label(\"Tiempo promedio (d칤as)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n=== Eficiencia de autores (tiempo promedio hasta merge) ===\")\n",
    "    print(author_efficiency.to_string(float_format=lambda x: f\"{x:.1f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e885a0",
   "metadata": {},
   "source": [
    "#### 3.2 Comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff35cd",
   "metadata": {},
   "source": [
    "##### PRs m치s largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar PRs con tiempos de revisi칩n largos y comentarios numerosos\n",
    "if \"comment_count\" in df_pr.columns:\n",
    "    high_discussion = df_pr.sort_values(\"comment_count\", ascending=False).head(5)\n",
    "    print(\"\\n=== PRs con m치s discusi칩n (mayor n칰mero de comentarios) ===\")\n",
    "    high_discussion[\"formatted_date\"] = high_discussion[\"created_on\"].dt.strftime(\n",
    "        \"%d-%m-%Y\"\n",
    "    )\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"T칤tulo\": high_discussion[\"title\"],\n",
    "                \"Autor\": high_discussion[\"author\"],\n",
    "                \"Comentarios\": high_discussion[\"comment_count\"],\n",
    "                \"Estado\": high_discussion[\"state\"],\n",
    "                \"Fecha\": high_discussion[\"formatted_date\"],\n",
    "            }\n",
    "        ).to_string()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb76a",
   "metadata": {},
   "source": [
    "##### Procesar los datos (primeras 3 gr치ficas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Par치metro configurable: n칰mero de d칤as a analizar\n",
    "num_days_to_analyze = 25\n",
    "\n",
    "# Calcular fecha l칤mite\n",
    "today = pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "date_limit = today - pd.Timedelta(days=num_days_to_analyze)\n",
    "\n",
    "# Asegurar que la columna de fecha est치 en el formato correcto\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "\n",
    "# Filtrar PRs por fecha\n",
    "recent_prs = df_pr[df_pr[\"created_on\"] >= date_limit]\n",
    "\n",
    "# Crear una lista de todas las fechas en el rango analizado\n",
    "date_range = pd.date_range(start=date_limit, end=today, freq=\"D\")\n",
    "date_range = [d.date() for d in date_range]\n",
    "\n",
    "# Contar PRs por d칤a\n",
    "prs_by_day = recent_prs.groupby(recent_prs[\"created_on\"].dt.date).size()\n",
    "\n",
    "# Asegurar que tenemos todas las fechas (incluso las que no tienen PRs)\n",
    "prs_by_day = prs_by_day.reindex(date_range, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e6b5c",
   "metadata": {},
   "source": [
    "##### Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37582fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 游늳 1. Gr치fico general de PRs por d칤a\n",
    "plt.figure(figsize=(12, 6))\n",
    "prs_by_day.plot(kind=\"bar\", color=\"cornflowerblue\")\n",
    "plt.title(f\"PRs creados por d칤a (칰ltimos {num_days_to_analyze} d칤as)\", fontsize=14)\n",
    "plt.xlabel(\"Fecha\", fontsize=12)\n",
    "plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "\n",
    "# A침adir etiquetas de valor sobre cada barra\n",
    "for i, value in enumerate(prs_by_day):\n",
    "    if value > 0:\n",
    "        plt.text(i, value + 0.1, str(int(value)), ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 游늳 2. Gr치ficos individuales por desarrollador\n",
    "# Obtener lista de desarrolladores\n",
    "developers = recent_prs[\"author\"].unique()\n",
    "\n",
    "for dev in developers:\n",
    "    # Filtrar PRs de este desarrollador\n",
    "    dev_prs = recent_prs[recent_prs[\"author\"] == dev]\n",
    "\n",
    "    # Contar PRs por d칤a para este desarrollador\n",
    "    dev_prs_by_day = dev_prs.groupby(dev_prs[\"created_on\"].dt.date).size()\n",
    "\n",
    "    # Asegurar que tenemos todas las fechas (incluso las que no tienen PRs)\n",
    "    dev_prs_by_day = dev_prs_by_day.reindex(date_range, fill_value=0)\n",
    "\n",
    "    # Crear gr치fico para este desarrollador\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    ax = dev_prs_by_day.plot(kind=\"bar\", color=\"lightseagreen\")\n",
    "    plt.title(\n",
    "        f\"PRs creados por {dev} (칰ltimos {num_days_to_analyze} d칤as)\", fontsize=14\n",
    "    )\n",
    "    plt.xlabel(\"Fecha\", fontsize=12)\n",
    "    plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "\n",
    "    # A침adir etiquetas de valor sobre cada barra\n",
    "    for i, value in enumerate(dev_prs_by_day):\n",
    "        if value > 0:\n",
    "            plt.text(i, value + 0.05, str(int(value)), ha=\"center\")\n",
    "\n",
    "    # A침adir informaci칩n adicional\n",
    "    total_prs = dev_prs_by_day.sum()\n",
    "    avg_prs = dev_prs_by_day.mean()\n",
    "    plt.figtext(\n",
    "        0.5,\n",
    "        0.01,\n",
    "        f\"Total: {int(total_prs)} PRs | Promedio: {avg_prs:.2f} PRs/d칤a\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "        bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5},\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 游늳 3. Gr치fico comparativo entre desarrolladores\n",
    "dev_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Desarrollador\": developers,\n",
    "        \"Total PRs\": [\n",
    "            len(recent_prs[recent_prs[\"author\"] == dev]) for dev in developers\n",
    "        ],\n",
    "    }\n",
    ").sort_values(\"Total PRs\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    dev_comparison[\"Desarrollador\"], dev_comparison[\"Total PRs\"], color=\"teal\"\n",
    ")\n",
    "\n",
    "# A침adir etiquetas de valor sobre cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Comparaci칩n de PRs creados por desarrollador (칰ltimos {num_days_to_analyze} d칤as)\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define the number of PRs to display per author\n",
    "num_prs_to_display = num_days_to_analyze  # This can be changed to any value as needed\n",
    "\n",
    "# Filtrar los 칰ltimos PRs para cada autor (basado en la variable)\n",
    "author_prs = {}\n",
    "for author in df_pr[\"author\"].unique():\n",
    "    # Obtener los 칰ltimos N PRs de este autor\n",
    "    latest_prs = (\n",
    "        df_pr[df_pr[\"author\"] == author]\n",
    "        .sort_values(\"created_on\", ascending=False)\n",
    "        .head(num_prs_to_display)\n",
    "    )\n",
    "\n",
    "    if not latest_prs.empty:\n",
    "        author_prs[author] = latest_prs\n",
    "\n",
    "# Crear una figura para cada autor\n",
    "for author, prs in author_prs.items():\n",
    "    # Configurar el gr치fico para este autor\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Preparar datos para este autor\n",
    "    comment_counts = []\n",
    "    pr_titles = []\n",
    "    actual_count = min(len(prs), num_prs_to_display)\n",
    "\n",
    "    # Obtener datos para las barras\n",
    "    for j in range(actual_count):\n",
    "        comment_counts.append(prs.iloc[j][\"comment_count\"])\n",
    "        pr_titles.append(f\"{j + 1}\")\n",
    "\n",
    "    # Crear posiciones para las barras\n",
    "    positions = np.arange(len(comment_counts))\n",
    "\n",
    "    # Graficar barras para este autor\n",
    "    bars = ax.bar(positions, comment_counts, color=\"skyblue\", width=0.7)\n",
    "\n",
    "    # A침adir etiquetas con el n칰mero de comentarios encima de cada barra\n",
    "    for bar, count in zip(bars, comment_counts):\n",
    "        if count > 0:\n",
    "            height = bar.get_height()\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height + 0.3,\n",
    "                str(int(count)),\n",
    "                ha=\"center\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "    # Configuraci칩n adicional del gr치fico\n",
    "    ax.set_title(\n",
    "        f\"Comentarios en los 칔ltimos {actual_count} PRs de {author}\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xlabel(\n",
    "        \"N칰mero de PR (del m치s reciente al m치s antiguo)\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_ylabel(\"N칰mero de Comentarios\", fontsize=12)\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(pr_titles)\n",
    "\n",
    "    # A침adir una referencia al n칰mero de ticket y estado en la parte inferior\n",
    "    if actual_count > 0:\n",
    "        ticket_info = []\n",
    "        for j in range(actual_count):\n",
    "            pr = prs.iloc[j]\n",
    "            # Extraer el c칩digo del ticket (BTB-XXX) del t칤tulo si existe\n",
    "            title = pr[\"title\"]\n",
    "            ticket_code = \"\"\n",
    "            import re\n",
    "\n",
    "            match = re.search(r\"\\(([A-Z]+-\\d+)\\)\", title) or re.search(\n",
    "                r\"\\s([A-Z]+-\\d+)\", title\n",
    "            )\n",
    "            if match:\n",
    "                ticket_code = match.group(1)\n",
    "            else:\n",
    "                # Intentar extraer cualquier c칩digo con formato BTB-XXX\n",
    "                match = re.search(r\"([A-Z]+-\\d+)\", title)\n",
    "                if match:\n",
    "                    ticket_code = match.group(1)\n",
    "\n",
    "            state_info = f\"[{pr['state']}]\"\n",
    "            ticket_info.append(f\"{ticket_code} {state_info}\")\n",
    "\n",
    "        # A침adir anotaciones con informaci칩n del ticket\n",
    "        plt.figtext(\n",
    "            0.5,\n",
    "            0.01,\n",
    "            \"Tickets de referencia (del m치s reciente): \"\n",
    "            + \" | \".join(ticket_info[:5])\n",
    "            + (\"...\" if len(ticket_info) > 5 else \"\"),\n",
    "            ha=\"center\",\n",
    "            fontsize=8,\n",
    "            wrap=True,\n",
    "        )\n",
    "\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout(\n",
    "        rect=[0, 0.05, 1, 0.95]\n",
    "    )  # Dejar espacio para la anotaci칩n inferior\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "# 游늳 Crear gr치fica comparativa del promedio de comentarios por PR por autor\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Calcular el promedio de comentarios por autor\n",
    "avg_comments_by_author = {}\n",
    "for author, prs in author_prs.items():\n",
    "    avg_comments = prs[\"comment_count\"].mean()\n",
    "    avg_comments_by_author[author] = avg_comments\n",
    "\n",
    "# Ordenar los autores por promedio de comentarios (descendente)\n",
    "sorted_authors = sorted(\n",
    "    avg_comments_by_author.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "authors = [item[0] for item in sorted_authors]\n",
    "avg_values = [item[1] for item in sorted_authors]\n",
    "\n",
    "# Crear barras\n",
    "positions = np.arange(len(authors))\n",
    "bars = plt.bar(positions, avg_values, color=\"teal\", width=0.6)\n",
    "\n",
    "# A침adir etiquetas con el valor promedio\n",
    "for bar, value in zip(bars, avg_values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{value:.1f}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Configurar gr치fico\n",
    "plt.title(\"Promedio de Comentarios por PR por Autor\", fontsize=16)\n",
    "plt.xlabel(\"Autor\", fontsize=14)\n",
    "plt.ylabel(\"Promedio de Comentarios\", fontsize=14)\n",
    "plt.xticks(positions, authors, rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e3683",
   "metadata": {},
   "source": [
    "### 4. Revisi칩n de C칩digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1530b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analizar la calidad de revisi칩n de c칩digo basado en los datos de PR\n",
    "# Extraer datos de comentarios, aprobaciones y estados\n",
    "\n",
    "# 1. An치lisis de comentarios y revisiones por PR\n",
    "comment_analysis = df_pr[\n",
    "    [\"author\", \"comment_count\", \"state\", \"repository\", \"days_open\"]\n",
    "]\n",
    "\n",
    "# 2. Estad칤sticas de comentarios por estado y repo\n",
    "comments_by_state = comment_analysis.groupby(\"state\")[\"comment_count\"].agg(\n",
    "    [\"mean\", \"median\", \"sum\", \"count\"]\n",
    ")\n",
    "comments_by_repo = comment_analysis.groupby(\"repository\")[\"comment_count\"].agg(\n",
    "    [\"mean\", \"median\", \"sum\", \"count\"]\n",
    ")\n",
    "\n",
    "# 3. Identificar PRs con comentarios vs sin comentarios\n",
    "comment_analysis[\"has_comments\"] = comment_analysis[\"comment_count\"] > 0\n",
    "comments_percentage = comment_analysis[\"has_comments\"].mean() * 100\n",
    "\n",
    "# 4. An치lisis por autor (qui칠n recibe m치s comentarios)\n",
    "author_comments = comment_analysis.groupby(\"author\").agg(\n",
    "    {\"comment_count\": [\"mean\", \"sum\", \"count\"], \"has_comments\": \"mean\"}\n",
    ")\n",
    "author_comments.columns = [\n",
    "    \"avg_comments\",\n",
    "    \"total_comments\",\n",
    "    \"total_prs\",\n",
    "    \"pct_prs_with_comments\",\n",
    "]\n",
    "author_comments[\"pct_prs_with_comments\"] = (\n",
    "    author_comments[\"pct_prs_with_comments\"] * 100\n",
    ")\n",
    "\n",
    "# 5. Relaci칩n entre tiempo abierto y cantidad de comentarios\n",
    "correlation = comment_analysis[[\"days_open\", \"comment_count\"]].corr().iloc[0, 1]\n",
    "\n",
    "# Visualizaciones\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# 游늳 1. Distribuci칩n de comentarios por PR\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(comment_analysis[\"comment_count\"], kde=True, bins=10)\n",
    "plt.title(\"Distribuci칩n de Comentarios por PR\")\n",
    "plt.xlabel(\"N칰mero de Comentarios\")\n",
    "plt.ylabel(\"Cantidad de PRs\")\n",
    "\n",
    "# 游늳 2. Comentarios promedio por autor\n",
    "plt.subplot(2, 2, 2)\n",
    "author_order = author_comments.sort_values(\"avg_comments\", ascending=False).index\n",
    "sns.barplot(x=author_comments.loc[author_order, \"avg_comments\"], y=author_order)\n",
    "plt.title(\"Comentarios Promedio por Autor\")\n",
    "plt.xlabel(\"Promedio de Comentarios\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# 游늳 3. Porcentaje de PRs con comentarios por autor\n",
    "plt.subplot(2, 2, 3)\n",
    "author_order = author_comments.sort_values(\n",
    "    \"pct_prs_with_comments\", ascending=False\n",
    ").index\n",
    "bars = plt.barh(\n",
    "    author_order, author_comments.loc[author_order, \"pct_prs_with_comments\"]\n",
    ")\n",
    "plt.title(\"% de PRs con Comentarios por Autor\")\n",
    "plt.xlabel(\"Porcentaje\")\n",
    "# A침adir etiquetas de valor a las barras\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(\n",
    "        width + 1,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{width:.1f}%\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "# 游늳 4. Relaci칩n entre tiempo abierto y comentarios\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x=\"days_open\", y=\"comment_count\", hue=\"author\", data=comment_analysis)\n",
    "plt.title(\n",
    "    f\"Relaci칩n entre Tiempo Abierto y Comentarios\\nCorrelaci칩n: {correlation:.2f}\"\n",
    ")\n",
    "plt.xlabel(\"D칤as Abierto\")\n",
    "plt.ylabel(\"N칰mero de Comentarios\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla de estad칤sticas\n",
    "print(\"\\n=== Estad칤sticas de Revisi칩n de C칩digo ===\")\n",
    "print(f\"PRs con al menos un comentario: {comments_percentage:.1f}%\")\n",
    "print(f\"Comentarios promedio por PR: {comment_analysis['comment_count'].mean():.2f}\")\n",
    "print(\"\\nComentarios por estado de PR:\")\n",
    "print(comments_by_state)\n",
    "print(\"\\nComentarios por repositorio:\")\n",
    "print(comments_by_repo)\n",
    "\n",
    "# An치lisis de calidad de revisi칩n\n",
    "print(\"\\n=== An치lisis de Calidad de Revisi칩n ===\")\n",
    "print(\"Estad칤sticas por autor:\")\n",
    "print(author_comments.sort_values(\"avg_comments\", ascending=False))\n",
    "\n",
    "# Identificar revisores m치s activos (estimaci칩n basada en comentarios)\n",
    "# Asumimos que autores que reciben comentarios tambi칠n hacen comentarios en PRs de otros\n",
    "active_reviewers = author_comments.sort_values(\"total_comments\", ascending=False)\n",
    "print(\"\\nRevisores m치s activos (estimado):\")\n",
    "for author, row in active_reviewers.iterrows():\n",
    "    print(\n",
    "        f\"- {author}: {row['total_comments']} comentarios totales en {row['total_prs']} PRs\"\n",
    "    )\n",
    "\n",
    "# An치lisis adicional de tiempo de respuesta y eficiencia\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"]\n",
    "if not merged_prs.empty:\n",
    "    print(f\"\\nTiempo promedio hasta merge: {merged_prs['days_open'].mean():.1f} d칤as\")\n",
    "    print(\n",
    "        f\"PRs que recibieron comentarios: {merged_prs['comment_count'].gt(0).mean() * 100:.1f}%\"\n",
    "    )\n",
    "\n",
    "    # Analizar si los PRs con comentarios tardan m치s en ser mergeados\n",
    "    with_comments = merged_prs[merged_prs[\"comment_count\"] > 0][\"days_open\"].mean()\n",
    "    without_comments = merged_prs[merged_prs[\"comment_count\"] == 0][\"days_open\"].mean()\n",
    "    print(f\"Tiempo promedio hasta merge (con comentarios): {with_comments:.1f} d칤as\")\n",
    "    print(f\"Tiempo promedio hasta merge (sin comentarios): {without_comments:.1f} d칤as\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b819596",
   "metadata": {},
   "source": [
    "### Tiempo de Revisi칩n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# An치lisis de tiempo desde PR creada hasta merge/cierre\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurar que las fechas est치n en formato correcto\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "df_pr[\"updated_on\"] = pd.to_datetime(df_pr[\"updated_on\"])\n",
    "\n",
    "# Filtrar PRs que han sido cerradas (merged o declined)\n",
    "closed_prs = df_pr[df_pr[\"state\"].isin([\"MERGED\", \"DECLINED\"])].copy()\n",
    "\n",
    "if not closed_prs.empty:\n",
    "    # Calcular tiempo hasta cierre para PRs cerradas\n",
    "    closed_prs[\"time_to_close_days\"] = (\n",
    "        closed_prs[\"updated_on\"] - closed_prs[\"created_on\"]\n",
    "    ).dt.total_seconds() / 86400\n",
    "\n",
    "    # Analizar por autor, repositorio y tipo de rama\n",
    "    time_by_author = (\n",
    "        closed_prs.groupby(\"author\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    time_by_repo = (\n",
    "        closed_prs.groupby(\"repository\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    time_by_branch_type = (\n",
    "        closed_prs.groupby(\"type_branch\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "\n",
    "    # Visualizaciones\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Distribuci칩n general de tiempos de revisi칩n\n",
    "    sns.histplot(closed_prs[\"time_to_close_days\"], bins=15, kde=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Distribuci칩n de Tiempos de Revisi칩n\")\n",
    "    axes[0, 0].set_xlabel(\"D칤as hasta cierre\")\n",
    "    axes[0, 0].axvline(\n",
    "        closed_prs[\"time_to_close_days\"].median(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mediana: {closed_prs['time_to_close_days'].median():.1f} d칤as\",\n",
    "    )\n",
    "    axes[0, 0].axvline(\n",
    "        closed_prs[\"time_to_close_days\"].mean(),\n",
    "        color=\"green\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Media: {closed_prs['time_to_close_days'].mean():.1f} d칤as\",\n",
    "    )\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "    # 2. Tiempo promedio por autor\n",
    "    sns.barplot(x=time_by_author.index, y=time_by_author[\"mean\"], ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Tiempo Promedio de Revisi칩n por Autor\")\n",
    "    axes[0, 1].set_ylabel(\"D칤as\")\n",
    "    axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)\n",
    "    for i, v in enumerate(time_by_author[\"mean\"]):\n",
    "        axes[0, 1].text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 3. Tiempo promedio por repositorio\n",
    "    sns.barplot(x=time_by_repo.index, y=time_by_repo[\"mean\"], ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Tiempo Promedio de Revisi칩n por Repositorio\")\n",
    "    axes[1, 0].set_ylabel(\"D칤as\")\n",
    "    axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45)\n",
    "    for i, v in enumerate(time_by_repo[\"mean\"]):\n",
    "        axes[1, 0].text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 4. Boxplot de tiempo por tipo de rama\n",
    "    sns.boxplot(x=\"type_branch\", y=\"time_to_close_days\", data=closed_prs, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Distribuci칩n de Tiempo por Tipo de Rama\")\n",
    "    axes[1, 1].set_ylabel(\"D칤as hasta cierre\")\n",
    "    axes[1, 1].set_xlabel(\"Tipo de rama\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # An치lisis adicional: Correlaci칩n entre comentarios y tiempo de revisi칩n\n",
    "    correlation = closed_prs[[\"time_to_close_days\", \"comment_count\"]].corr().iloc[0, 1]\n",
    "\n",
    "    # Visualizar relaci칩n entre comentarios y tiempo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x=\"comment_count\", y=\"time_to_close_days\", hue=\"author\", data=closed_prs\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Relaci칩n entre Comentarios y Tiempo de Revisi칩n (r = {correlation:.2f})\"\n",
    "    )\n",
    "    plt.xlabel(\"N칰mero de Comentarios\")\n",
    "    plt.ylabel(\"D칤as hasta cierre\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Imprimir estad칤sticas de tiempo de revisi칩n\n",
    "    print(\"===== AN츼LISIS DE TIEMPO DE REVISI칍N =====\")\n",
    "    print(\n",
    "        f\"\\nTiempo promedio global hasta cierre: {closed_prs['time_to_close_days'].mean():.1f} d칤as\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Tiempo mediano global hasta cierre: {closed_prs['time_to_close_days'].median():.1f} d칤as\"\n",
    "    )\n",
    "    print(\n",
    "        f\"PRs con tiempo de revisi칩n excesivo (>7 d칤as): {(closed_prs['time_to_close_days'] > 7).sum()} ({(closed_prs['time_to_close_days'] > 7).mean() * 100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Identificar PRs con tiempos de revisi칩n r치pidos vs lentos\n",
    "    fast_reviews = closed_prs[closed_prs[\"time_to_close_days\"] <= 1]\n",
    "    slow_reviews = closed_prs[closed_prs[\"time_to_close_days\"] >= 7]\n",
    "\n",
    "    print(\n",
    "        f\"\\nPRs con revisi칩n r치pida (곣1 d칤a): {len(fast_reviews)} ({len(fast_reviews) / len(closed_prs) * 100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"PRs con revisi칩n lenta (곤7 d칤as): {len(slow_reviews)} ({len(slow_reviews) / len(closed_prs) * 100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Analizar tendencia de tiempo de revisi칩n a lo largo del tiempo\n",
    "    closed_prs[\"merge_month\"] = closed_prs[\"updated_on\"].dt.strftime(\"%Y-%m\")\n",
    "    time_trend = (\n",
    "        closed_prs.groupby(\"merge_month\")[\"time_to_close_days\"].mean().reset_index()\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(\n",
    "        time_trend[\"merge_month\"],\n",
    "        time_trend[\"time_to_close_days\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.title(\"Tendencia de Tiempo de Revisi칩n a lo Largo del Tiempo\")\n",
    "    plt.xlabel(\"Mes\")\n",
    "    plt.ylabel(\"Tiempo Promedio de Revisi칩n (d칤as)\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay PRs cerradas para analizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a764a",
   "metadata": {},
   "source": [
    "### Actividad en Ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3607b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# An치lisis de Actividad en Ramas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraer informaci칩n de ramas de los PRs\n",
    "branches_info = []\n",
    "\n",
    "# Obtener informaci칩n de las ramas desde los PR\n",
    "for pr in df_pr.to_dict(\"records\"):\n",
    "    # Solo procesamos si tenemos informaci칩n de rama\n",
    "    if \"branch\" in pr and \"type_branch\" in pr:\n",
    "        # Extraer tipo de rama (feature, bugfix, etc)\n",
    "        branch_type = pr[\"type_branch\"]\n",
    "        # Nombre de la rama\n",
    "        branch_name = pr[\"branch\"]\n",
    "        # Repositorio\n",
    "        repo = pr[\"repository\"]\n",
    "        # Fecha de creaci칩n (estimada desde la PR)\n",
    "        created_date = pr[\"created_on\"]\n",
    "        # Fecha de cierre (si est치 cerrada)\n",
    "        closed_date = pr[\"updated_on\"] if pr[\"state\"] != \"OPEN\" else None\n",
    "        # Estado actual\n",
    "        state = pr[\"state\"]\n",
    "        # Autor de la rama (asumimos que es el mismo que el de la PR)\n",
    "        author = pr[\"author\"]\n",
    "\n",
    "        # Agregar a la lista\n",
    "        branches_info.append(\n",
    "            {\n",
    "                \"branch_name\": branch_name,\n",
    "                \"branch_type\": branch_type,\n",
    "                \"repository\": repo,\n",
    "                \"author\": author,\n",
    "                \"created_date\": created_date,\n",
    "                \"closed_date\": closed_date,\n",
    "                \"state\": state,\n",
    "                \"days_active\": (pd.Timestamp.now(tz=\"UTC\") - created_date).days\n",
    "                if state == \"OPEN\"\n",
    "                else (closed_date - created_date).days\n",
    "                if closed_date\n",
    "                else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Crear DataFrame con la informaci칩n de ramas\n",
    "df_branches = pd.DataFrame(branches_info)\n",
    "\n",
    "# 1. An치lisis general de ramas\n",
    "branch_states = df_branches[\"state\"].value_counts().reset_index()\n",
    "branch_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# 2. An치lisis por tipo de rama\n",
    "branch_types = df_branches[\"branch_type\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author = df_branches.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"OPEN\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"OPEN\"] = 0\n",
    "if \"MERGED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"MERGED\"] = 0\n",
    "if \"DECLINED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"DECLINED\"] = 0\n",
    "\n",
    "# 4. Tiempo activo de las ramas\n",
    "branch_lifetime = (\n",
    "    df_branches.dropna(subset=[\"days_active\"])\n",
    "    .groupby([\"branch_type\", \"state\"])[\"days_active\"]\n",
    "    .agg([\"mean\", \"median\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5. Ramas abiertas vs cerradas por repositorio\n",
    "branches_by_repo = (\n",
    "    df_branches.groupby([\"repository\", \"state\"]).size().unstack().fillna(0)\n",
    ")\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Estado de las ramas\n",
    "sns.barplot(\n",
    "    x=\"Estado\", y=\"Cantidad\", data=branch_states, ax=axes[0, 0], palette=\"viridis\"\n",
    ")\n",
    "axes[0, 0].set_title(\"Estado de las Ramas\", fontsize=14)\n",
    "for i, v in enumerate(branch_states[\"Cantidad\"]):\n",
    "    axes[0, 0].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 2. Tipos de ramas\n",
    "sns.barplot(x=\"Tipo\", y=\"Cantidad\", data=branch_types, ax=axes[0, 1], palette=\"muted\")\n",
    "axes[0, 1].set_title(\"Distribuci칩n por Tipo de Rama\", fontsize=14)\n",
    "for i, v in enumerate(branch_types[\"Cantidad\"]):\n",
    "    axes[0, 1].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author.plot(kind=\"bar\", stacked=True, ax=axes[1, 0], colormap=\"tab10\")\n",
    "axes[1, 0].set_title(\"Ramas por Autor y Estado\", fontsize=14)\n",
    "axes[1, 0].set_xlabel(\"Autor\")\n",
    "axes[1, 0].set_ylabel(\"N칰mero de Ramas\")\n",
    "axes[1, 0].legend(title=\"Estado\")\n",
    "\n",
    "# 4. Tiempo promedio de las ramas abiertas\n",
    "open_branches = df_branches[df_branches[\"state\"] == \"OPEN\"]\n",
    "if not open_branches.empty:\n",
    "    sns.boxplot(x=\"branch_type\", y=\"days_active\", data=open_branches, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Tiempo de Ramas Abiertas por Tipo\", fontsize=14)\n",
    "    axes[1, 1].set_xlabel(\"Tipo de Rama\")\n",
    "    axes[1, 1].set_ylabel(\"D칤as Activa\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Gr치fico adicional: Evoluci칩n de ramas a lo largo del tiempo\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Crear fechas para el per칤odo analizado\n",
    "start_date = df_branches[\"created_date\"].min().date()\n",
    "end_date = pd.Timestamp.now(tz=\"UTC\").date()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "# Contar ramas creadas por d칤a\n",
    "df_branches[\"created_day\"] = df_branches[\"created_date\"].dt.date\n",
    "created_by_day = df_branches.groupby(\"created_day\").size()\n",
    "\n",
    "# Contar ramas cerradas por d칤a\n",
    "closed_branches = df_branches.dropna(subset=[\"closed_date\"])\n",
    "if not closed_branches.empty:\n",
    "    closed_branches[\"closed_day\"] = closed_branches[\"closed_date\"].dt.date\n",
    "    closed_by_day = closed_branches.groupby(\"closed_day\").size()\n",
    "else:\n",
    "    closed_by_day = pd.Series(0, index=[])\n",
    "\n",
    "# Preparar datos para el gr치fico\n",
    "created_cumsum = pd.Series(0, index=date_range)\n",
    "closed_cumsum = pd.Series(0, index=date_range)\n",
    "\n",
    "for day, count in created_by_day.items():\n",
    "    if day in created_cumsum.index:\n",
    "        created_cumsum[day] = count\n",
    "\n",
    "for day, count in closed_by_day.items():\n",
    "    if day in closed_cumsum.index:\n",
    "        closed_cumsum[day] = count\n",
    "\n",
    "# Calcular acumulados\n",
    "created_cumsum = created_cumsum.cumsum()\n",
    "closed_cumsum = closed_cumsum.cumsum()\n",
    "\n",
    "# Calcular ramas activas (creadas - cerradas)\n",
    "active_branches = created_cumsum - closed_cumsum\n",
    "\n",
    "# Graficar\n",
    "plt.plot(date_range, created_cumsum, \"b-\", label=\"Ramas Creadas (Acumulado)\")\n",
    "plt.plot(date_range, closed_cumsum, \"r-\", label=\"Ramas Cerradas (Acumulado)\")\n",
    "plt.plot(date_range, active_branches, \"g-\", label=\"Ramas Activas\")\n",
    "\n",
    "plt.title(\"Evoluci칩n de Ramas a lo Largo del Tiempo\", fontsize=16)\n",
    "plt.xlabel(\"Fecha\", fontsize=12)\n",
    "plt.ylabel(\"N칰mero de Ramas\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir estad칤sticas\n",
    "print(\"\\n===== AN츼LISIS DE ACTIVIDAD EN RAMAS =====\")\n",
    "print(f\"Total de ramas analizadas: {len(df_branches)}\")\n",
    "print(f\"Ramas por estado: {dict(branch_states.values)}\")\n",
    "print(f\"Ramas por tipo: {dict(branch_types.values)}\")\n",
    "print(\"\\nRamas abiertas por tiempo:\")\n",
    "if not open_branches.empty:\n",
    "    open_by_time = (\n",
    "        open_branches.groupby(\"branch_type\")[\"days_active\"]\n",
    "        .agg([\"count\", \"mean\", \"median\", \"max\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in open_by_time.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_type']}: {row['count']} ramas, promedio {row['mean']:.1f} d칤as, m치ximo {row['max']} d칤as\"\n",
    "        )\n",
    "\n",
    "# Detectar ramas potencialmente abandonadas (abiertas por m치s de 30 d칤as)\n",
    "abandoned = open_branches[open_branches[\"days_active\"] > 30].sort_values(\n",
    "    \"days_active\", ascending=False\n",
    ")\n",
    "if not abandoned.empty:\n",
    "    print(\"\\nRamas potencialmente abandonadas (>30 d칤as abiertas):\")\n",
    "    for _, row in abandoned.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_name']} ({row['repository']}): {row['days_active']} d칤as, autor: {row['author']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\nNo hay ramas potencialmente abandonadas.\")\n",
    "\n",
    "# Analizar patrones de creaci칩n de ramas por autor\n",
    "author_patterns = (\n",
    "    df_branches.groupby(\"author\")[\"branch_type\"].value_counts().unstack().fillna(0)\n",
    ")\n",
    "print(\"\\nPatrones de creaci칩n de ramas por autor:\")\n",
    "print(author_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e785e2",
   "metadata": {},
   "source": [
    "### Frecuencia de Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar solo PRs que fueron mergeados\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "\n",
    "# Convertir fechas a datetime si no lo est치n ya\n",
    "merged_prs[\"merge_date\"] = pd.to_datetime(merged_prs[\"updated_on\"]).dt.date\n",
    "\n",
    "# An치lisis de merges por autor\n",
    "merges_by_author = merged_prs.groupby(\"author\").size().sort_values(ascending=False)\n",
    "merges_by_author.name = \"total_merges\"\n",
    "\n",
    "# An치lisis temporal: merges por semana por autor\n",
    "merged_prs[\"merge_week\"] = pd.to_datetime(merged_prs[\"updated_on\"]).dt.strftime(\"%Y-%U\")\n",
    "weekly_merges = (\n",
    "    merged_prs.groupby([\"author\", \"merge_week\"]).size().reset_index(name=\"merges\")\n",
    ")\n",
    "avg_weekly_merges = (\n",
    "    weekly_merges.groupby(\"author\")[\"merges\"].mean().sort_values(ascending=False)\n",
    ")\n",
    "avg_weekly_merges.name = \"avg_weekly_merges\"\n",
    "\n",
    "# Merges por repositorio\n",
    "merges_by_repo_author = (\n",
    "    merged_prs.groupby([\"author\", \"repository\"]).size().unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Crear un DataFrame de resumen\n",
    "merge_stats = pd.DataFrame(\n",
    "    {\"Total Merges\": merges_by_author, \"Promedio Semanal\": avg_weekly_merges}\n",
    ").reset_index()\n",
    "merge_stats = merge_stats.sort_values(\"Total Merges\", ascending=False)\n",
    "\n",
    "# Visualizaci칩n: Gr치fico de barras para total de merges por autor\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    merge_stats[\"author\"], merge_stats[\"Total Merges\"], color=\"cornflowerblue\"\n",
    ")\n",
    "\n",
    "# Agregar etiquetas de valor sobre cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Cantidad de Merges por Desarrollador\", fontsize=15)\n",
    "plt.xlabel(\"Desarrollador\", fontsize=12)\n",
    "plt.ylabel(\"N칰mero de Merges\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizaci칩n: Gr치fico de l칤neas para evoluci칩n temporal de merges\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Crear un DataFrame pivotado para visualizar merges por semana\n",
    "weekly_pivot = weekly_merges.pivot(\n",
    "    index=\"merge_week\", columns=\"author\", values=\"merges\"\n",
    ").fillna(0)\n",
    "\n",
    "# Asegurar que tenemos todas las semanas en el rango\n",
    "all_weeks = (\n",
    "    pd.date_range(\n",
    "        start=merged_prs[\"updated_on\"].min().date(),\n",
    "        end=merged_prs[\"updated_on\"].max().date(),\n",
    "        freq=\"W\",\n",
    "    )\n",
    "    .strftime(\"%Y-%U\")\n",
    "    .tolist()\n",
    ")\n",
    "weekly_pivot = weekly_pivot.reindex(all_weeks, fill_value=0)\n",
    "\n",
    "# Graficar la evoluci칩n temporal\n",
    "weekly_pivot.plot(marker=\"o\")\n",
    "plt.title(\"Evoluci칩n de Merges por Semana por Desarrollador\", fontsize=15)\n",
    "plt.xlabel(\"Semana\", fontsize=12)\n",
    "plt.ylabel(\"N칰mero de Merges\", fontsize=12)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizaci칩n: Gr치fico de calor para merges por repositorio\n",
    "plt.figure(figsize=(11, 7))\n",
    "sns.heatmap(merges_by_repo_author, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Merges por Desarrollador y Repositorio\", fontsize=15)\n",
    "plt.ylabel(\"Desarrollador\", fontsize=12)\n",
    "plt.xlabel(\"Repositorio\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad칤sticas de frecuencia de merges\n",
    "print(\"\\n===== AN츼LISIS DE FRECUENCIA DE MERGES =====\")\n",
    "print(f\"Total de PRs mergeados: {len(merged_prs)}\")\n",
    "print(\"\\nFrequencia de merges por desarrollador:\")\n",
    "for _, row in merge_stats.iterrows():\n",
    "    print(\n",
    "        f\"- {row['author']}: {int(row['Total Merges'])} merges totales, {row['Promedio Semanal']:.1f} merges por semana\"\n",
    "    )\n",
    "\n",
    "# Calcular tiempo promedio entre merges por desarrollador\n",
    "developer_merge_gaps = {}\n",
    "for author in merged_prs[\"author\"].unique():\n",
    "    author_prs = merged_prs[merged_prs[\"author\"] == author].sort_values(\"updated_on\")\n",
    "    if len(author_prs) > 1:\n",
    "        gaps = []\n",
    "        for i in range(1, len(author_prs)):\n",
    "            gap = (\n",
    "                author_prs.iloc[i][\"updated_on\"] - author_prs.iloc[i - 1][\"updated_on\"]\n",
    "            ).total_seconds() / 86400  # d칤as\n",
    "            gaps.append(gap)\n",
    "        developer_merge_gaps[author] = np.mean(gaps)\n",
    "\n",
    "if developer_merge_gaps:\n",
    "    print(\"\\nTiempo promedio entre merges consecutivos:\")\n",
    "    for author, avg_days in sorted(developer_merge_gaps.items(), key=lambda x: x[1]):\n",
    "        print(f\"- {author}: {avg_days:.1f} d칤as\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
