{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "280a8149",
   "metadata": {},
   "source": [
    "# Proyectos bitbucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205ddc3",
   "metadata": {},
   "source": [
    "## üì¶Obtener los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a631e",
   "metadata": {},
   "source": [
    "#### Repositorios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3bbc1",
   "metadata": {},
   "source": [
    "Consultar los repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Configura tus credenciales\n",
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"BITBUCKET_USERNAME\")\n",
    "app_password = os.getenv(\"BITBUCKET_APP_PASSWORD\")\n",
    "workspace = os.getenv(\"BITBUCKET_WORKSPACE\")\n",
    "\n",
    "\n",
    "url_repos = f\"https://api.bitbucket.org/2.0/repositories/{workspace}\"\n",
    "\n",
    "response = requests.get(url_repos, auth=(username, app_password))\n",
    "\n",
    "if response.status_code == 200:\n",
    "    repositorios = response.json()\n",
    "    print(f\"Repositorios en {workspace}:\")\n",
    "    repos_data = []\n",
    "    for repo in repositorios.get(\"values\", []):\n",
    "        repos_data.append(\n",
    "            {\n",
    "                \"Nombre\": repo.get(\"name\"),\n",
    "                \"URL\": repo.get(\"links\", {}).get(\"html\", {}).get(\"href\"),\n",
    "            }\n",
    "        )\n",
    "    repos_df = pd.DataFrame(repos_data)\n",
    "    repos_df = repos_df.sort_values(\n",
    "        by=\"Nombre\"\n",
    "    )  # Ordenar por nombre del repositorio en ascendente\n",
    "    # print(repos_df)\n",
    "else:\n",
    "    print(\"Error al obtener repositorios:\", response.status_code, response.text)\n",
    "\n",
    "# Almacenar los repositorios en una variable para uso posterior\n",
    "repositorios = [\n",
    "    repo[\"Nombre\"]\n",
    "    for repo in repos_data\n",
    "    if repo[\"Nombre\"] not in [\"pgp\", \"Pruebas_erp\", \"Inventario\", \"b2c\", \"efi\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f3c4e",
   "metadata": {},
   "source": [
    "Listado de repositorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaf0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_df = pd.DataFrame(repositorios, columns=[\"Repositorio\"])\n",
    "display(repos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573fe9b",
   "metadata": {},
   "source": [
    "#### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener todos los elementos paginados\n",
    "def get_all_items(url, params=None):\n",
    "    items = []\n",
    "    response = requests.get(url, params=params, auth=(username, app_password))\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return items\n",
    "    data = response.json()\n",
    "    items.extend(data.get(\"values\", []))\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50436680",
   "metadata": {},
   "source": [
    "#### Pull requests y commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3529fef7",
   "metadata": {},
   "source": [
    "Consultar todos los estados de PR's.\n",
    "\n",
    "Filtrar 50 registros por p√°ginas, 3 p√°ginas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba4b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_paginas = 4\n",
    "registros_por_pagina = 50  # Creo que no soporta m√°s de 50 registros por p√°gina\n",
    "\n",
    "# Obtener pull requests\n",
    "pull_requests = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests\"\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        pull_requests.extend(\n",
    "            get_all_items(\n",
    "                pr_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina, \"state\": \"ALL\"},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo pull requests, repositorio: '{repo_slug}' - p√°gina: {page}\")\n",
    "\n",
    "print(f\"‚úÖTotal de pull requests: {len(pull_requests)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f619f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener commits\n",
    "commits = []\n",
    "\n",
    "for repo_slug in repositorios:\n",
    "    # for repo_slug in [\"fip\", \"b2b\"]:\n",
    "    commits_url = (\n",
    "        f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/commits\"\n",
    "    )\n",
    "    for page in range(1, cantidad_paginas + 1):\n",
    "        commits.extend(\n",
    "            get_all_items(\n",
    "                commits_url,\n",
    "                params={\"page\": page, \"pagelen\": registros_por_pagina},\n",
    "            )\n",
    "        )\n",
    "        print(f\"Obteniendo commits, repositorio: '{repo_slug}' - p√°gina: {page}\")\n",
    "\n",
    "print(f\"‚úÖTotal de commits: {len(commits)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6718731",
   "metadata": {},
   "source": [
    "Filtrar registros de m√°s de 120 d√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d64cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_dias = 120\n",
    "\n",
    "\n",
    "print(f\"\\nTotal pull requests: {len(pull_requests)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "pull_requests = [\n",
    "    pr for pr in pull_requests if pd.to_datetime(pr[\"created_on\"]) >= fecha_limite\n",
    "]\n",
    "print(f\"Registros de los √∫ltimos {cantidad_dias} d√≠as: {len(pull_requests)}\\n\")\n",
    "\n",
    "\n",
    "print(f\"\\nTotal commits: {len(commits)}\")\n",
    "fecha_limite = pd.Timestamp.now(tz=\"America/Bogota\") - pd.Timedelta(days=cantidad_dias)\n",
    "commits = [\n",
    "    commit\n",
    "    for commit in commits\n",
    "    if pd.to_datetime(commit[\"date\"]) >= fecha_limite\n",
    "    # and \"Resolve:\" in commit.get(\"message\", \"\")\n",
    "]\n",
    "print(\n",
    "    f\"Registros de los √∫ltimos {cantidad_dias} d√≠as y con 'Resolve:' en el mensaje: {len(commits)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0cab1",
   "metadata": {},
   "source": [
    "Limpiar **pull requests**:\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40846f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr in pull_requests:\n",
    "    if \"author\" in pr and \"nickname\" in pr[\"author\"]:\n",
    "        pr[\"author\"] = pr[\"author\"][\"nickname\"]\n",
    "    if \"source\" in pr and \"branch\" in pr[\"source\"] and \"name\" in pr[\"source\"][\"branch\"]:\n",
    "        pr[\"branch\"] = pr[\"source\"][\"branch\"][\"name\"]\n",
    "        pr[\"type_branch\"] = (\n",
    "            pr[\"branch\"].split(\"/\")[0] if \"/\" in pr[\"branch\"] else \"unknown\"\n",
    "        )\n",
    "    if (\n",
    "        \"source\" in pr\n",
    "        and \"repository\" in pr[\"source\"]\n",
    "        and \"name\" in pr[\"source\"][\"repository\"]\n",
    "    ):\n",
    "        pr[\"repository\"] = pr[\"source\"][\"repository\"][\"name\"]\n",
    "    if pr.get(\"merge_commit\") and \"hash\" in pr[\"merge_commit\"]:\n",
    "        pr[\"merge_commit\"] = pr[\"merge_commit\"][\"hash\"]\n",
    "\n",
    "    # Calculate days_open based on the PR state\n",
    "    if \"state\" in pr and \"created_on\" in pr:\n",
    "        created_on = pd.to_datetime(pr[\"created_on\"])\n",
    "        if pr[\"state\"] == \"OPEN\":\n",
    "            # For open PRs: days between created_on and now\n",
    "            days_open = (\n",
    "                pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        elif pr[\"state\"] == \"MERGED\" and \"updated_on\" in pr:\n",
    "            # For merged PRs: days between created_on and updated_on\n",
    "            updated_on = pd.to_datetime(pr[\"updated_on\"])\n",
    "            days_open = (\n",
    "                updated_on.tz_convert(\"America/Bogota\")\n",
    "                - created_on.tz_convert(\"America/Bogota\")\n",
    "            ).days\n",
    "        else:\n",
    "            days_open = 0\n",
    "        pr[\"days_open\"] = days_open\n",
    "\n",
    "\n",
    "df_pr = pd.DataFrame(pull_requests)\n",
    "\n",
    "print(pull_requests[0])\n",
    "\n",
    "# Sort by created_on in descending order to show most recent records first\n",
    "df_pr = df_pr.sort_values(by=\"created_on\", ascending=False)\n",
    "\n",
    "# Eliminar columnas innecesarias\n",
    "# df_pr = df_pr.drop(\n",
    "#     columns=[\n",
    "#         \"type\",\n",
    "#         \"title\",\n",
    "#         \"description\",\n",
    "#         \"reason\",\n",
    "#         \"destination\",\n",
    "#         \"summary\",\n",
    "#         \"closed_by\",\n",
    "#         \"links\",\n",
    "#         \"source\",\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f82a69",
   "metadata": {},
   "source": [
    "Limpiar **commits**\n",
    "\n",
    "- Agrega campos nuevos\n",
    "- Elimina campos sin uso\n",
    "- Ordena por created_on DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e52ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cm in commits:\n",
    "    # Extract author name from nested dictionary\n",
    "    if \"author\" in cm and \"user\" in cm[\"author\"] and \"nickname\" in cm[\"author\"][\"user\"]:\n",
    "        cm[\"author\"] = cm[\"author\"][\"user\"][\"nickname\"]\n",
    "    if \"repository\" in cm and \"name\" in cm[\"repository\"]:\n",
    "        cm[\"repository\"] = cm[\"repository\"][\"name\"]\n",
    "\n",
    "\n",
    "df_commits = pd.DataFrame(commits)\n",
    "\n",
    "\n",
    "# Sort by date in descending order to show most recent records first\n",
    "df_commits = df_commits.sort_values(by=\"date\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e0bbd",
   "metadata": {},
   "source": [
    "Imprimir **pull requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb85e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_pr))\n",
    "print(f\"Cantidad de registros: {len(df_pr)}\")\n",
    "display(df_pr.head(3))\n",
    "# display(df_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0343ec",
   "metadata": {},
   "source": [
    "Imprimir **commits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef10544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(df_commits))\n",
    "print(f\"Cantidad de registros: {len(df_commits)}\")\n",
    "display(df_commits.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b2302",
   "metadata": {},
   "source": [
    "## üìàReportes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c351d6",
   "metadata": {},
   "source": [
    "### 1. Actividad de commits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c9094",
   "metadata": {},
   "source": [
    "#### Procesar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1982794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install matplotlib if needed\n",
    "%pip install matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to import seaborn\n",
    "try:\n",
    "    import seaborn as sns\n",
    "\n",
    "    has_seaborn = True\n",
    "except ImportError:\n",
    "    has_seaborn = False\n",
    "    print(\"Seaborn no instalado. Algunas visualizaciones ser√°n simplificadas.\")\n",
    "\n",
    "# Make sure author is a string, not a dictionary\n",
    "df_commits[\"author\"] = df_commits[\"author\"].astype(str)\n",
    "\n",
    "# Convert date to datetime\n",
    "df_commits[\"date\"] = pd.to_datetime(df_commits[\"date\"])\n",
    "\n",
    "# Extract time periods\n",
    "df_commits[\"day\"] = df_commits[\"date\"].dt.date\n",
    "df_commits[\"week\"] = df_commits[\"date\"].dt.isocalendar().week\n",
    "df_commits[\"month\"] = df_commits[\"date\"].dt.month\n",
    "df_commits[\"year\"] = df_commits[\"date\"].dt.year\n",
    "\n",
    "# Create year-month field\n",
    "df_commits[\"year_month\"] = df_commits[\"date\"].dt.strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dbf813",
   "metadata": {},
   "source": [
    "#### An√°lisis de actividad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5ccce",
   "metadata": {},
   "source": [
    "### 3. Pull Requests (PR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2bec7",
   "metadata": {},
   "source": [
    "#### 3.1 Cantidades y tiempos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2df90e",
   "metadata": {},
   "source": [
    "##### Procesar los datos y graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da054156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import datetime\n",
    "\n",
    "# An√°lisis de Pull Requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar los estados disponibles en los PRs\n",
    "pr_states = df_pr[\"state\"].value_counts().reset_index()\n",
    "pr_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# Analizar PR por autor\n",
    "pr_by_author = df_pr.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"MERGED\" in pr_by_author.columns:\n",
    "    pr_by_author[\"total\"] = pr_by_author.sum(axis=1)\n",
    "    pr_by_author = pr_by_author.sort_values(\"total\", ascending=False)\n",
    "    pr_by_author = pr_by_author.drop(columns=[\"total\"])\n",
    "\n",
    "# Calcular tiempos promedio\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "df_pr[\"updated_on\"] = pd.to_datetime(df_pr[\"updated_on\"])\n",
    "\n",
    "# M√©tricas de tiempo para PRs cerrados/mergeados\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "if not merged_prs.empty:\n",
    "    merged_prs[\"time_to_merge_days\"] = (\n",
    "        merged_prs[\"updated_on\"] - merged_prs[\"created_on\"]\n",
    "    ).dt.total_seconds() / 86400\n",
    "    avg_merge_time = merged_prs[\"time_to_merge_days\"].mean()\n",
    "    median_merge_time = merged_prs[\"time_to_merge_days\"].median()\n",
    "    max_merge_time = merged_prs[\"time_to_merge_days\"].max()\n",
    "\n",
    "# Extraer tipos de ramas de los PRs\n",
    "branch_types = df_pr[\"type_branch\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# üìà 1. Estado de los PRs\n",
    "axes[0, 0].bar(pr_states[\"Estado\"], pr_states[\"Cantidad\"], color=\"skyblue\")\n",
    "axes[0, 0].set_title(\"Estado de Pull Requests\")\n",
    "axes[0, 0].set_xlabel(\"Estado\")\n",
    "axes[0, 0].set_ylabel(\"Cantidad\")\n",
    "\n",
    "# üìà 2. PRs por autor\n",
    "pr_by_author.plot(kind=\"bar\", stacked=True, ax=axes[0, 1])\n",
    "axes[0, 1].set_title(\"Pull Requests por Autor\")\n",
    "axes[0, 1].set_xlabel(\"Autor\")\n",
    "axes[0, 1].set_ylabel(\"Cantidad\")\n",
    "axes[0, 1].legend(title=\"Estado\")\n",
    "\n",
    "\n",
    "# üìà 3. Tiempo de resoluci√≥n de PRs\n",
    "if not merged_prs.empty:\n",
    "    merged_prs.boxplot(column=\"time_to_merge_days\", ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Tiempo para Merge (d√≠as)\")\n",
    "    axes[1, 0].set_ylabel(\"D√≠as\")\n",
    "\n",
    "    # A√±adir una l√≠nea para el promedio\n",
    "    axes[1, 0].axhline(\n",
    "        y=avg_merge_time,\n",
    "        color=\"red\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Promedio: {avg_merge_time:.1f} d√≠as\",\n",
    "    )\n",
    "    axes[1, 0].legend()\n",
    "\n",
    "# üìà 4. Tipos de ramas\n",
    "axes[1, 1].pie(branch_types[\"Cantidad\"], labels=branch_types[\"Tipo\"], autopct=\"%1.1f%%\")\n",
    "axes[1, 1].set_title(\"Distribuci√≥n de Tipos de Ramas\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# M√©tricas adicionales\n",
    "print(\"\\n=== M√©tricas de Pull Requests ===\")\n",
    "print(f\"Total de PRs analizados: {len(df_pr)}\")\n",
    "print(f\"PRs por estado: {dict(pr_states.values)}\")\n",
    "if not merged_prs.empty:\n",
    "    print(f\"\\nTiempo promedio hasta merge: {avg_merge_time:.1f} d√≠as\")\n",
    "    print(f\"Tiempo mediano hasta merge: {median_merge_time:.1f} d√≠as\")\n",
    "    print(f\"Tiempo m√°ximo hasta merge: {max_merge_time:.1f} d√≠as\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# üìä An√°lisis de eficiencia de PRs\n",
    "if not merged_prs.empty:\n",
    "    author_efficiency = (\n",
    "        merged_prs.groupby(\"author\")[\"time_to_merge_days\"]\n",
    "        .agg([\"mean\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    author_efficiency.columns = [\"Tiempo promedio (d√≠as)\", \"PRs mergeados\"]\n",
    "\n",
    "    # Crear tres gr√°ficas para visualizar la eficiencia de los autores\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # üìà Gr√°fica 1: Tiempo promedio hasta merge\n",
    "    author_efficiency[\"Tiempo promedio (d√≠as)\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"skyblue\",\n",
    "        ax=ax1,\n",
    "        title=\"Tiempo promedio hasta merge por autor\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"Autor\")\n",
    "    ax1.set_ylabel(\"D√≠as\")\n",
    "    for i, v in enumerate(author_efficiency[\"Tiempo promedio (d√≠as)\"]):\n",
    "        ax1.text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # üìà Gr√°fica 2: Cantidad de PRs mergeados\n",
    "    author_efficiency[\"PRs mergeados\"].plot(\n",
    "        kind=\"bar\",\n",
    "        color=\"lightgreen\",\n",
    "        ax=ax2,\n",
    "        title=\"Cantidad de PRs mergeados por autor\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"Autor\")\n",
    "    ax2.set_ylabel(\"Cantidad\")\n",
    "    for i, v in enumerate(author_efficiency[\"PRs mergeados\"]):\n",
    "        ax2.text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "    # üìà Gr√°fica 3: Eficiencia general de los autores\n",
    "    scatter = ax3.scatter(\n",
    "        author_efficiency[\"Tiempo promedio (d√≠as)\"],\n",
    "        author_efficiency[\"PRs mergeados\"],\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        c=author_efficiency[\"Tiempo promedio (d√≠as)\"],\n",
    "        cmap=\"coolwarm_r\",\n",
    "    )\n",
    "\n",
    "    # A√±adir etiquetas a cada punto\n",
    "    for i, author in enumerate(author_efficiency.index):\n",
    "        ax3.annotate(\n",
    "            author,\n",
    "            (\n",
    "                author_efficiency[\"Tiempo promedio (d√≠as)\"][i],\n",
    "                author_efficiency[\"PRs mergeados\"][i],\n",
    "            ),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "        )\n",
    "\n",
    "    ax3.set_title(\"Eficiencia de autores\")\n",
    "    ax3.set_xlabel(\"Tiempo promedio (d√≠as)\")\n",
    "    ax3.set_ylabel(\"PRs mergeados\")\n",
    "    ax3.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # A√±adir colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax3)\n",
    "    cbar.set_label(\"Tiempo promedio (d√≠as)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n=== Eficiencia de autores (tiempo promedio hasta merge) ===\")\n",
    "    print(author_efficiency.to_string(float_format=lambda x: f\"{x:.1f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e885a0",
   "metadata": {},
   "source": [
    "#### 3.2 Comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff35cd",
   "metadata": {},
   "source": [
    "##### PRs m√°s largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55a5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar PRs con tiempos de revisi√≥n largos y comentarios numerosos\n",
    "if \"comment_count\" in df_pr.columns:\n",
    "    high_discussion = df_pr.sort_values(\"comment_count\", ascending=False).head(5)\n",
    "    print(\"\\n=== PRs con m√°s discusi√≥n (mayor n√∫mero de comentarios) ===\")\n",
    "    high_discussion[\"formatted_date\"] = high_discussion[\"created_on\"].dt.strftime(\n",
    "        \"%d-%m-%Y\"\n",
    "    )\n",
    "    print(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"T√≠tulo\": high_discussion[\"title\"],\n",
    "                \"Autor\": high_discussion[\"author\"],\n",
    "                \"Comentarios\": high_discussion[\"comment_count\"],\n",
    "                \"Estado\": high_discussion[\"state\"],\n",
    "                \"Fecha\": high_discussion[\"formatted_date\"],\n",
    "            }\n",
    "        ).to_string()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abb76a",
   "metadata": {},
   "source": [
    "##### Procesar los datos (primeras 3 gr√°ficas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Par√°metro configurable: n√∫mero de d√≠as a analizar\n",
    "num_days_to_analyze = 30\n",
    "# Calcular fecha l√≠mite\n",
    "today = pd.Timestamp.now(tz=\"America/Bogota\")\n",
    "date_limit = today - pd.Timedelta(days=num_days_to_analyze)\n",
    "\n",
    "# Asegurar que la columna de fecha est√° en el formato correcto\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "\n",
    "# Filtrar PRs por fecha\n",
    "recent_prs = df_pr[df_pr[\"created_on\"] >= date_limit]\n",
    "\n",
    "# Crear una lista de todas las fechas en el rango analizado\n",
    "date_range = pd.date_range(start=date_limit, end=today, freq=\"D\")\n",
    "date_range = [d.date() for d in date_range]\n",
    "\n",
    "# Contar PRs por d√≠a\n",
    "prs_by_day = recent_prs.groupby(recent_prs[\"created_on\"].dt.date).size()\n",
    "\n",
    "# Asegurar que tenemos todas las fechas (incluso las que no tienen PRs)\n",
    "prs_by_day = prs_by_day.reindex(date_range, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74e6b5c",
   "metadata": {},
   "source": [
    "##### Graficar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37582fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# üìà 1. Gr√°fico general de PRs por d√≠a\n",
    "plt.figure(figsize=(12, 6))\n",
    "prs_by_day.plot(kind=\"bar\", color=\"cornflowerblue\")\n",
    "plt.title(f\"PRs creados por d√≠a (√∫ltimos {num_days_to_analyze} d√≠as)\", fontsize=14)\n",
    "plt.xlabel(\"Fecha\", fontsize=12)\n",
    "plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "\n",
    "# A√±adir etiquetas de valor sobre cada barra\n",
    "for i, value in enumerate(prs_by_day):\n",
    "    if value > 0:\n",
    "        plt.text(i, value + 0.1, str(int(value)), ha=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# üìà 2. Gr√°ficos individuales por desarrollador\n",
    "# Obtener lista de desarrolladores\n",
    "developers = recent_prs[\"author\"].unique()\n",
    "\n",
    "for dev in developers:\n",
    "    # Filtrar PRs de este desarrollador\n",
    "    dev_prs = recent_prs[recent_prs[\"author\"] == dev]\n",
    "\n",
    "    # Contar PRs por d√≠a para este desarrollador\n",
    "    dev_prs_by_day = dev_prs.groupby(dev_prs[\"created_on\"].dt.date).size()\n",
    "\n",
    "    # Asegurar que tenemos todas las fechas (incluso las que no tienen PRs)\n",
    "    dev_prs_by_day = dev_prs_by_day.reindex(date_range, fill_value=0)\n",
    "\n",
    "    # Crear gr√°fico para este desarrollador\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    ax = dev_prs_by_day.plot(kind=\"bar\", color=\"lightseagreen\")\n",
    "    plt.title(\n",
    "        f\"PRs creados por {dev} (√∫ltimos {num_days_to_analyze} d√≠as)\", fontsize=14\n",
    "    )\n",
    "    plt.xlabel(\"Fecha\", fontsize=12)\n",
    "    plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "\n",
    "    # A√±adir etiquetas de valor sobre cada barra\n",
    "    for i, value in enumerate(dev_prs_by_day):\n",
    "        if value > 0:\n",
    "            plt.text(i, value + 0.05, str(int(value)), ha=\"center\")\n",
    "\n",
    "    # A√±adir informaci√≥n adicional\n",
    "    total_prs = dev_prs_by_day.sum()\n",
    "    avg_prs = dev_prs_by_day.mean()\n",
    "    plt.figtext(\n",
    "        0.5,\n",
    "        0.01,\n",
    "        f\"Total: {int(total_prs)} PRs | Promedio: {avg_prs:.2f} PRs/d√≠a\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "        bbox={\"facecolor\": \"lightgray\", \"alpha\": 0.5, \"pad\": 5},\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# üìà 3. Gr√°fico comparativo entre desarrolladores\n",
    "dev_comparison = pd.DataFrame(\n",
    "    {\n",
    "        \"Desarrollador\": developers,\n",
    "        \"Total PRs\": [\n",
    "            len(recent_prs[recent_prs[\"author\"] == dev]) for dev in developers\n",
    "        ],\n",
    "    }\n",
    ").sort_values(\"Total PRs\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    dev_comparison[\"Desarrollador\"], dev_comparison[\"Total PRs\"], color=\"teal\"\n",
    ")\n",
    "\n",
    "# A√±adir etiquetas de valor sobre cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "plt.title(\n",
    "    f\"Comparaci√≥n de PRs creados por desarrollador (√∫ltimos {num_days_to_analyze} d√≠as)\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plt.ylabel(\"Cantidad de PRs\", fontsize=12)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Define the number of PRs to display per author\n",
    "num_prs_to_display = num_days_to_analyze  # This can be changed to any value as needed\n",
    "\n",
    "# Filtrar los √∫ltimos PRs para cada autor (basado en la variable)\n",
    "author_prs = {}\n",
    "for author in df_pr[\"author\"].unique():\n",
    "    # Obtener los √∫ltimos N PRs de este autor\n",
    "    latest_prs = (\n",
    "        df_pr[df_pr[\"author\"] == author]\n",
    "        .sort_values(\"created_on\", ascending=False)\n",
    "        .head(num_prs_to_display)\n",
    "    )\n",
    "\n",
    "    if not latest_prs.empty:\n",
    "        author_prs[author] = latest_prs\n",
    "\n",
    "# Crear una figura para cada autor\n",
    "for author, prs in author_prs.items():\n",
    "    # Configurar el gr√°fico para este autor\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Preparar datos para este autor\n",
    "    comment_counts = []\n",
    "    pr_titles = []\n",
    "    actual_count = min(len(prs), num_prs_to_display)\n",
    "\n",
    "    # Obtener datos para las barras\n",
    "    for j in range(actual_count):\n",
    "        comment_counts.append(prs.iloc[j][\"comment_count\"])\n",
    "        pr_titles.append(f\"{j + 1}\")\n",
    "\n",
    "    # Crear posiciones para las barras\n",
    "    positions = np.arange(len(comment_counts))\n",
    "\n",
    "    # Graficar barras para este autor\n",
    "    bars = ax.bar(positions, comment_counts, color=\"skyblue\", width=0.7)\n",
    "\n",
    "    # A√±adir etiquetas con el n√∫mero de comentarios encima de cada barra\n",
    "    for bar, count in zip(bars, comment_counts):\n",
    "        if count > 0:\n",
    "            height = bar.get_height()\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height + 0.3,\n",
    "                str(int(count)),\n",
    "                ha=\"center\",\n",
    "                fontsize=9,\n",
    "            )\n",
    "\n",
    "    # Configuraci√≥n adicional del gr√°fico\n",
    "    ax.set_title(\n",
    "        f\"Comentarios en los √öltimos {actual_count} PRs de {author}\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "    ax.set_xlabel(\n",
    "        \"N√∫mero de PR (del m√°s reciente al m√°s antiguo)\",\n",
    "        fontsize=12,\n",
    "    )\n",
    "    ax.set_ylabel(\"N√∫mero de Comentarios\", fontsize=12)\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(pr_titles)\n",
    "\n",
    "    # A√±adir una referencia al n√∫mero de ticket y estado en la parte inferior\n",
    "    if actual_count > 0:\n",
    "        ticket_info = []\n",
    "        for j in range(actual_count):\n",
    "            pr = prs.iloc[j]\n",
    "            # Extraer el c√≥digo del ticket (BTB-XXX) del t√≠tulo si existe\n",
    "            title = pr[\"title\"]\n",
    "            ticket_code = \"\"\n",
    "            import re\n",
    "\n",
    "            match = re.search(r\"\\(([A-Z]+-\\d+)\\)\", title) or re.search(\n",
    "                r\"\\s([A-Z]+-\\d+)\", title\n",
    "            )\n",
    "            if match:\n",
    "                ticket_code = match.group(1)\n",
    "            else:\n",
    "                # Intentar extraer cualquier c√≥digo con formato BTB-XXX\n",
    "                match = re.search(r\"([A-Z]+-\\d+)\", title)\n",
    "                if match:\n",
    "                    ticket_code = match.group(1)\n",
    "\n",
    "            state_info = f\"[{pr['state']}]\"\n",
    "            ticket_info.append(f\"{ticket_code} {state_info}\")\n",
    "\n",
    "        # A√±adir anotaciones con informaci√≥n del ticket\n",
    "        plt.figtext(\n",
    "            0.5,\n",
    "            0.01,\n",
    "            \"Tickets de referencia (del m√°s reciente): \"\n",
    "            + \" | \".join(ticket_info[:5])\n",
    "            + (\"...\" if len(ticket_info) > 5 else \"\"),\n",
    "            ha=\"center\",\n",
    "            fontsize=8,\n",
    "            wrap=True,\n",
    "        )\n",
    "\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout(\n",
    "        rect=[0, 0.05, 1, 0.95]\n",
    "    )  # Dejar espacio para la anotaci√≥n inferior\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "# üìà Crear gr√°fica comparativa del promedio de comentarios por PR por autor\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Calcular el promedio de comentarios por autor\n",
    "avg_comments_by_author = {}\n",
    "for author, prs in author_prs.items():\n",
    "    avg_comments = prs[\"comment_count\"].mean()\n",
    "    avg_comments_by_author[author] = avg_comments\n",
    "\n",
    "# Ordenar los autores por promedio de comentarios (descendente)\n",
    "sorted_authors = sorted(\n",
    "    avg_comments_by_author.items(), key=lambda x: x[1], reverse=True\n",
    ")\n",
    "authors = [item[0] for item in sorted_authors]\n",
    "avg_values = [item[1] for item in sorted_authors]\n",
    "\n",
    "# Crear barras\n",
    "positions = np.arange(len(authors))\n",
    "bars = plt.bar(positions, avg_values, color=\"teal\", width=0.6)\n",
    "\n",
    "# A√±adir etiquetas con el valor promedio\n",
    "for bar, value in zip(bars, avg_values):\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{value:.1f}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Configurar gr√°fico\n",
    "plt.title(\"Promedio de Comentarios por PR por Autor\", fontsize=16)\n",
    "plt.xlabel(\"Autor\", fontsize=14)\n",
    "plt.ylabel(\"Promedio de Comentarios\", fontsize=14)\n",
    "plt.xticks(positions, authors, rotation=45, ha=\"right\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e3683",
   "metadata": {},
   "source": [
    "### 4. Revisi√≥n de C√≥digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1530b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analizar la calidad de revisi√≥n de c√≥digo basado en los datos de PR\n",
    "# Extraer datos de comentarios, aprobaciones y estados\n",
    "\n",
    "# 1. An√°lisis de comentarios y revisiones por PR\n",
    "comment_analysis = df_pr[\n",
    "    [\"author\", \"comment_count\", \"state\", \"repository\", \"days_open\"]\n",
    "]\n",
    "\n",
    "# 2. Estad√≠sticas de comentarios por estado y repo\n",
    "comments_by_state = comment_analysis.groupby(\"state\")[\"comment_count\"].agg(\n",
    "    [\"mean\", \"median\", \"sum\", \"count\"]\n",
    ")\n",
    "comments_by_repo = comment_analysis.groupby(\"repository\")[\"comment_count\"].agg(\n",
    "    [\"mean\", \"median\", \"sum\", \"count\"]\n",
    ")\n",
    "\n",
    "# 3. Identificar PRs con comentarios vs sin comentarios\n",
    "comment_analysis[\"has_comments\"] = comment_analysis[\"comment_count\"] > 0\n",
    "comments_percentage = comment_analysis[\"has_comments\"].mean() * 100\n",
    "\n",
    "# 4. An√°lisis por autor (qui√©n recibe m√°s comentarios)\n",
    "author_comments = comment_analysis.groupby(\"author\").agg(\n",
    "    {\"comment_count\": [\"mean\", \"sum\", \"count\"], \"has_comments\": \"mean\"}\n",
    ")\n",
    "author_comments.columns = [\n",
    "    \"avg_comments\",\n",
    "    \"total_comments\",\n",
    "    \"total_prs\",\n",
    "    \"pct_prs_with_comments\",\n",
    "]\n",
    "author_comments[\"pct_prs_with_comments\"] = (\n",
    "    author_comments[\"pct_prs_with_comments\"] * 100\n",
    ")\n",
    "\n",
    "# 5. Relaci√≥n entre tiempo abierto y cantidad de comentarios\n",
    "correlation = comment_analysis[[\"days_open\", \"comment_count\"]].corr().iloc[0, 1]\n",
    "\n",
    "# Visualizaciones\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# üìà 1. Distribuci√≥n de comentarios por PR\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(comment_analysis[\"comment_count\"], kde=True, bins=10)\n",
    "plt.title(\"Distribuci√≥n de Comentarios por PR\")\n",
    "plt.xlabel(\"N√∫mero de Comentarios\")\n",
    "plt.ylabel(\"Cantidad de PRs\")\n",
    "\n",
    "# üìà 2. Comentarios promedio por autor\n",
    "plt.subplot(2, 2, 2)\n",
    "author_order = author_comments.sort_values(\"avg_comments\", ascending=False).index\n",
    "sns.barplot(x=author_comments.loc[author_order, \"avg_comments\"], y=author_order)\n",
    "plt.title(\"Comentarios Promedio por Autor\")\n",
    "plt.xlabel(\"Promedio de Comentarios\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# üìà 3. Porcentaje de PRs con comentarios por autor\n",
    "plt.subplot(2, 2, 3)\n",
    "author_order = author_comments.sort_values(\n",
    "    \"pct_prs_with_comments\", ascending=False\n",
    ").index\n",
    "bars = plt.barh(\n",
    "    author_order, author_comments.loc[author_order, \"pct_prs_with_comments\"]\n",
    ")\n",
    "plt.title(\"% de PRs con Comentarios por Autor\")\n",
    "plt.xlabel(\"Porcentaje\")\n",
    "# A√±adir etiquetas de valor a las barras\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(\n",
    "        width + 1,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{width:.1f}%\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "    )\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "# üìà 4. Relaci√≥n entre tiempo abierto y comentarios\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x=\"days_open\", y=\"comment_count\", hue=\"author\", data=comment_analysis)\n",
    "plt.title(\n",
    "    f\"Relaci√≥n entre Tiempo Abierto y Comentarios\\nCorrelaci√≥n: {correlation:.2f}\"\n",
    ")\n",
    "plt.xlabel(\"D√≠as Abierto\")\n",
    "plt.ylabel(\"N√∫mero de Comentarios\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla de estad√≠sticas\n",
    "print(\"\\n=== Estad√≠sticas de Revisi√≥n de C√≥digo ===\")\n",
    "print(f\"PRs con al menos un comentario: {comments_percentage:.1f}%\")\n",
    "print(f\"Comentarios promedio por PR: {comment_analysis['comment_count'].mean():.2f}\")\n",
    "print(\"\\nComentarios por estado de PR:\")\n",
    "print(comments_by_state)\n",
    "print(\"\\nComentarios por repositorio:\")\n",
    "print(comments_by_repo)\n",
    "\n",
    "# An√°lisis de calidad de revisi√≥n\n",
    "print(\"\\n=== An√°lisis de Calidad de Revisi√≥n ===\")\n",
    "print(\"Estad√≠sticas por autor:\")\n",
    "print(author_comments.sort_values(\"avg_comments\", ascending=False))\n",
    "\n",
    "# Identificar revisores m√°s activos (estimaci√≥n basada en comentarios)\n",
    "# Asumimos que autores que reciben comentarios tambi√©n hacen comentarios en PRs de otros\n",
    "active_reviewers = author_comments.sort_values(\"total_comments\", ascending=False)\n",
    "print(\"\\nRevisores m√°s activos (estimado):\")\n",
    "for author, row in active_reviewers.iterrows():\n",
    "    print(\n",
    "        f\"- {author}: {row['total_comments']} comentarios totales en {row['total_prs']} PRs\"\n",
    "    )\n",
    "\n",
    "# An√°lisis adicional de tiempo de respuesta y eficiencia\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"]\n",
    "if not merged_prs.empty:\n",
    "    print(f\"\\nTiempo promedio hasta merge: {merged_prs['days_open'].mean():.1f} d√≠as\")\n",
    "    print(\n",
    "        f\"PRs que recibieron comentarios: {merged_prs['comment_count'].gt(0).mean() * 100:.1f}%\"\n",
    "    )\n",
    "\n",
    "    # Analizar si los PRs con comentarios tardan m√°s en ser mergeados\n",
    "    with_comments = merged_prs[merged_prs[\"comment_count\"] > 0][\"days_open\"].mean()\n",
    "    without_comments = merged_prs[merged_prs[\"comment_count\"] == 0][\"days_open\"].mean()\n",
    "    print(f\"Tiempo promedio hasta merge (con comentarios): {with_comments:.1f} d√≠as\")\n",
    "    print(f\"Tiempo promedio hasta merge (sin comentarios): {without_comments:.1f} d√≠as\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b819596",
   "metadata": {},
   "source": [
    "### Tiempo de Revisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# An√°lisis de tiempo desde PR creada hasta merge/cierre\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Asegurar que las fechas est√°n en formato correcto\n",
    "df_pr[\"created_on\"] = pd.to_datetime(df_pr[\"created_on\"])\n",
    "df_pr[\"updated_on\"] = pd.to_datetime(df_pr[\"updated_on\"])\n",
    "\n",
    "# Filtrar PRs que han sido cerradas (merged o declined)\n",
    "closed_prs = df_pr[df_pr[\"state\"].isin([\"MERGED\", \"DECLINED\"])].copy()\n",
    "\n",
    "if not closed_prs.empty:\n",
    "    # Calcular tiempo hasta cierre para PRs cerradas\n",
    "    closed_prs[\"time_to_close_days\"] = (\n",
    "        closed_prs[\"updated_on\"] - closed_prs[\"created_on\"]\n",
    "    ).dt.total_seconds() / 86400\n",
    "\n",
    "    # Analizar por autor, repositorio y tipo de rama\n",
    "    time_by_author = (\n",
    "        closed_prs.groupby(\"author\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    time_by_repo = (\n",
    "        closed_prs.groupby(\"repository\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "    time_by_branch_type = (\n",
    "        closed_prs.groupby(\"type_branch\")[\"time_to_close_days\"]\n",
    "        .agg([\"mean\", \"median\", \"count\"])\n",
    "        .sort_values(\"mean\")\n",
    "    )\n",
    "\n",
    "    # Visualizaciones\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "    # 1. Distribuci√≥n general de tiempos de revisi√≥n\n",
    "    sns.histplot(closed_prs[\"time_to_close_days\"], bins=15, kde=True, ax=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"Distribuci√≥n de Tiempos de Revisi√≥n\")\n",
    "    axes[0, 0].set_xlabel(\"D√≠as hasta cierre\")\n",
    "    axes[0, 0].axvline(\n",
    "        closed_prs[\"time_to_close_days\"].median(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        label=f\"Mediana: {closed_prs['time_to_close_days'].median():.1f} d√≠as\",\n",
    "    )\n",
    "    axes[0, 0].axvline(\n",
    "        closed_prs[\"time_to_close_days\"].mean(),\n",
    "        color=\"green\",\n",
    "        linestyle=\"-\",\n",
    "        label=f\"Media: {closed_prs['time_to_close_days'].mean():.1f} d√≠as\",\n",
    "    )\n",
    "    axes[0, 0].legend()\n",
    "\n",
    "    # 2. Tiempo promedio por autor\n",
    "    sns.barplot(x=time_by_author.index, y=time_by_author[\"mean\"], ax=axes[0, 1])\n",
    "    axes[0, 1].set_title(\"Tiempo Promedio de Revisi√≥n por Autor\")\n",
    "    axes[0, 1].set_ylabel(\"D√≠as\")\n",
    "    axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)\n",
    "    for i, v in enumerate(time_by_author[\"mean\"]):\n",
    "        axes[0, 1].text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 3. Tiempo promedio por repositorio\n",
    "    sns.barplot(x=time_by_repo.index, y=time_by_repo[\"mean\"], ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(\"Tiempo Promedio de Revisi√≥n por Repositorio\")\n",
    "    axes[1, 0].set_ylabel(\"D√≠as\")\n",
    "    axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45)\n",
    "    for i, v in enumerate(time_by_repo[\"mean\"]):\n",
    "        axes[1, 0].text(i, v + 0.1, f\"{v:.1f}\", ha=\"center\")\n",
    "\n",
    "    # 4. Boxplot de tiempo por tipo de rama\n",
    "    sns.boxplot(x=\"type_branch\", y=\"time_to_close_days\", data=closed_prs, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Distribuci√≥n de Tiempo por Tipo de Rama\")\n",
    "    axes[1, 1].set_ylabel(\"D√≠as hasta cierre\")\n",
    "    axes[1, 1].set_xlabel(\"Tipo de rama\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # An√°lisis adicional: Correlaci√≥n entre comentarios y tiempo de revisi√≥n\n",
    "    correlation = closed_prs[[\"time_to_close_days\", \"comment_count\"]].corr().iloc[0, 1]\n",
    "\n",
    "    # Visualizar relaci√≥n entre comentarios y tiempo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x=\"comment_count\", y=\"time_to_close_days\", hue=\"author\", data=closed_prs\n",
    "    )\n",
    "    plt.title(\n",
    "        f\"Relaci√≥n entre Comentarios y Tiempo de Revisi√≥n (r = {correlation:.2f})\"\n",
    "    )\n",
    "    plt.xlabel(\"N√∫mero de Comentarios\")\n",
    "    plt.ylabel(\"D√≠as hasta cierre\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "    # Imprimir estad√≠sticas de tiempo de revisi√≥n\n",
    "    print(\"===== AN√ÅLISIS DE TIEMPO DE REVISI√ìN =====\")\n",
    "    print(\n",
    "        f\"\\nTiempo promedio global hasta cierre: {closed_prs['time_to_close_days'].mean():.1f} d√≠as\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Tiempo mediano global hasta cierre: {closed_prs['time_to_close_days'].median():.1f} d√≠as\"\n",
    "    )\n",
    "    print(\n",
    "        f\"PRs con tiempo de revisi√≥n excesivo (>7 d√≠as): {(closed_prs['time_to_close_days'] > 7).sum()} ({(closed_prs['time_to_close_days'] > 7).mean() * 100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Identificar PRs con tiempos de revisi√≥n r√°pidos vs lentos\n",
    "    fast_reviews = closed_prs[closed_prs[\"time_to_close_days\"] <= 1]\n",
    "    slow_reviews = closed_prs[closed_prs[\"time_to_close_days\"] >= 7]\n",
    "\n",
    "    print(\n",
    "        f\"\\nPRs con revisi√≥n r√°pida (‚â§1 d√≠a): {len(fast_reviews)} ({len(fast_reviews) / len(closed_prs) * 100:.1f}%)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"PRs con revisi√≥n lenta (‚â•7 d√≠as): {len(slow_reviews)} ({len(slow_reviews) / len(closed_prs) * 100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    # Analizar tendencia de tiempo de revisi√≥n a lo largo del tiempo\n",
    "    closed_prs[\"merge_month\"] = closed_prs[\"updated_on\"].dt.strftime(\"%Y-%m\")\n",
    "    time_trend = (\n",
    "        closed_prs.groupby(\"merge_month\")[\"time_to_close_days\"].mean().reset_index()\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(\n",
    "        time_trend[\"merge_month\"],\n",
    "        time_trend[\"time_to_close_days\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    plt.title(\"Tendencia de Tiempo de Revisi√≥n a lo Largo del Tiempo\")\n",
    "    plt.xlabel(\"Mes\")\n",
    "    plt.ylabel(\"Tiempo Promedio de Revisi√≥n (d√≠as)\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No hay PRs cerradas para analizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a764a",
   "metadata": {},
   "source": [
    "### Actividad en Ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3607b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# An√°lisis de Actividad en Ramas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extraer informaci√≥n de ramas de los PRs\n",
    "branches_info = []\n",
    "\n",
    "# Obtener informaci√≥n de las ramas desde los PR\n",
    "for pr in df_pr.to_dict(\"records\"):\n",
    "    # Solo procesamos si tenemos informaci√≥n de rama\n",
    "    if \"branch\" in pr and \"type_branch\" in pr:\n",
    "        # Extraer tipo de rama (feature, bugfix, etc)\n",
    "        branch_type = pr[\"type_branch\"]\n",
    "        # Nombre de la rama\n",
    "        branch_name = pr[\"branch\"]\n",
    "        # Repositorio\n",
    "        repo = pr[\"repository\"]\n",
    "        # Fecha de creaci√≥n (estimada desde la PR)\n",
    "        created_date = pr[\"created_on\"]\n",
    "        # Fecha de cierre (si est√° cerrada)\n",
    "        closed_date = pr[\"updated_on\"] if pr[\"state\"] != \"OPEN\" else None\n",
    "        # Estado actual\n",
    "        state = pr[\"state\"]\n",
    "        # Autor de la rama (asumimos que es el mismo que el de la PR)\n",
    "        author = pr[\"author\"]\n",
    "\n",
    "        # Agregar a la lista\n",
    "        branches_info.append(\n",
    "            {\n",
    "                \"branch_name\": branch_name,\n",
    "                \"branch_type\": branch_type,\n",
    "                \"repository\": repo,\n",
    "                \"author\": author,\n",
    "                \"created_date\": created_date,\n",
    "                \"closed_date\": closed_date,\n",
    "                \"state\": state,\n",
    "                \"days_active\": (pd.Timestamp.now(tz=\"UTC\") - created_date).days\n",
    "                if state == \"OPEN\"\n",
    "                else (closed_date - created_date).days\n",
    "                if closed_date\n",
    "                else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Crear DataFrame con la informaci√≥n de ramas\n",
    "df_branches = pd.DataFrame(branches_info)\n",
    "\n",
    "# 1. An√°lisis general de ramas\n",
    "branch_states = df_branches[\"state\"].value_counts().reset_index()\n",
    "branch_states.columns = [\"Estado\", \"Cantidad\"]\n",
    "\n",
    "# 2. An√°lisis por tipo de rama\n",
    "branch_types = df_branches[\"branch_type\"].value_counts().reset_index()\n",
    "branch_types.columns = [\"Tipo\", \"Cantidad\"]\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author = df_branches.groupby([\"author\", \"state\"]).size().unstack().fillna(0)\n",
    "if \"OPEN\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"OPEN\"] = 0\n",
    "if \"MERGED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"MERGED\"] = 0\n",
    "if \"DECLINED\" not in branches_by_author.columns:\n",
    "    branches_by_author[\"DECLINED\"] = 0\n",
    "\n",
    "# 4. Tiempo activo de las ramas\n",
    "branch_lifetime = (\n",
    "    df_branches.dropna(subset=[\"days_active\"])\n",
    "    .groupby([\"branch_type\", \"state\"])[\"days_active\"]\n",
    "    .agg([\"mean\", \"median\", \"max\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5. Ramas abiertas vs cerradas por repositorio\n",
    "branches_by_repo = (\n",
    "    df_branches.groupby([\"repository\", \"state\"]).size().unstack().fillna(0)\n",
    ")\n",
    "\n",
    "# Visualizaciones\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# 1. Estado de las ramas\n",
    "sns.barplot(\n",
    "    x=\"Estado\", y=\"Cantidad\", data=branch_states, ax=axes[0, 0], palette=\"viridis\"\n",
    ")\n",
    "axes[0, 0].set_title(\"Estado de las Ramas\", fontsize=14)\n",
    "for i, v in enumerate(branch_states[\"Cantidad\"]):\n",
    "    axes[0, 0].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 2. Tipos de ramas\n",
    "sns.barplot(x=\"Tipo\", y=\"Cantidad\", data=branch_types, ax=axes[0, 1], palette=\"muted\")\n",
    "axes[0, 1].set_title(\"Distribuci√≥n por Tipo de Rama\", fontsize=14)\n",
    "for i, v in enumerate(branch_types[\"Cantidad\"]):\n",
    "    axes[0, 1].text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "# 3. Ramas por autor\n",
    "branches_by_author.plot(kind=\"bar\", stacked=True, ax=axes[1, 0], colormap=\"tab10\")\n",
    "axes[1, 0].set_title(\"Ramas por Autor y Estado\", fontsize=14)\n",
    "axes[1, 0].set_xlabel(\"Autor\")\n",
    "axes[1, 0].set_ylabel(\"N√∫mero de Ramas\")\n",
    "axes[1, 0].legend(title=\"Estado\")\n",
    "\n",
    "# 4. Tiempo promedio de las ramas abiertas\n",
    "open_branches = df_branches[df_branches[\"state\"] == \"OPEN\"]\n",
    "if not open_branches.empty:\n",
    "    sns.boxplot(x=\"branch_type\", y=\"days_active\", data=open_branches, ax=axes[1, 1])\n",
    "    axes[1, 1].set_title(\"Tiempo de Ramas Abiertas por Tipo\", fontsize=14)\n",
    "    axes[1, 1].set_xlabel(\"Tipo de Rama\")\n",
    "    axes[1, 1].set_ylabel(\"D√≠as Activa\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Gr√°fico adicional: Evoluci√≥n de ramas a lo largo del tiempo\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Crear fechas para el per√≠odo analizado\n",
    "start_date = df_branches[\"created_date\"].min().date()\n",
    "end_date = pd.Timestamp.now(tz=\"UTC\").date()\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "\n",
    "# Contar ramas creadas por d√≠a\n",
    "df_branches[\"created_day\"] = df_branches[\"created_date\"].dt.date\n",
    "\n",
    "\n",
    "# Imprimir estad√≠sticas\n",
    "print(\"\\n===== AN√ÅLISIS DE ACTIVIDAD EN RAMAS =====\")\n",
    "print(f\"Total de ramas analizadas: {len(df_branches)}\")\n",
    "print(f\"Ramas por estado: {dict(branch_states.values)}\")\n",
    "print(f\"Ramas por tipo: {dict(branch_types.values)}\")\n",
    "print(\"\\nRamas abiertas por tiempo:\")\n",
    "if not open_branches.empty:\n",
    "    open_by_time = (\n",
    "        open_branches.groupby(\"branch_type\")[\"days_active\"]\n",
    "        .agg([\"count\", \"mean\", \"median\", \"max\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "    for _, row in open_by_time.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_type']}: {row['count']} ramas, promedio {row['mean']:.1f} d√≠as, m√°ximo {row['max']} d√≠as\"\n",
    "        )\n",
    "\n",
    "# Detectar ramas potencialmente abandonadas (abiertas por m√°s de 30 d√≠as)\n",
    "abandoned = open_branches[open_branches[\"days_active\"] > 30].sort_values(\n",
    "    \"days_active\", ascending=False\n",
    ")\n",
    "if not abandoned.empty:\n",
    "    print(\"\\nRamas potencialmente abandonadas (>30 d√≠as abiertas):\")\n",
    "    for _, row in abandoned.iterrows():\n",
    "        print(\n",
    "            f\"- {row['branch_name']} ({row['repository']}): {row['days_active']} d√≠as, autor: {row['author']}\"\n",
    "        )\n",
    "else:\n",
    "    print(\"\\nNo hay ramas potencialmente abandonadas.\")\n",
    "\n",
    "# Analizar patrones de creaci√≥n de ramas por autor\n",
    "author_patterns = (\n",
    "    df_branches.groupby(\"author\")[\"branch_type\"].value_counts().unstack().fillna(0)\n",
    ")\n",
    "print(\"\\nPatrones de creaci√≥n de ramas por autor:\")\n",
    "print(author_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e785e2",
   "metadata": {},
   "source": [
    "### Frecuencia de Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3f88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar solo PRs que fueron mergeados\n",
    "merged_prs = df_pr[df_pr[\"state\"] == \"MERGED\"].copy()\n",
    "\n",
    "# Convertir fechas a datetime si no lo est√°n ya\n",
    "merged_prs[\"merge_date\"] = pd.to_datetime(merged_prs[\"updated_on\"]).dt.date\n",
    "\n",
    "# An√°lisis de merges por autor\n",
    "merges_by_author = merged_prs.groupby(\"author\").size().sort_values(ascending=False)\n",
    "merges_by_author.name = \"total_merges\"\n",
    "\n",
    "# An√°lisis temporal: merges por semana por autor\n",
    "merged_prs[\"merge_week\"] = pd.to_datetime(merged_prs[\"updated_on\"]).dt.strftime(\"%Y-%U\")\n",
    "weekly_merges = (\n",
    "    merged_prs.groupby([\"author\", \"merge_week\"]).size().reset_index(name=\"merges\")\n",
    ")\n",
    "avg_weekly_merges = (\n",
    "    weekly_merges.groupby(\"author\")[\"merges\"].mean().sort_values(ascending=False)\n",
    ")\n",
    "avg_weekly_merges.name = \"avg_weekly_merges\"\n",
    "\n",
    "# Merges por repositorio\n",
    "merges_by_repo_author = (\n",
    "    merged_prs.groupby([\"author\", \"repository\"]).size().unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# Crear un DataFrame de resumen\n",
    "merge_stats = pd.DataFrame(\n",
    "    {\"Total Merges\": merges_by_author, \"Promedio Semanal\": avg_weekly_merges}\n",
    ").reset_index()\n",
    "merge_stats = merge_stats.sort_values(\"Total Merges\", ascending=False)\n",
    "\n",
    "# Visualizaci√≥n: Gr√°fico de barras para total de merges por autor\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    merge_stats[\"author\"], merge_stats[\"Total Merges\"], color=\"cornflowerblue\"\n",
    ")\n",
    "\n",
    "# Agregar etiquetas de valor sobre cada barra\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.title(\"Cantidad de Merges por Desarrollador\", fontsize=15)\n",
    "plt.xlabel(\"Desarrollador\", fontsize=12)\n",
    "plt.ylabel(\"N√∫mero de Merges\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizaci√≥n: Gr√°fico de l√≠neas para evoluci√≥n temporal de merges\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Crear un DataFrame pivotado para visualizar merges por semana\n",
    "weekly_pivot = weekly_merges.pivot(\n",
    "    index=\"merge_week\", columns=\"author\", values=\"merges\"\n",
    ").fillna(0)\n",
    "\n",
    "# Asegurar que tenemos todas las semanas en el rango\n",
    "all_weeks = (\n",
    "    pd.date_range(\n",
    "        start=merged_prs[\"updated_on\"].min().date(),\n",
    "        end=merged_prs[\"updated_on\"].max().date(),\n",
    "        freq=\"W\",\n",
    "    )\n",
    "    .strftime(\"%Y-%U\")\n",
    "    .tolist()\n",
    ")\n",
    "weekly_pivot = weekly_pivot.reindex(all_weeks, fill_value=0)\n",
    "\n",
    "# Graficar la evoluci√≥n temporal\n",
    "weekly_pivot.plot(marker=\"o\")\n",
    "plt.title(\"Evoluci√≥n de Merges por Semana por Desarrollador\", fontsize=15)\n",
    "plt.xlabel(\"Semana\", fontsize=12)\n",
    "plt.ylabel(\"N√∫mero de Merges\", fontsize=12)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualizaci√≥n: Gr√°fico de calor para merges por repositorio\n",
    "plt.figure(figsize=(11, 7))\n",
    "sns.heatmap(merges_by_repo_author, annot=True, fmt=\"g\", cmap=\"YlGnBu\")\n",
    "plt.title(\"Merges por Desarrollador y Repositorio\", fontsize=15)\n",
    "plt.ylabel(\"Desarrollador\", fontsize=12)\n",
    "plt.xlabel(\"Repositorio\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de frecuencia de merges\n",
    "print(\"\\n===== AN√ÅLISIS DE FRECUENCIA DE MERGES =====\")\n",
    "print(f\"Total de PRs mergeados: {len(merged_prs)}\")\n",
    "print(\"\\nFrequencia de merges por desarrollador:\")\n",
    "for _, row in merge_stats.iterrows():\n",
    "    print(\n",
    "        f\"- {row['author']}: {int(row['Total Merges'])} merges totales, {row['Promedio Semanal']:.1f} merges por semana\"\n",
    "    )\n",
    "\n",
    "# Calcular tiempo promedio entre merges por desarrollador\n",
    "developer_merge_gaps = {}\n",
    "for author in merged_prs[\"author\"].unique():\n",
    "    author_prs = merged_prs[merged_prs[\"author\"] == author].sort_values(\"updated_on\")\n",
    "    if len(author_prs) > 1:\n",
    "        gaps = []\n",
    "        for i in range(1, len(author_prs)):\n",
    "            gap = (\n",
    "                author_prs.iloc[i][\"updated_on\"] - author_prs.iloc[i - 1][\"updated_on\"]\n",
    "            ).total_seconds() / 86400  # d√≠as\n",
    "            gaps.append(gap)\n",
    "        developer_merge_gaps[author] = np.mean(gaps)\n",
    "\n",
    "if developer_merge_gaps:\n",
    "    print(\"\\nTiempo promedio entre merges consecutivos:\")\n",
    "    for author, avg_days in sorted(developer_merge_gaps.items(), key=lambda x: x[1]):\n",
    "        print(f\"- {author}: {avg_days:.1f} d√≠as\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
