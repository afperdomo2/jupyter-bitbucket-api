{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db4f799",
   "metadata": {},
   "source": [
    "# ðŸ“Š Reporte de Pull Requests Merged en Bitbucket\n",
    "\n",
    "Este reporte proporciona una vista completa de todos los pull requests que han sido exitosamente merged en los repositorios de Bitbucket, incluyendo informaciÃ³n detallada sobre comentarios, tiempos de resoluciÃ³n y mÃ©tricas de productividad para anÃ¡lisis histÃ³rico y mejora de procesos de desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d315bf9",
   "metadata": {},
   "source": [
    "## ðŸ”§ ConfiguraciÃ³n e ImportaciÃ³n de LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv requests pandas matplotlib seaborn\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbcfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar credenciales de Bitbucket\n",
    "username = os.getenv(\"BITBUCKET_USERNAME\")\n",
    "app_password = os.getenv(\"BITBUCKET_APP_PASSWORD\")\n",
    "workspace = os.getenv(\"BITBUCKET_WORKSPACE\")\n",
    "\n",
    "# Verificar que las credenciales estÃ©n configuradas\n",
    "if not all([username, app_password, workspace]):\n",
    "    print(\"âŒ Error: AsegÃºrate de tener configuradas las variables de entorno:\")\n",
    "    print(\"- BITBUCKET_USERNAME\")\n",
    "    print(\"- BITBUCKET_APP_PASSWORD\")\n",
    "    print(\"- BITBUCKET_WORKSPACE\")\n",
    "else:\n",
    "    print(f\"âœ… Credenciales configuradas correctamente para el workspace: {workspace}\")\n",
    "    print(f\"   Usuario: {username}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd024f",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Obtener Repositorios y Funciones de Utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para obtener todos los elementos paginados de la API de Bitbucket\n",
    "def get_all_items(url, params=None):\n",
    "    \"\"\"\n",
    "    Obtiene todos los elementos de una URL paginada de la API de Bitbucket\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    while url:\n",
    "        response = requests.get(url, params=params, auth=(username, app_password))\n",
    "        if response.status_code != 200:\n",
    "            print(\n",
    "                f\"âŒ Error al obtener datos: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        items.extend(data.get(\"values\", []))\n",
    "\n",
    "        # Obtener la siguiente pÃ¡gina si existe\n",
    "        url = data.get(\"next\")\n",
    "        params = None  # Los parÃ¡metros ya estÃ¡n incluidos en la URL 'next'\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "# FunciÃ³n para obtener comentarios de un pull request\n",
    "def get_pr_comments(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene todos los comentarios de un pull request especÃ­fico\n",
    "    \"\"\"\n",
    "    comments_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}/comments\"\n",
    "    return get_all_items(comments_url)\n",
    "\n",
    "\n",
    "# FunciÃ³n para convertir fechas a formato \"para humanos\" en espaÃ±ol\n",
    "def fecha_para_humanos(fecha_str):\n",
    "    \"\"\"\n",
    "    Convierte una fecha en formato datetime o string a texto legible en espaÃ±ol\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Si ya es string formateado, intentar parsearlo\n",
    "        if isinstance(fecha_str, str):\n",
    "            # Intentar varios formatos posibles\n",
    "            try:\n",
    "                fecha = pd.to_datetime(fecha_str, format=\"%Y-%m-%d %H:%M\")\n",
    "            except:\n",
    "                fecha = pd.to_datetime(fecha_str)\n",
    "        else:\n",
    "            # Si es un objeto datetime de pandas\n",
    "            fecha = pd.to_datetime(fecha_str)\n",
    "\n",
    "        # Asegurar que la fecha tenga zona horaria UTC para comparaciÃ³n\n",
    "        if fecha.tz is None:\n",
    "            fecha = fecha.tz_localize(\"UTC\")\n",
    "\n",
    "        # Obtener tiempo actual en UTC\n",
    "        ahora = pd.Timestamp.now(tz=\"UTC\")\n",
    "\n",
    "        # Calcular diferencia\n",
    "        diff = ahora - fecha\n",
    "\n",
    "        # Obtener componentes\n",
    "        dias = diff.days\n",
    "        segundos_totales = diff.total_seconds()\n",
    "        horas = int(segundos_totales // 3600)\n",
    "        minutos = int((segundos_totales % 3600) // 60)\n",
    "\n",
    "        if dias > 0:\n",
    "            if dias == 1:\n",
    "                return \"hace 1 dÃ­a\"\n",
    "            elif dias < 7:\n",
    "                return f\"hace {dias} dÃ­as\"\n",
    "            elif dias < 30:\n",
    "                semanas = dias // 7\n",
    "                if semanas == 1:\n",
    "                    return \"hace 1 semana\"\n",
    "                else:\n",
    "                    return f\"hace {semanas} semanas\"\n",
    "            elif dias < 365:\n",
    "                meses = dias // 30\n",
    "                if meses == 1:\n",
    "                    return \"hace 1 mes\"\n",
    "                else:\n",
    "                    return f\"hace {meses} meses\"\n",
    "            else:\n",
    "                aÃ±os = dias // 365\n",
    "                if aÃ±os == 1:\n",
    "                    return \"hace 1 aÃ±o\"\n",
    "                else:\n",
    "                    return f\"hace {aÃ±os} aÃ±os\"\n",
    "        elif horas > 0:\n",
    "            if horas == 1:\n",
    "                return \"hace 1 hora\"\n",
    "            else:\n",
    "                return f\"hace {horas} horas\"\n",
    "        elif minutos > 0:\n",
    "            if minutos == 1:\n",
    "                return \"hace 1 minuto\"\n",
    "            else:\n",
    "                return f\"hace {minutos} minutos\"\n",
    "        else:\n",
    "            return \"hace menos de 1 minuto\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando fecha {fecha_str}: {e}\")\n",
    "        return str(fecha_str)  # Si hay error, devolver la fecha original como string\n",
    "\n",
    "\n",
    "# FunciÃ³n para analizar comentarios del pull request segÃºn las nuevas reglas\n",
    "def analyze_pr_comments(comments, pr_author_name):\n",
    "    \"\"\"\n",
    "    Analiza los comentarios de un PR y los clasifica segÃºn las nuevas reglas (mutuamente excluyentes):\n",
    "    - Devoluciones: Comentarios normales de usuarios diferentes al autor del PR (NO inline)\n",
    "    - Estandarizaciones_Codigo: Comentarios inline de usuarios diferentes al autor del PR\n",
    "    \"\"\"\n",
    "    comm_pullrequest = 0\n",
    "    estandarizaciones_codigo = 0\n",
    "\n",
    "    for comment in comments:\n",
    "        # Solo procesar comentarios no eliminados\n",
    "        if comment.get(\"deleted\", False):\n",
    "            continue\n",
    "\n",
    "        # Obtener el nombre del usuario que hizo el comentario\n",
    "        comment_author = None\n",
    "        if \"user\" in comment and comment[\"user\"]:\n",
    "            # Priorizar display_name, luego nickname\n",
    "            comment_author = comment[\"user\"].get(\"display_name\") or comment[\"user\"].get(\n",
    "                \"nickname\"\n",
    "            )\n",
    "\n",
    "        # Solo contar si el comentario es de un usuario diferente al autor del PR\n",
    "        if comment_author and comment_author != pr_author_name:\n",
    "            # Verificar si es comentario inline (desarrollador) o normal (pull request)\n",
    "            if \"inline\" in comment and comment[\"inline\"]:\n",
    "                # Es un comentario inline -> comentario de estandarizaciÃ³n de cÃ³digo\n",
    "                estandarizaciones_codigo += 1\n",
    "            else:\n",
    "                # Es un comentario normal -> comentario del pull request\n",
    "                comm_pullrequest += 1\n",
    "\n",
    "    return comm_pullrequest, estandarizaciones_codigo\n",
    "\n",
    "\n",
    "# FunciÃ³n para acortar nombres largos\n",
    "def acortar_nombre(nombre_completo):\n",
    "    \"\"\"\n",
    "    Acorta nombres largos para mostrar solo primer nombre + primera letra del segundo nombre\n",
    "    Ejemplo: \"Daniel Felipe Leal Chaves\" -> \"DanielF.\"\n",
    "    \"\"\"\n",
    "    if not nombre_completo or not isinstance(nombre_completo, str):\n",
    "        return nombre_completo\n",
    "\n",
    "    # Dividir el nombre en partes\n",
    "    partes = nombre_completo.strip().split()\n",
    "\n",
    "    if len(partes) == 1:\n",
    "        # Solo tiene un nombre\n",
    "        return partes[0]\n",
    "    elif len(partes) >= 2:\n",
    "        # Tiene al menos dos nombres\n",
    "        primer_nombre = partes[0]\n",
    "        segunda_parte = partes[1]\n",
    "\n",
    "        # Devolver primer nombre + primera letra del segundo en mayÃºscula + punto (sin espacios)\n",
    "        return f\"{primer_nombre}{segunda_parte[0].upper()}.\"\n",
    "\n",
    "    return nombre_completo\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# FUNCIONES DE PRESENTACIÃ“N (SEPARAR DATOS DE VISTA)\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def get_devoluciones_icon(count):\n",
    "    \"\"\"\n",
    "    Convierte nÃºmero de devoluciones a indicador visual con emoji\n",
    "    \"\"\"\n",
    "    return f\"{count} {'ðŸ”´' if count >= 5 else 'ðŸŸ¡' if count >= 3 else 'ðŸŸ¢'}\"\n",
    "\n",
    "\n",
    "def get_codigo_comentarios_icon(count):\n",
    "    \"\"\"\n",
    "    Convierte nÃºmero de comentarios de cÃ³digo a indicador visual con emoji\n",
    "    \"\"\"\n",
    "    return f\"{count} {'ðŸ”´' if count >= 10 else 'ðŸŸ¡' if count >= 4 else 'ðŸŸ¢'}\"\n",
    "\n",
    "\n",
    "def get_codigo_comentarios_category(count):\n",
    "    \"\"\"\n",
    "    Categoriza comentarios de cÃ³digo para anÃ¡lisis (sin emojis)\n",
    "    \"\"\"\n",
    "    if count >= 10:\n",
    "        return \"Alto\"\n",
    "    elif count >= 4:\n",
    "        return \"Medio\"\n",
    "    else:\n",
    "        return \"Bajo\"\n",
    "\n",
    "\n",
    "def get_tiempo_resolucion_icon(dias):\n",
    "    \"\"\"\n",
    "    Convierte dÃ­as de resoluciÃ³n a indicador visual con emoji (solo muestra Ã­cono si es lento)\n",
    "    \"\"\"\n",
    "    return f\"ðŸŒ {dias}\" if dias >= 7 else str(dias)\n",
    "\n",
    "\n",
    "def get_tiempo_resolucion_category(dias):\n",
    "    \"\"\"\n",
    "    Categoriza tiempo de resoluciÃ³n para anÃ¡lisis: solo \"Normal\" y \"Lento\"\n",
    "    \"\"\"\n",
    "    if dias >= 7:\n",
    "        return \"Lento\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "\n",
    "print(\"âœ… Funciones de utilidad y presentaciÃ³n definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para obtener participantes de un pull request\n",
    "def get_pr_participants(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene los participantes de un pull request especÃ­fico con sus estados de revisiÃ³n\n",
    "    \"\"\"\n",
    "    participants_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}/participants\"\n",
    "    participants = get_all_items(participants_url)\n",
    "    return participants\n",
    "\n",
    "# FunciÃ³n para obtener informaciÃ³n detallada de un pull request\n",
    "def get_pr_details(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene informaciÃ³n detallada de un pull request especÃ­fico\n",
    "    \"\"\"\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}\"\n",
    "    response = requests.get(pr_url, auth=(username, app_password))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# FunciÃ³n para obtener informaciÃ³n detallada de un pull request incluyendo participants\n",
    "def get_pr_details_with_participants(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene informaciÃ³n detallada de un pull request especÃ­fico incluyendo participants\n",
    "    \"\"\"\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}\"\n",
    "    response = requests.get(pr_url, auth=(username, app_password))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# FunciÃ³n para analizar los estados de revisiÃ³n de los reviewers\n",
    "def analyze_reviewer_statuses(participants, reviewers_basic):\n",
    "    \"\"\"\n",
    "    Analiza los estados de revisiÃ³n de los participantes y reviewers\n",
    "    Retorna conteos de aprobaciones y solicitudes de cambio\n",
    "    \"\"\"\n",
    "    approvals = 0\n",
    "    changes_requested = 0\n",
    "    reviewers_info = []\n",
    "    \n",
    "    # Crear un diccionario para facilitar la bÃºsqueda\n",
    "    participants_dict = {}\n",
    "    for participant in participants:\n",
    "        if participant.get('user'):\n",
    "            username = participant['user'].get('nickname') or participant['user'].get('display_name')\n",
    "            if username:\n",
    "                participants_dict[username] = participant\n",
    "    \n",
    "    # Analizar cada reviewer\n",
    "    for reviewer in reviewers_basic:\n",
    "        reviewer_info = {\"name\": reviewer, \"status\": \"pending\"}\n",
    "        \n",
    "        # Buscar el reviewer en los participantes\n",
    "        if reviewer in participants_dict:\n",
    "            participant = participants_dict[reviewer]\n",
    "            if participant.get('approved'):\n",
    "                approvals += 1\n",
    "                reviewer_info[\"status\"] = \"approved\"\n",
    "            elif participant.get('state') == 'changes_requested':\n",
    "                changes_requested += 1\n",
    "                reviewer_info[\"status\"] = \"changes_requested\"\n",
    "        \n",
    "        reviewers_info.append(reviewer_info)\n",
    "    \n",
    "    return approvals, changes_requested, reviewers_info\n",
    "\n",
    "# FunciÃ³n para analizar los estados de revisiÃ³n desde los datos del PR\n",
    "def analyze_pr_review_statuses(pr_data):\n",
    "    \"\"\"\n",
    "    Analiza los estados de revisiÃ³n desde los datos completos del PR\n",
    "    Extrae informaciÃ³n de reviewers y participants si estÃ¡ disponible\n",
    "    \"\"\"\n",
    "    approvals = 0\n",
    "    changes_requested = 0\n",
    "    reviewers_info = []\n",
    "    \n",
    "    # Primero obtener reviewers bÃ¡sicos\n",
    "    reviewers_basic = []\n",
    "    if \"reviewers\" in pr_data and pr_data[\"reviewers\"]:\n",
    "        for reviewer in pr_data[\"reviewers\"]:\n",
    "            if \"nickname\" in reviewer:\n",
    "                reviewers_basic.append(reviewer[\"nickname\"])\n",
    "            elif \"display_name\" in reviewer:\n",
    "                reviewers_basic.append(reviewer[\"display_name\"])\n",
    "    \n",
    "    # Buscar informaciÃ³n de participants si estÃ¡ disponible en el PR\n",
    "    participants = pr_data.get(\"participants\", [])\n",
    "    \n",
    "    # Crear diccionario de participantes para facilitar bÃºsqueda\n",
    "    participants_dict = {}\n",
    "    for participant in participants:\n",
    "        if participant.get('user'):\n",
    "            user_name = participant['user'].get('nickname') or participant['user'].get('display_name')\n",
    "            if user_name:\n",
    "                participants_dict[user_name] = participant\n",
    "    \n",
    "    # Analizar cada reviewer\n",
    "    for reviewer in reviewers_basic:\n",
    "        reviewer_info = {\"name\": reviewer, \"status\": \"pending\"}\n",
    "        \n",
    "        # Buscar el reviewer en los participantes\n",
    "        if reviewer in participants_dict:\n",
    "            participant = participants_dict[reviewer]\n",
    "            # Verificar estados de aprobaciÃ³n\n",
    "            if participant.get('approved'):\n",
    "                approvals += 1\n",
    "                reviewer_info[\"status\"] = \"approved\"\n",
    "            elif participant.get('state') == 'changes_requested':\n",
    "                changes_requested += 1\n",
    "                reviewer_info[\"status\"] = \"changes_requested\"\n",
    "        \n",
    "        reviewers_info.append(reviewer_info)\n",
    "    \n",
    "    return approvals, changes_requested, reviewers_info, reviewers_basic\n",
    "\n",
    "# FunciÃ³n para analizar todos los participants\n",
    "def analyze_participants_reviewers(pr_data):\n",
    "    \"\"\"\n",
    "    Analiza todos los participants del PR y extrae su estado de aprobaciÃ³n\n",
    "    - Aprobado: cuando 'approved' es True\n",
    "    - No aprobado/Pendiente: cuando 'state' es 'changes_requested'\n",
    "    \"\"\"\n",
    "    participants_reviewers = []\n",
    "    \n",
    "    # Obtener participants del PR\n",
    "    participants = pr_data.get(\"participants\", [])\n",
    "    \n",
    "    # Procesar todos los participants (sin filtrar por role)\n",
    "    for participant in participants:\n",
    "        user_info = participant.get('user', {})\n",
    "        user_name = user_info.get('display_name') or user_info.get('nickname', 'Usuario Desconocido')\n",
    "        \n",
    "        # Verificar el estado segÃºn las nuevas reglas\n",
    "        is_approved = participant.get('approved', False)\n",
    "        state = participant.get('state', '')\n",
    "        \n",
    "        participant_info = {\n",
    "            \"name\": user_name,\n",
    "            \"approved\": is_approved,\n",
    "            \"state\": state\n",
    "        }\n",
    "        \n",
    "        participants_reviewers.append(participant_info)\n",
    "    \n",
    "    return participants_reviewers\n",
    "\n",
    "print(\"âœ… Funciones actualizadas para usar todos los participants con nuevas reglas de estado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista de repositorios\n",
    "url_repos = f\"https://api.bitbucket.org/2.0/repositories/{workspace}\"\n",
    "\n",
    "print(\"ðŸ”„ Obteniendo lista de repositorios...\")\n",
    "repositorios_data = get_all_items(url_repos)\n",
    "\n",
    "if repositorios_data:\n",
    "    repos_list = []\n",
    "    for repo in repositorios_data:\n",
    "        repos_list.append(\n",
    "            {\n",
    "                \"Nombre\": repo.get(\"name\"),\n",
    "                \"URL\": repo.get(\"links\", {}).get(\"html\", {}).get(\"href\"),\n",
    "                \"DescripciÃ³n\": repo.get(\"description\", \"\"),\n",
    "                \"Privado\": repo.get(\"is_private\", False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    repos_df = pd.DataFrame(repos_list)\n",
    "    repos_df = repos_df.sort_values(by=\"Nombre\")\n",
    "\n",
    "    # Filtrar repositorios (excluir algunos como en el archivo original)\n",
    "    repositorios_excluir = [\"pgp\", \"Pruebas_erp\", \"Inventario\", \"b2c\", \"efi\"]\n",
    "    repositorios_activos = [\n",
    "        repo[\"Nombre\"]\n",
    "        for repo in repos_list\n",
    "        if repo[\"Nombre\"] not in repositorios_excluir\n",
    "    ]\n",
    "\n",
    "    print(f\"âœ… Total de repositorios encontrados: {len(repositorios_data)}\")\n",
    "    print(f\"âœ… Repositorios activos para anÃ¡lisis: {len(repositorios_activos)}\")\n",
    "\n",
    "    # Mostrar algunos repositorios\n",
    "    display(repos_df.head(10))\n",
    "else:\n",
    "    print(\"âŒ No se pudieron obtener los repositorios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74dad3",
   "metadata": {},
   "source": [
    "## ðŸ” Obtener Pull Requests Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para obtener PRs de un repositorio individual\n",
    "def obtener_prs_repositorio(repo_slug, workspace, repo_index, total_repos):\n",
    "    \"\"\"\n",
    "    Obtiene los pull requests merged de un repositorio especÃ­fico.\n",
    "    Esta funciÃ³n estÃ¡ diseÃ±ada para ser ejecutada en paralelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"   ðŸ”„ Procesando repositorio {repo_index}/{total_repos}: {repo_slug}\")\n",
    "        \n",
    "        # URL para obtener PRs merged\n",
    "        pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests\"\n",
    "        \n",
    "        # Obtener solo PRs merged (sin declined)\n",
    "        params = {\"state\": \"MERGED\"}\n",
    "        prs = get_all_items(pr_url, params=params)\n",
    "        \n",
    "        # Limitar a los Ãºltimos 50 PRs por repositorio para optimizar\n",
    "        if len(prs) > 50:\n",
    "            prs = prs[:50]\n",
    "        \n",
    "        # Agregar informaciÃ³n del repositorio a cada PR\n",
    "        for pr in prs:\n",
    "            pr[\"repository\"] = repo_slug\n",
    "        \n",
    "        print(f\"   âœ… Repositorio {repo_slug}: {len(prs)} PRs encontrados\")\n",
    "        return prs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error procesando repositorio {repo_slug}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Obtener todos los pull requests merged EN PARALELO\n",
    "print(\"ðŸ”„ Obteniendo pull requests merged de todos los repositorios...\")\n",
    "print(\"ðŸš€ Usando procesamiento paralelo para acelerar las consultas...\")\n",
    "\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "start_time = time.time()\n",
    "pull_requests_merged = []\n",
    "total_repos = len(repositorios_activos)\n",
    "\n",
    "# Usar ThreadPoolExecutor para consultas paralelas\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    # Enviar todas las tareas al pool de threads\n",
    "    futures = []\n",
    "    for i, repo_slug in enumerate(repositorios_activos, 1):\n",
    "        future = executor.submit(obtener_prs_repositorio, repo_slug, workspace, i, total_repos)\n",
    "        futures.append(future)\n",
    "    \n",
    "    # Recopilar resultados conforme van completÃ¡ndose\n",
    "    for future in futures:\n",
    "        repo_prs = future.result()\n",
    "        if repo_prs:  # Solo agregar si hay PRs encontrados\n",
    "            pull_requests_merged.extend(repo_prs)\n",
    "\n",
    "# Calcular tiempo de consulta\n",
    "end_time = time.time()\n",
    "tiempo_consulta = end_time - start_time\n",
    "\n",
    "print(f\"\\nâœ… Consulta paralela completada en {tiempo_consulta:.1f} segundos\")\n",
    "print(f\"âœ… Total de pull requests merged encontrados: {len(pull_requests_merged)}\")\n",
    "print(f\"ðŸš€ Mejora de rendimiento: {(total_repos * 2 / tiempo_consulta):.1f}x mÃ¡s rÃ¡pido estimado\")\n",
    "\n",
    "if len(pull_requests_merged) == 0:\n",
    "    print(\"â„¹ï¸  No hay pull requests merged en el perÃ­odo consultado\")\n",
    "else:\n",
    "    print(\"ðŸ”„ Procesando informaciÃ³n adicional de los pull requests...\")\n",
    "\n",
    "    # Filtrar por fecha si es necesario (Ãºltimos 30 dÃ­as por defecto)\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    fecha_limite = datetime.now() - timedelta(days=30)\n",
    "\n",
    "    # Filtrar PRs por fecha de merge\n",
    "    prs_filtrados = []\n",
    "    for pr in pull_requests_merged:\n",
    "        fecha_updated = pd.to_datetime(pr[\"updated_on\"])\n",
    "        if fecha_updated.tz_localize(None) >= fecha_limite:\n",
    "            prs_filtrados.append(pr)\n",
    "\n",
    "    pull_requests_merged = prs_filtrados\n",
    "    print(f\"ðŸ”„ PRs filtrados por Ãºltimos 30 dÃ­as: {len(pull_requests_merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunciÃ³n para procesar un PR individual de manera thread-safe\n",
    "def procesar_pr_individual(pr, progress_dict, total_prs):\n",
    "    try:\n",
    "        # Extraer informaciÃ³n del autor del PR\n",
    "        autor = \"Desconocido\"\n",
    "        if \"author\" in pr and pr[\"author\"]:\n",
    "            if \"display_name\" in pr[\"author\"]:\n",
    "                autor = pr[\"author\"][\"display_name\"]\n",
    "            elif \"nickname\" in pr[\"author\"]:\n",
    "                autor = pr[\"author\"][\"nickname\"]\n",
    "        autor = acortar_nombre(autor)\n",
    "\n",
    "        # Obtener comentarios del PR y analizarlos\n",
    "        try:\n",
    "            comentarios = get_pr_comments(workspace, pr[\"repository\"], pr[\"id\"])\n",
    "            comm_pullrequest, estandarizaciones_codigo = analyze_pr_comments(\n",
    "                comentarios, autor\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"      âš ï¸  Error obteniendo comentarios para PR {pr['id']}: {str(e)}\")\n",
    "            comm_pullrequest = 0\n",
    "            estandarizaciones_codigo = 0\n",
    "\n",
    "        # Calcular tiempo de resoluciÃ³n\n",
    "        created_on = pd.to_datetime(pr[\"created_on\"])\n",
    "        updated_on = pd.to_datetime(pr[\"updated_on\"])\n",
    "        tiempo_resolucion = (updated_on - created_on).days\n",
    "\n",
    "        # InformaciÃ³n sobre quien merged el PR\n",
    "        merged_por = \"Desconocido\"\n",
    "        if \"closed_by\" in pr and pr[\"closed_by\"]:\n",
    "            if \"display_name\" in pr[\"closed_by\"]:\n",
    "                merged_por = pr[\"closed_by\"][\"display_name\"]\n",
    "            elif \"nickname\" in pr[\"closed_by\"]:\n",
    "                merged_por = pr[\"closed_by\"][\"nickname\"]\n",
    "\n",
    "        # Crear registro procesado\n",
    "        pr_procesado = {\n",
    "            \"ID\": pr[\"id\"],\n",
    "            \"TÃ­tulo\": pr.get(\"title\", \"Sin tÃ­tulo\"),\n",
    "            \"Repositorio\": pr[\"repository\"],\n",
    "            \"Autor\": autor,\n",
    "            \"Merged_Por\": merged_por,\n",
    "            \"Devoluciones\": comm_pullrequest,\n",
    "            \"Estandarizaciones_Codigo\": estandarizaciones_codigo,\n",
    "            \"Fecha_Creacion\": created_on,\n",
    "            \"Fecha_Merge\": updated_on,\n",
    "            \"Tiempo_Resolucion\": tiempo_resolucion,\n",
    "            \"Descripcion\": (\n",
    "                pr.get(\"description\", \"Sin descripciÃ³n\")[:100] + \"...\"\n",
    "                if pr.get(\"description\", \"\")\n",
    "                else \"Sin descripciÃ³n\"\n",
    "            ),\n",
    "            \"URL\": pr.get(\"links\", {}).get(\"html\", {}).get(\"href\", \"\"),\n",
    "            \"Rama_Origen\": pr.get(\"source\", {})\n",
    "            .get(\"branch\", {})\n",
    "            .get(\"name\", \"Desconocida\"),\n",
    "            \"Rama_Destino\": pr.get(\"destination\", {})\n",
    "            .get(\"branch\", {})\n",
    "            .get(\"name\", \"Desconocida\"),\n",
    "        }\n",
    "\n",
    "        # Actualizar progreso de manera thread-safe\n",
    "        with progress_dict['lock']:\n",
    "            progress_dict['procesados'] += 1\n",
    "            current = progress_dict['procesados']\n",
    "            print(f\"   âœ… PR {current}/{total_prs} procesado: {pr.get('title', 'Sin tÃ­tulo')[:50]}...\")\n",
    "\n",
    "        return pr_procesado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error procesando PR {pr.get('id', 'unknown')}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Procesar informaciÃ³n detallada de cada pull request merged con threading\n",
    "if len(pull_requests_merged) > 0:\n",
    "    print(f\"ðŸš€ Iniciando procesamiento con threading de {len(pull_requests_merged)} PRs...\")\n",
    "    \n",
    "    # Medir tiempo de procesamiento\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Variables para tracking del progreso thread-safe\n",
    "    progress_dict = {\n",
    "        'procesados': 0,\n",
    "        'lock': threading.Lock()\n",
    "    }\n",
    "    \n",
    "    # Usar ThreadPoolExecutor para procesamiento paralelo\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Enviar todas las tareas al pool de threads\n",
    "        futures = []\n",
    "        for pr in pull_requests_merged:\n",
    "            future = executor.submit(procesar_pr_individual, pr, progress_dict, len(pull_requests_merged))\n",
    "            futures.append(future)\n",
    "        \n",
    "        # Recopilar resultados\n",
    "        prs_procesados = []\n",
    "        for future in futures:\n",
    "            resultado = future.result()\n",
    "            if resultado is not None:\n",
    "                prs_procesados.append(resultado)\n",
    "    \n",
    "    # Calcular tiempo transcurrido\n",
    "    end_time = time.time()\n",
    "    tiempo_total = end_time - start_time\n",
    "    \n",
    "    # Crear DataFrame con los datos procesados\n",
    "    df_prs_merged = pd.DataFrame(prs_procesados)\n",
    "\n",
    "    # Ordenar por fecha de merge (mÃ¡s recientes primero)\n",
    "    df_prs_merged = df_prs_merged.sort_values(\"Fecha_Merge\", ascending=False)\n",
    "\n",
    "    print(f\"\\nâœ… Procesamiento completado en {tiempo_total:.1f} segundos\")\n",
    "    print(f\"ðŸ“Š {len(df_prs_merged)} pull requests procesados exitosamente\")\n",
    "    if len(prs_procesados) < len(pull_requests_merged):\n",
    "        print(f\"âš ï¸  {len(pull_requests_merged) - len(prs_procesados)} PRs fallaron en el procesamiento\")\n",
    "else:\n",
    "    df_prs_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40875abf",
   "metadata": {},
   "source": [
    "## ðŸ“Š Reportes y AnÃ¡lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen ejecutivo\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ“ˆ RESUMEN EJECUTIVO - PULL REQUESTS MERGED\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    total_prs = len(df_prs_merged)\n",
    "\n",
    "    prs_con_comentarios = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 0])\n",
    "    total_comentarios = df_prs_merged[\"Devoluciones\"].sum()\n",
    "    total_estandarizaciones_codigo = df_prs_merged[\"Estandarizaciones_Codigo\"].sum()\n",
    "\n",
    "    promedio_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].mean()\n",
    "    max_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].max()\n",
    "    min_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].min()\n",
    "\n",
    "    print(f\"ðŸ”¢ Total de Pull Requests Merged: {total_prs}\")\n",
    "    print(f\"ðŸ’¬ PRs con Comentarios: {prs_con_comentarios}\")\n",
    "    print(f\"ðŸ“Š Total de Comentarios: {total_comentarios}\")\n",
    "    print(\n",
    "        f\"ðŸ‘¨â€ðŸ’» Estandarizaciones de CÃ³digo (inline): {total_estandarizaciones_codigo}\"\n",
    "    )\n",
    "    print(f\"â±ï¸  Tiempo Promedio de ResoluciÃ³n: {promedio_tiempo_resolucion:.1f} dÃ­as\")\n",
    "    print(f\"ðŸš€ ResoluciÃ³n mÃ¡s RÃ¡pida: {min_tiempo_resolucion} dÃ­as\")\n",
    "    print(f\"ðŸŒ ResoluciÃ³n mÃ¡s Lenta: {max_tiempo_resolucion} dÃ­as\")\n",
    "\n",
    "    # Repositorios con mÃ¡s PRs merged\n",
    "    repos_prs = df_prs_merged[\"Repositorio\"].value_counts()\n",
    "    print(f\"\\nðŸ† Repositorios con mÃ¡s PRs merged:\")\n",
    "    for i, (repo, count) in enumerate(repos_prs.head(5).items(), 1):\n",
    "        print(f\"   {i}. {repo}: {count} PRs\")\n",
    "\n",
    "    # Autores con mÃ¡s PRs merged\n",
    "    autores_prs = df_prs_merged[\"Autor\"].value_counts()\n",
    "    print(f\"\\nðŸ‘¥ Autores con mÃ¡s PRs merged:\")\n",
    "    for i, (autor, count) in enumerate(autores_prs.head(5).items(), 1):\n",
    "        print(f\"   {i}. {autor}: {count} PRs\")\n",
    "\n",
    "    # Personas que mÃ¡s hacen merge\n",
    "    merged_por = df_prs_merged[\"Merged_Por\"].value_counts()\n",
    "    print(f\"\\nðŸ”€ Quienes mÃ¡s hacen merge de PRs:\")\n",
    "    for i, (persona, count) in enumerate(merged_por.head(5).items(), 1):\n",
    "        print(f\"   {i}. {persona}: {count} PRs\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\n",
    "        \"â„¹ï¸  No hay pull requests merged en el perÃ­odo consultado para mostrar en el resumen\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tabla detallada de Pull Requests merged\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"\\nðŸ“‹ DETALLE DE PULL REQUESTS MERGED\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Mostrar rango temporal de los datos analizados\n",
    "    fecha_primer_pr = df_prs_merged[\"Fecha_Creacion\"].min()\n",
    "    fecha_ultimo_pr = df_prs_merged[\"Fecha_Creacion\"].max()\n",
    "\n",
    "    print(f\"ðŸ“… Fecha primer pull request: {fecha_primer_pr.strftime('%d/%m/%Y %H:%M')}\")\n",
    "    print(f\"ðŸ“… Fecha Ãºltimo pull request: {fecha_ultimo_pr.strftime('%d/%m/%Y %H:%M')}\")\n",
    "\n",
    "    # Calcular perÃ­odo total\n",
    "    periodo_total = (fecha_ultimo_pr - fecha_primer_pr).days\n",
    "    print(\n",
    "        f\"â±ï¸  PerÃ­odo total analizado: {periodo_total} dÃ­as ({periodo_total / 30:.1f} meses)\"\n",
    "    )\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Crear una versiÃ³n de la tabla optimizada para visualizaciÃ³n (sin Merged_Por)\n",
    "    df_display = df_prs_merged[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Repositorio\",\n",
    "            \"TÃ­tulo\",\n",
    "            \"Autor\",\n",
    "            \"Devoluciones\",\n",
    "            \"Estandarizaciones_Codigo\",\n",
    "            \"Tiempo_Resolucion\",\n",
    "            \"Rama_Origen\",\n",
    "            \"Fecha_Creacion\",\n",
    "            \"Fecha_Merge\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # Ordenar por fecha de merge (mÃ¡s recientes primero)\n",
    "    df_display = df_display.sort_values(\"Fecha_Merge\", ascending=False)\n",
    "\n",
    "    # Convertir fechas a formato \"para humanos\"\n",
    "    df_display[\"Creado\"] = df_display[\"Fecha_Creacion\"].apply(fecha_para_humanos)\n",
    "    df_display[\"Merged\"] = df_display[\"Fecha_Merge\"].apply(fecha_para_humanos)\n",
    "\n",
    "    # Eliminar las columnas de fecha originales\n",
    "    df_display = df_display.drop(columns=[\"Fecha_Creacion\", \"Fecha_Merge\"])\n",
    "\n",
    "    # ===================================================================\n",
    "    # MEJORES PRÃCTICAS: Crear columnas categÃ³ricas para anÃ¡lisis futuro\n",
    "    # ===================================================================\n",
    "\n",
    "    # Categorizar comentarios de cÃ³digo (para anÃ¡lisis/filtros)\n",
    "    df_display[\"Estandarizaciones_Codigo_Categoria\"] = df_display[\n",
    "        \"Estandarizaciones_Codigo\"\n",
    "    ].apply(get_codigo_comentarios_category)\n",
    "\n",
    "    # Categorizar tiempo de resoluciÃ³n (para anÃ¡lisis/filtros) - Solo \"Normal\" y \"Lento\"\n",
    "    df_display[\"Tiempo_Resolucion_Categoria\"] = df_display[\"Tiempo_Resolucion\"].apply(\n",
    "        get_tiempo_resolucion_category\n",
    "    )\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    df_display = df_display.rename(columns={\"Rama_Origen\": \"Branch\"})\n",
    "\n",
    "    # ===================================================================\n",
    "    # APLICAR PRESENTACIÃ“N VISUAL SOLO PARA MOSTRAR (NO PARA ALMACENAR)\n",
    "    # ===================================================================\n",
    "\n",
    "    # Crear copia temporal solo para visualizaciÃ³n\n",
    "    df_show = df_display.copy()\n",
    "\n",
    "    # Aplicar iconos solo en la copia de visualizaciÃ³n\n",
    "    df_show[\"Devoluciones\"] = df_show[\"Devoluciones\"].apply(get_devoluciones_icon)\n",
    "\n",
    "    # Aplicar iconos solo en la copia de visualizaciÃ³n\n",
    "    df_show[\"Estandarizaciones_Codigo\"] = df_show[\"Estandarizaciones_Codigo\"].apply(\n",
    "        get_codigo_comentarios_icon\n",
    "    )\n",
    "    df_show[\"Tiempo_Resolucion\"] = df_show[\"Tiempo_Resolucion\"].apply(\n",
    "        get_tiempo_resolucion_icon\n",
    "    )\n",
    "\n",
    "    # Renombrar columna de tiempo para mostrar\n",
    "    df_show = df_show.rename(columns={\"Tiempo_Resolucion\": \"DÃ­as_ResoluciÃ³n\"})\n",
    "\n",
    "    # Seleccionar columnas para mostrar (sin las categÃ³ricas internas)\n",
    "    df_show = df_show[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Repositorio\",\n",
    "            \"TÃ­tulo\",\n",
    "            \"Autor\",\n",
    "            \"Branch\",\n",
    "            \"Devoluciones\",\n",
    "            \"Estandarizaciones_Codigo\",\n",
    "            \"DÃ­as_ResoluciÃ³n\",\n",
    "            \"Creado\",\n",
    "            \"Merged\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Configurar pandas para mostrar todas las columnas\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.width\", None)\n",
    "    pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "    # Mostrar la tabla (solo la versiÃ³n con iconos)\n",
    "    display(df_show)\n",
    "\n",
    "    print(f\"\\nðŸ“Œ Mostrando {len(df_display)} pull requests merged\")\n",
    "    print(\"ðŸ’¡ Tip: Los PRs estÃ¡n ordenados por fecha de merge (mÃ¡s recientes primero)\")\n",
    "    print(\"ðŸŒ ResoluciÃ³n lenta: â‰¥7 dÃ­as (sin Ã­cono = resoluciÃ³n normal)\")\n",
    "    print(\"ðŸŸ¢ 0-2 devoluciones | ðŸŸ¡ 3-4 comentarios | ðŸ”´ 5+ comentarios\")\n",
    "    print(\"ðŸŸ¢ 0-3 comentarios de cÃ³digo | ðŸŸ¡ 4-9 comentarios | ðŸ”´ 10+ comentarios\")\n",
    "\n",
    "    print(f\"\\nðŸ” Para anÃ¡lisis futuro usar:\")\n",
    "    print(\n",
    "        f\"   â€¢ df_display['Estandarizaciones_Codigo_Categoria'] -> 'Bajo', 'Medio', 'Alto'\"\n",
    "    )\n",
    "    print(f\"   â€¢ df_display['Tiempo_Resolucion_Categoria'] -> 'Normal', 'Lento'\")\n",
    "    print(f\"   â€¢ df_display['Estandarizaciones_Codigo'] -> valores numÃ©ricos puros\")\n",
    "    print(f\"   â€¢ df_display['Tiempo_Resolucion'] -> dÃ­as numÃ©ricos puros\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  No hay pull requests merged en el perÃ­odo consultado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454526c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AnÃ¡lisis especÃ­fico de los datos actuales para generar recomendaciones de reportes\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"ðŸ” ANÃLISIS DE DATOS DISPONIBLES Y RECOMENDACIONES DE REPORTES\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # AnÃ¡lisis bÃ¡sico de los datos\n",
    "    total_prs = len(df_prs_merged)\n",
    "    autores_unicos = df_prs_merged[\"Autor\"].nunique()\n",
    "    repos_unicos = df_prs_merged[\"Repositorio\"].nunique()\n",
    "\n",
    "    print(f\"ðŸ“Š Resumen de datos disponibles:\")\n",
    "    print(f\"   â€¢ Total PRs: {total_prs}\")\n",
    "    print(f\"   â€¢ Autores Ãºnicos: {autores_unicos}\")\n",
    "    print(f\"   â€¢ Repositorios Ãºnicos: {repos_unicos}\")\n",
    "    print(\n",
    "        f\"   â€¢ Rango de fechas: {df_prs_merged['Fecha_Creacion'].min().strftime('%Y-%m-%d')} a {df_prs_merged['Fecha_Merge'].max().strftime('%Y-%m-%d')}\"\n",
    "    )\n",
    "\n",
    "    # AnÃ¡lisis de distribuciÃ³n de mÃ©tricas clave\n",
    "    print(f\"\\nðŸ“ˆ DistribuciÃ³n de mÃ©tricas clave:\")\n",
    "\n",
    "    # Estandarizaciones de cÃ³digo\n",
    "    est_stats = df_prs_merged[\"Estandarizaciones_Codigo\"].describe()\n",
    "    print(f\"   ðŸ”§ Estandarizaciones de CÃ³digo:\")\n",
    "    print(f\"      - Promedio: {est_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {est_stats['50%']:.1f}\")\n",
    "    print(f\"      - MÃ¡ximo: {int(est_stats['max'])}\")\n",
    "\n",
    "    # Devoluciones\n",
    "    dev_stats = df_prs_merged[\"Devoluciones\"].describe()\n",
    "    print(f\"   ðŸ”„ Devoluciones:\")\n",
    "    print(f\"      - Promedio: {dev_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {dev_stats['50%']:.1f}\")\n",
    "    print(f\"      - MÃ¡ximo: {int(dev_stats['max'])}\")\n",
    "\n",
    "    # Tiempo de resoluciÃ³n\n",
    "    tiempo_stats = df_prs_merged[\"Tiempo_Resolucion\"].describe()\n",
    "    print(f\"   â±ï¸  Tiempo de ResoluciÃ³n (dÃ­as):\")\n",
    "    print(f\"      - Promedio: {tiempo_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {tiempo_stats['50%']:.1f}\")\n",
    "    print(f\"      - MÃ¡ximo: {int(tiempo_stats['max'])}\")\n",
    "\n",
    "    print(f\"\\nðŸŽ¯ REPORTES RECOMENDADOS POR PRIORIDAD:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Generar recomendaciones basadas en los datos\n",
    "    reportes_recomendados = []\n",
    "\n",
    "    # 1. Si hay variabilidad en autores, recomendar anÃ¡lisis de productividad\n",
    "    if autores_unicos >= 3:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"ðŸ”´ ALTA\",\n",
    "                \"nombre\": \"Dashboard de Productividad por Desarrollador\",\n",
    "                \"justificacion\": f\"Con {autores_unicos} desarrolladores activos, este reporte identificarÃ¡ patrones de rendimiento y oportunidades de mejora.\",\n",
    "                \"impacto\": \"GestiÃ³n de equipo y desarrollo profesional\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 2. Si hay alta variabilidad en estandarizaciones, recomendar anÃ¡lisis de calidad\n",
    "    if est_stats[\"std\"] > 2:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"ðŸ”´ ALTA\",\n",
    "                \"nombre\": \"AnÃ¡lisis de Calidad de CÃ³digo\",\n",
    "                \"justificacion\": f\"Alta variabilidad en estandarizaciones (std: {est_stats['std']:.1f}) sugiere inconsistencias en calidad.\",\n",
    "                \"impacto\": \"Mejora de procesos de code review\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 3. Si hay mÃºltiples repositorios, recomendar anÃ¡lisis por repo\n",
    "    if repos_unicos >= 3:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"ðŸŸ¡ MEDIA\",\n",
    "                \"nombre\": \"Ranking de Repositorios por MÃ©tricas\",\n",
    "                \"justificacion\": f\"Con {repos_unicos} repositorios, podemos identificar cuÃ¡les necesitan mÃ¡s atenciÃ³n.\",\n",
    "                \"impacto\": \"PriorizaciÃ³n de esfuerzos de mejora tÃ©cnica\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 4. Si hay PRs lentos, recomendar anÃ¡lisis de eficiencia\n",
    "    prs_lentos = len(df_prs_merged[df_prs_merged[\"Tiempo_Resolucion\"] > 7])\n",
    "    if prs_lentos > 0:\n",
    "        porcentaje_lentos = (prs_lentos / total_prs) * 100\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"ðŸŸ¡ MEDIA\" if porcentaje_lentos < 20 else \"ðŸ”´ ALTA\",\n",
    "                \"nombre\": \"AnÃ¡lisis de Eficiencia del Proceso\",\n",
    "                \"justificacion\": f\"{prs_lentos} PRs ({porcentaje_lentos:.1f}%) tardaron mÃ¡s de 7 dÃ­as en resolverse.\",\n",
    "                \"impacto\": \"OptimizaciÃ³n del flujo de trabajo\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 5. AnÃ¡lisis temporal siempre Ãºtil\n",
    "    reportes_recomendados.append(\n",
    "        {\n",
    "            \"prioridad\": \"ðŸŸ¢ BAJA\",\n",
    "            \"nombre\": \"Tendencias Temporales\",\n",
    "            \"justificacion\": \"Ãštil para identificar patrones estacionales y planificaciÃ³n futura.\",\n",
    "            \"impacto\": \"PlanificaciÃ³n estratÃ©gica\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Mostrar recomendaciones\n",
    "    for i, reporte in enumerate(reportes_recomendados, 1):\n",
    "        print(f\"\\n{i}. {reporte['prioridad']} - {reporte['nombre']}\")\n",
    "        print(f\"   ðŸ’¡ JustificaciÃ³n: {reporte['justificacion']}\")\n",
    "        print(f\"   ðŸŽ¯ Impacto: {reporte['impacto']}\")\n",
    "\n",
    "    print(f\"\\nðŸš€ PRÃ“XIMOS PASOS SUGERIDOS:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"1. Comenzar con reportes de prioridad ALTA\")\n",
    "    print(\"2. Implementar dashboards automÃ¡ticos para seguimiento continuo\")\n",
    "    print(\"3. Definir umbrales de alerta para intervenciÃ³n proactiva\")\n",
    "    print(\"4. Establecer revisiones periÃ³dicas de mÃ©tricas con el equipo\")\n",
    "\n",
    "    # Mostrar informaciÃ³n sobre campos disponibles para cada reporte\n",
    "    print(f\"\\nðŸ“‹ CAMPOS DISPONIBLES PARA ANÃLISIS:\")\n",
    "    print(\"=\" * 40)\n",
    "    campos_numericos = [\"Devoluciones\", \"Estandarizaciones_Codigo\", \"Tiempo_Resolucion\"]\n",
    "    campos_categoricos = [\n",
    "        \"Autor\",\n",
    "        \"Repositorio\",\n",
    "        \"Merged_Por\",\n",
    "        \"Rama_Origen\",\n",
    "        \"Rama_Destino\",\n",
    "    ]\n",
    "    campos_temporales = [\"Fecha_Creacion\", \"Fecha_Merge\"]\n",
    "    campos_derivados = [\n",
    "        \"Estandarizaciones_Codigo_Categoria\",\n",
    "        \"Tiempo_Resolucion_Categoria\",\n",
    "    ]\n",
    "\n",
    "    print(f\"ðŸ”¢ Campos numÃ©ricos: {', '.join(campos_numericos)}\")\n",
    "    print(f\"ðŸ·ï¸  Campos categÃ³ricos: {', '.join(campos_categoricos)}\")\n",
    "    print(f\"ðŸ“… Campos temporales: {', '.join(campos_temporales)}\")\n",
    "    print(f\"ðŸ“Š Campos derivados: {', '.join(campos_derivados)}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸  No hay datos disponibles para generar recomendaciones de reportes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar las columnas disponibles en df_prs_merged\n",
    "print(\"ðŸ“‹ COLUMNAS DISPONIBLES EN df_prs_merged:\")\n",
    "print(list(df_prs_merged.columns))\n",
    "print(f\"\\nShape del DataFrame: {df_prs_merged.shape}\")\n",
    "\n",
    "# Verificar si existe la columna 'Autor' en lugar de 'author_name'\n",
    "if 'Autor' in df_prs_merged.columns:\n",
    "    print(\"âœ… La columna 'Autor' estÃ¡ disponible\")\n",
    "    print(f\"Autores Ãºnicos: {df_prs_merged['Autor'].nunique()}\")\n",
    "else:\n",
    "    print(\"âŒ La columna 'Autor' no estÃ¡ disponible\")\n",
    "\n",
    "# Verificar otras columnas necesarias\n",
    "columnas_necesarias = ['Tiempo_Resolucion', 'Devoluciones', 'Estandarizaciones_Codigo', 'Fecha_Creacion']\n",
    "for col in columnas_necesarias:\n",
    "    if col in df_prs_merged.columns:\n",
    "        print(f\"âœ… {col} disponible\")\n",
    "    else:\n",
    "        print(f\"âŒ {col} NO disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si existe declined_prs, si no, crear un DataFrame vacÃ­o\n",
    "if 'declined_prs' not in globals():\n",
    "    declined_prs = pd.DataFrame()  # DataFrame vacÃ­o para evitar errores\n",
    "    print(\"âš ï¸ declined_prs no encontrado, creando DataFrame vacÃ­o\")\n",
    "else:\n",
    "    print(f\"âœ… declined_prs encontrado con {len(declined_prs)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6eafe8",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ REPORTES Y VISUALIZACIONES IMPLEMENTADAS\n",
    "\n",
    "En esta secciÃ³n implementamos los reportes prioritarios identificados en el anÃ¡lisis anterior, proporcionando visualizaciones y mÃ©tricas que aportan valor directo al equipo de desarrollo para la toma de decisiones y mejora continua de procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcb8a3",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ REPORTE 1: Dashboard de Productividad del Equipo\n",
    "\n",
    "**Objetivo:** Proporcionar una vista consolidada de la productividad del equipo con mÃ©tricas clave de rendimiento.\n",
    "\n",
    "**MÃ©tricas incluidas:**\n",
    "- Volumen total de PRs procesados por desarrollador\n",
    "- Tiempo promedio de resoluciÃ³n por desarrollador\n",
    "- Tasa de Ã©xito (PRs merged vs declined)\n",
    "- DistribuciÃ³n de carga de trabajo\n",
    "- Ranking de productividad balanceada (velocidad + volumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# REPORTE 1: DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\n",
    "# ====================================================================================\n",
    "\n",
    "\n",
    "# Configurar el estilo de las visualizaciones\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Preparar datos para el dashboard de productividad\n",
    "print(\"ðŸš€ DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. MÃ©tricas generales de productividad\n",
    "metrics_productividad = {\n",
    "    \"Total PRs Procesados\": len(df_prs_merged),\n",
    "    \"Desarrolladores Activos\": len(df_prs_merged[\"Autor\"].unique()),\n",
    "    \"Tiempo Promedio ResoluciÃ³n\": f\"{df_prs_merged['Tiempo_Resolucion'].mean():.1f} dÃ­as\",\n",
    "    \"Tasa de Ã‰xito Global\": f\"{(len(df_prs_merged) / (len(df_prs_merged) + len(declined_prs)) * 100):.1f}%\",\n",
    "    \"PRs/DÃ­a (promedio)\": f\"{len(df_prs_merged) / ((df_prs_merged['Fecha_Creacion'].max() - df_prs_merged['Fecha_Creacion'].min()).days + 1):.1f}\",\n",
    "}\n",
    "\n",
    "# Mostrar mÃ©tricas principales\n",
    "print(\"\\nðŸ“Š MÃ‰TRICAS PRINCIPALES:\")\n",
    "for metric, value in metrics_productividad.items():\n",
    "    print(f\"   {metric}: {value}\")\n",
    "\n",
    "# 2. AnÃ¡lisis de productividad por desarrollador\n",
    "print(\"\\n\\nðŸ‘¥ ANÃLISIS POR DESARROLLADOR:\")\n",
    "\n",
    "# Calcular mÃ©tricas detalladas por autor\n",
    "productivity_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"ID\": \"count\",  # Volumen de PRs\n",
    "            \"Tiempo_Resolucion\": [\"mean\", \"std\"],  # Tiempo promedio y variabilidad\n",
    "            \"Devoluciones\": \"mean\",  # Complejidad promedio\n",
    "            \"Estandarizaciones_Codigo\": \"mean\",  # Calidad del cÃ³digo\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "productivity_stats.columns = [\n",
    "    \"PRs_Total\",\n",
    "    \"Tiempo_Promedio\",\n",
    "    \"Tiempo_Std\",\n",
    "    \"Devoluciones_Promedio\",\n",
    "    \"Estandarizaciones_Promedio\",\n",
    "]\n",
    "\n",
    "# Calcular score de productividad (balanceado entre volumen y velocidad)\n",
    "productivity_stats[\"Score_Volumen\"] = (\n",
    "    productivity_stats[\"PRs_Total\"] / productivity_stats[\"PRs_Total\"].max()\n",
    ") * 100\n",
    "productivity_stats[\"Score_Velocidad\"] = (\n",
    "    1\n",
    "    - (\n",
    "        productivity_stats[\"Tiempo_Promedio\"]\n",
    "        / productivity_stats[\"Tiempo_Promedio\"].max()\n",
    "    )\n",
    ") * 100\n",
    "productivity_stats[\"Score_Productividad\"] = (\n",
    "    productivity_stats[\"Score_Volumen\"] + productivity_stats[\"Score_Velocidad\"]\n",
    ") / 2\n",
    "\n",
    "# Ordenar por score de productividad\n",
    "productivity_stats = productivity_stats.sort_values(\n",
    "    \"Score_Productividad\", ascending=False\n",
    ")\n",
    "\n",
    "# Mostrar top 10 desarrolladores mÃ¡s productivos\n",
    "print(f\"\\nðŸ† TOP 10 DESARROLLADORES MÃS PRODUCTIVOS:\")\n",
    "display(\n",
    "    productivity_stats.head(10)[[\"PRs_Total\", \"Tiempo_Promedio\", \"Score_Productividad\"]]\n",
    ")\n",
    "\n",
    "# 3. Crear visualizaciÃ³n del dashboard\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.7, wspace=0.3)\n",
    "\n",
    "# GrÃ¡fico 1: Volumen de PRs por desarrollador (Top 15)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "top_15_volume = productivity_stats.head(15)\n",
    "bars1 = ax1.bar(\n",
    "    range(len(top_15_volume)), top_15_volume[\"PRs_Total\"], color=\"steelblue\", alpha=0.8\n",
    ")\n",
    "ax1.set_title(\n",
    "    \"ðŸ“Š Volumen de PRs por Desarrollador (Top 15)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax1.set_ylabel(\"NÃºmero de PRs\")\n",
    "ax1.set_xticks(range(len(top_15_volume)))\n",
    "ax1.set_xticklabels(\n",
    "    [name[:15] + \"...\" if len(name) > 15 else name for name in top_15_volume.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.5,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# GrÃ¡fico 2: Tiempo promedio de resoluciÃ³n (Top 15)\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "bars2 = ax2.bar(\n",
    "    range(len(top_15_volume)),\n",
    "    top_15_volume[\"Tiempo_Promedio\"],\n",
    "    color=\"lightcoral\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax2.set_title(\n",
    "    \"â±ï¸ Tiempo Promedio de ResoluciÃ³n (Top 15)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax2.set_ylabel(\"DÃ­as\")\n",
    "ax2.set_xticks(range(len(top_15_volume)))\n",
    "ax2.set_xticklabels(\n",
    "    [name[:15] + \"...\" if len(name) > 15 else name for name in top_15_volume.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{height:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# GrÃ¡fico 3: Score de Productividad (Top 12)\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "top_12_prod = productivity_stats.head(12)\n",
    "colors_grad = plt.cm.RdYlGn([x / 100 for x in top_12_prod[\"Score_Productividad\"]])\n",
    "bars3 = ax3.bar(\n",
    "    range(len(top_12_prod)),\n",
    "    top_12_prod[\"Score_Productividad\"],\n",
    "    color=colors_grad,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax3.set_title(\n",
    "    \"ðŸ† Score de Productividad Balanceado (Top 12)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax3.set_ylabel(\"Score (0-100)\")\n",
    "ax3.set_xticks(range(len(top_12_prod)))\n",
    "ax3.set_xticklabels(\n",
    "    [name[:12] + \"...\" if len(name) > 12 else name for name in top_12_prod.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{height:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# GrÃ¡fico 4: DistribuciÃ³n de carga de trabajo\n",
    "ax4 = fig.add_subplot(gs[1, 2:])\n",
    "# Agrupar desarrolladores por rangos de volumen\n",
    "bins = [0, 5, 15, 30, 50, 999]\n",
    "labels = [\"1-5 PRs\", \"6-15 PRs\", \"16-30 PRs\", \"31-50 PRs\", \"50+ PRs\"]\n",
    "productivity_stats[\"Rango_Volumen\"] = pd.cut(\n",
    "    productivity_stats[\"PRs_Total\"], bins=bins, labels=labels, include_lowest=True\n",
    ")\n",
    "dist_carga = productivity_stats[\"Rango_Volumen\"].value_counts()\n",
    "\n",
    "wedges, texts, autotexts = ax4.pie(\n",
    "    dist_carga.values,\n",
    "    labels=dist_carga.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=sns.color_palette(\"Set3\", len(dist_carga)),\n",
    ")\n",
    "ax4.set_title(\"ðŸ“ˆ DistribuciÃ³n de Carga de Trabajo\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Mejorar legibilidad del pie chart\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color(\"white\")\n",
    "    autotext.set_fontweight(\"bold\")\n",
    "\n",
    "# GrÃ¡fico 5: CorrelaciÃ³n Volumen vs Velocidad\n",
    "ax5 = fig.add_subplot(gs[2, :2])\n",
    "scatter = ax5.scatter(\n",
    "    productivity_stats[\"PRs_Total\"],\n",
    "    productivity_stats[\"Tiempo_Promedio\"],\n",
    "    c=productivity_stats[\"Score_Productividad\"],\n",
    "    cmap=\"RdYlGn\",\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax5.set_xlabel(\"Volumen de PRs\")\n",
    "ax5.set_ylabel(\"Tiempo Promedio (dÃ­as)\")\n",
    "ax5.set_title(\"ðŸŽ¯ RelaciÃ³n Volumen vs Velocidad\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Agregar colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax5)\n",
    "cbar.set_label(\"Score de Productividad\", rotation=270, labelpad=20)\n",
    "\n",
    "# Agregar lÃ­nea de tendencia\n",
    "z = np.polyfit(\n",
    "    productivity_stats[\"PRs_Total\"], productivity_stats[\"Tiempo_Promedio\"], 1\n",
    ")\n",
    "p = np.poly1d(z)\n",
    "ax5.plot(\n",
    "    productivity_stats[\"PRs_Total\"],\n",
    "    p(productivity_stats[\"PRs_Total\"]),\n",
    "    \"r--\",\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# GrÃ¡fico 6: EvoluciÃ³n temporal de productividad (Ãºltimos 6 meses)\n",
    "ax6 = fig.add_subplot(gs[2, 2:])\n",
    "if len(df_prs_merged) > 0:\n",
    "    # Agrupar por mes\n",
    "    df_prs_merged[\"mes\"] = df_prs_merged[\"Fecha_Creacion\"].dt.to_period(\"M\")\n",
    "    productivity_monthly = (\n",
    "        df_prs_merged.groupby(\"mes\")\n",
    "        .agg({\"ID\": \"count\", \"Tiempo_Resolucion\": \"mean\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Mostrar Ãºltimos 6 meses\n",
    "    productivity_monthly = productivity_monthly.tail(6)\n",
    "\n",
    "    ax6_twin = ax6.twinx()\n",
    "\n",
    "    # LÃ­nea de volumen\n",
    "    line1 = ax6.plot(\n",
    "        productivity_monthly[\"mes\"].astype(str),\n",
    "        productivity_monthly[\"ID\"],\n",
    "        \"b-o\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        label=\"Volumen PRs\",\n",
    "    )\n",
    "    ax6.set_ylabel(\"NÃºmero de PRs\", color=\"blue\")\n",
    "    ax6.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # LÃ­nea de tiempo promedio\n",
    "    line2 = ax6_twin.plot(\n",
    "        productivity_monthly[\"mes\"].astype(str),\n",
    "        productivity_monthly[\"Tiempo_Resolucion\"],\n",
    "        \"r-s\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        label=\"Tiempo Promedio\",\n",
    "    )\n",
    "    ax6_twin.set_ylabel(\"Tiempo Promedio (dÃ­as)\", color=\"red\")\n",
    "    ax6_twin.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    ax6.set_title(\n",
    "        \"ðŸ“… EvoluciÃ³n Temporal de Productividad\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    ax6.set_xlabel(\"Mes\")\n",
    "    plt.setp(ax6.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Combinar leyendas\n",
    "    lines1, labels1 = ax6.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax6_twin.get_legend_handles_labels()\n",
    "    ax6.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "# Tabla resumen de insights\n",
    "ax7 = fig.add_subplot(gs[3, :])\n",
    "ax7.axis(\"tight\")\n",
    "ax7.axis(\"off\")\n",
    "\n",
    "# Generar insights automÃ¡ticos\n",
    "insights_data = [\n",
    "    [\n",
    "        \"ðŸ† Desarrollador MÃ¡s Productivo\",\n",
    "        productivity_stats.index[0],\n",
    "        f\"{productivity_stats.iloc[0]['Score_Productividad']:.1f} puntos\",\n",
    "    ],\n",
    "    [\n",
    "        \"âš¡ Desarrollador MÃ¡s RÃ¡pido\",\n",
    "        productivity_stats.nsmallest(1, \"Tiempo_Promedio\").index[0],\n",
    "        f\"{productivity_stats.nsmallest(1, 'Tiempo_Promedio').iloc[0]['Tiempo_Promedio']:.1f} dÃ­as\",\n",
    "    ],\n",
    "    [\n",
    "        \"ðŸŽ¯ Desarrollador MÃ¡s Volumen\",\n",
    "        productivity_stats.nlargest(1, \"PRs_Total\").index[0],\n",
    "        f\"{productivity_stats.nlargest(1, 'PRs_Total').iloc[0]['PRs_Total']} PRs\",\n",
    "    ],\n",
    "    [\n",
    "        \"ðŸ“Š Promedio Equipo\",\n",
    "        \"Tiempo de ResoluciÃ³n\",\n",
    "        f\"{productivity_stats['Tiempo_Promedio'].mean():.1f} dÃ­as\",\n",
    "    ],\n",
    "    [\n",
    "        \"ðŸ” RecomendaciÃ³n\",\n",
    "        \"Desarrolladores a Analizar\",\n",
    "        f\"{len(productivity_stats[productivity_stats['Score_Productividad'] < 30])} con score < 30\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "table = ax7.table(\n",
    "    cellText=insights_data,\n",
    "    colLabels=[\"MÃ©trica\", \"Valor\", \"Detalle\"],\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    "    colWidths=[0.3, 0.3, 0.4],\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Estilizar tabla\n",
    "for i in range(len(insights_data) + 1):\n",
    "    for j in range(3):\n",
    "        cell = table[(i, j)]\n",
    "        if i == 0:  # Header\n",
    "            cell.set_facecolor(\"#4CAF50\")\n",
    "            cell.set_text_props(weight=\"bold\", color=\"white\")\n",
    "        else:\n",
    "            cell.set_facecolor(\"#f8f9fa\" if i % 2 == 0 else \"white\")\n",
    "\n",
    "ax7.set_title(\n",
    "    \"ðŸ’¡ INSIGHTS Y RECOMENDACIONES CLAVE\", fontsize=16, fontweight=\"bold\", pad=20\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"ðŸŽ¯ DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\", fontsize=20, fontweight=\"bold\", y=0.98\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Dashboard de Productividad generado exitosamente!\")\n",
    "print(\n",
    "    f\"ðŸ“ˆ Datos analizados: {len(df_prs_merged)} PRs de {len(productivity_stats)} desarrolladores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac71a0",
   "metadata": {},
   "source": [
    "## ðŸ” REPORTE 2: AnÃ¡lisis de Eficiencia y Calidad\n",
    "\n",
    "**Objetivo:** Evaluar la eficiencia en el proceso de revisiÃ³n y la calidad del cÃ³digo entregado.\n",
    "\n",
    "**MÃ©tricas incluidas:**\n",
    "- Tiempo de resoluciÃ³n vs complejidad (comentarios/estandarizaciones)\n",
    "- IdentificaciÃ³n de desarrolladores que necesitan mÃ¡s soporte\n",
    "- AnÃ¡lisis de patrones de trabajo y outliers\n",
    "- Correlaciones entre mÃ©tricas de calidad y eficiencia\n",
    "- Recomendaciones especÃ­ficas de mejora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1addddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# REPORTE 2: ANÃLISIS DE EFICIENCIA Y CALIDAD\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"ðŸ” ANÃLISIS DE EFICIENCIA Y CALIDAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. AnÃ¡lisis de correlaciones entre mÃ©tricas\n",
    "print(\"\\nðŸ“Š ANÃLISIS DE CORRELACIONES ENTRE MÃ‰TRICAS:\")\n",
    "\n",
    "# Preparar datos para correlaciones\n",
    "correlation_data = df_prs_merged[\n",
    "    [\"Tiempo_Resolucion\", \"Devoluciones\", \"Estandarizaciones_Codigo\"]\n",
    "].copy()\n",
    "correlation_data.columns = [\n",
    "    \"Tiempo_ResoluciÃ³n\",\n",
    "    \"Devoluciones\",\n",
    "    \"Estandarizaciones_CÃ³digo\",\n",
    "]\n",
    "\n",
    "# Calcular matriz de correlaciÃ³n\n",
    "corr_matrix = correlation_data.corr()\n",
    "print(\"\\nMatriz de CorrelaciÃ³n:\")\n",
    "display(corr_matrix.round(3))\n",
    "\n",
    "# 2. AnÃ¡lisis de eficiencia por desarrollador\n",
    "print(\"\\n\\nâš¡ ANÃLISIS DE EFICIENCIA POR DESARROLLADOR:\")\n",
    "\n",
    "# Calcular mÃ©tricas de eficiencia\n",
    "efficiency_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"Tiempo_Resolucion\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "            \"Devoluciones\": [\"mean\", \"std\"],\n",
    "            \"Estandarizaciones_Codigo\": [\"mean\", \"sum\"],\n",
    "            \"ID\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "efficiency_stats.columns = [\n",
    "    \"Tiempo_Medio\",\n",
    "    \"Tiempo_Std\",\n",
    "    \"Tiempo_Min\",\n",
    "    \"Tiempo_Max\",\n",
    "    \"Devoluciones_Medio\",\n",
    "    \"Devoluciones_Std\",\n",
    "    \"Estandarizaciones_Medio\",\n",
    "    \"Estandarizaciones_Total\",\n",
    "    \"Total_PRs\",\n",
    "]\n",
    "\n",
    "# Calcular mÃ©tricas de eficiencia\n",
    "efficiency_stats[\"Coef_Variacion_Tiempo\"] = (\n",
    "    efficiency_stats[\"Tiempo_Std\"] / efficiency_stats[\"Tiempo_Medio\"]\n",
    ") * 100\n",
    "efficiency_stats[\"Ratio_Estandarizaciones\"] = (\n",
    "    efficiency_stats[\"Estandarizaciones_Total\"] / efficiency_stats[\"Total_PRs\"]\n",
    ")\n",
    "efficiency_stats[\"Score_Consistencia\"] = 100 - efficiency_stats[\n",
    "    \"Coef_Variacion_Tiempo\"\n",
    "].fillna(0)\n",
    "efficiency_stats[\"Score_Calidad\"] = (\n",
    "    efficiency_stats[\"Ratio_Estandarizaciones\"]\n",
    "    / efficiency_stats[\"Ratio_Estandarizaciones\"].max()\n",
    ") * 100\n",
    "\n",
    "# Filtrar desarrolladores con al menos 3 PRs para anÃ¡lisis mÃ¡s confiable\n",
    "efficiency_relevant = efficiency_stats[efficiency_stats[\"Total_PRs\"] >= 3].copy()\n",
    "\n",
    "# Identificar categorÃ­as de desarrolladores\n",
    "print(\"\\nðŸŽ¯ CATEGORIZACIÃ“N DE DESARROLLADORES:\")\n",
    "\n",
    "# Desarrolladores eficientes (rÃ¡pidos y consistentes)\n",
    "eficientes = efficiency_relevant[\n",
    "    (\n",
    "        efficiency_relevant[\"Tiempo_Medio\"]\n",
    "        <= efficiency_relevant[\"Tiempo_Medio\"].quantile(0.25)\n",
    "    )\n",
    "    & (\n",
    "        efficiency_relevant[\"Score_Consistencia\"]\n",
    "        >= efficiency_relevant[\"Score_Consistencia\"].quantile(0.75)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Desarrolladores que necesitan soporte (lentos o inconsistentes)\n",
    "necesitan_soporte = efficiency_relevant[\n",
    "    (\n",
    "        efficiency_relevant[\"Tiempo_Medio\"]\n",
    "        >= efficiency_relevant[\"Tiempo_Medio\"].quantile(0.75)\n",
    "    )\n",
    "    | (\n",
    "        efficiency_relevant[\"Score_Consistencia\"]\n",
    "        <= efficiency_relevant[\"Score_Consistencia\"].quantile(0.25)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"âœ… Desarrolladores Eficientes: {len(eficientes)}\")\n",
    "print(f\"âš ï¸  Desarrolladores que Necesitan Soporte: {len(necesitan_soporte)}\")\n",
    "print(\n",
    "    f\"ðŸ“Š Desarrolladores Promedio: {len(efficiency_relevant) - len(eficientes) - len(necesitan_soporte)}\"\n",
    ")\n",
    "\n",
    "# 3. Crear visualizaciÃ³n del anÃ¡lisis de eficiencia\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.8, wspace=0.3)\n",
    "\n",
    "# GrÃ¡fico 1: Matriz de correlaciÃ³n\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "im1 = ax1.imshow(corr_matrix, cmap=\"RdBu_r\", aspect=\"auto\", vmin=-1, vmax=1)\n",
    "ax1.set_xticks(range(len(corr_matrix.columns)))\n",
    "ax1.set_yticks(range(len(corr_matrix.columns)))\n",
    "ax1.set_xticklabels(corr_matrix.columns, rotation=45, ha=\"right\")\n",
    "ax1.set_yticklabels(corr_matrix.columns)\n",
    "ax1.set_title(\n",
    "    \"ðŸ”— Matriz de CorrelaciÃ³n\\nEntre MÃ©tricas\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Agregar valores en la matriz\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(len(corr_matrix.columns)):\n",
    "        text = ax1.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{corr_matrix.iloc[i, j]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if abs(corr_matrix.iloc[i, j]) > 0.5 else \"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "# Colorbar para correlaciÃ³n\n",
    "plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "\n",
    "# GrÃ¡fico 2: Tiempo vs Complejidad (Devoluciones)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "scatter1 = ax2.scatter(\n",
    "    df_prs_merged[\"Devoluciones\"],\n",
    "    df_prs_merged[\"Tiempo_Resolucion\"],\n",
    "    c=df_prs_merged[\"Estandarizaciones_Codigo\"],\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.6,\n",
    "    s=50,\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.3,\n",
    ")\n",
    "ax2.set_xlabel(\"Devoluciones\")\n",
    "ax2.set_ylabel(\"Tiempo de ResoluciÃ³n (dÃ­as)\")\n",
    "ax2.set_title(\n",
    "    \"â±ï¸ Tiempo vs Complejidad\\n(Color = Estandarizaciones)\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.colorbar(scatter1, ax=ax2, shrink=0.8, label=\"Estandarizaciones\")\n",
    "\n",
    "# Agregar lÃ­nea de tendencia\n",
    "if len(df_prs_merged) > 1:\n",
    "    z = np.polyfit(df_prs_merged[\"Devoluciones\"], df_prs_merged[\"Tiempo_Resolucion\"], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax2.plot(\n",
    "        df_prs_merged[\"Devoluciones\"],\n",
    "        p(df_prs_merged[\"Devoluciones\"]),\n",
    "        \"r--\",\n",
    "        alpha=0.8,\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "# GrÃ¡fico 3: DistribuciÃ³n de eficiencia por categorÃ­as\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "categorias_count = [\n",
    "    len(eficientes),\n",
    "    len(necesitan_soporte),\n",
    "    len(efficiency_relevant) - len(eficientes) - len(necesitan_soporte),\n",
    "]\n",
    "categorias_labels = [\"Eficientes\", \"Necesitan\\nSoporte\", \"Promedio\"]\n",
    "colors_cat = [\"#2ecc71\", \"#e74c3c\", \"#f39c12\"]\n",
    "\n",
    "bars_cat = ax3.bar(categorias_labels, categorias_count, color=colors_cat, alpha=0.8)\n",
    "ax3.set_title(\n",
    "    \"ðŸ“Š DistribuciÃ³n por\\nCategorÃ­a de Eficiencia\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax3.set_ylabel(\"NÃºmero de Desarrolladores\")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars_cat):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# GrÃ¡fico 4: Top 10 mÃ¡s eficientes\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "if len(efficiency_relevant) > 0:\n",
    "    # Calcular score combinado de eficiencia\n",
    "    efficiency_relevant[\"Score_Eficiencia\"] = (\n",
    "        (1 / efficiency_relevant[\"Tiempo_Medio\"])\n",
    "        / (1 / efficiency_relevant[\"Tiempo_Medio\"]).max()\n",
    "    ) * 50 + (efficiency_relevant[\"Score_Consistencia\"] / 100) * 50\n",
    "\n",
    "    top_10_eff = efficiency_relevant.nlargest(10, \"Score_Eficiencia\")\n",
    "\n",
    "    x_pos = range(len(top_10_eff))\n",
    "    bars_eff = ax4.bar(\n",
    "        x_pos,\n",
    "        top_10_eff[\"Score_Eficiencia\"],\n",
    "        color=plt.cm.RdYlGn([x / 100 for x in top_10_eff[\"Score_Eficiencia\"]]),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax4.set_title(\n",
    "        \"ðŸ† TOP 10 DESARROLLADORES MÃS EFICIENTES (Velocidad + Consistencia)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax4.set_ylabel(\"Score de Eficiencia (0-100)\")\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(\n",
    "        [name[:20] + \"...\" if len(name) > 20 else name for name in top_10_eff.index],\n",
    "        rotation=45,\n",
    "        ha=\"right\",\n",
    "    )\n",
    "\n",
    "    # Agregar etiquetas con detalles\n",
    "    for i, bar in enumerate(bars_eff):\n",
    "        height = bar.get_height()\n",
    "        author = top_10_eff.index[i]\n",
    "        tiempo = top_10_eff.loc[author, \"Tiempo_Medio\"]\n",
    "        ax4.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 1,\n",
    "            f\"{height:.1f}\\n({tiempo:.1f}d)\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "# GrÃ¡fico 5: AnÃ¡lisis de outliers\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "# Boxplot de tiempos de resoluciÃ³n\n",
    "bp = ax5.boxplot(\n",
    "    [df_prs_merged[\"Tiempo_Resolucion\"]],\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"lightblue\", alpha=0.7),\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"ðŸ“¦ DetecciÃ³n de Outliers\\nen Tiempo de ResoluciÃ³n\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax5.set_ylabel(\"Tiempo (dÃ­as)\")\n",
    "ax5.set_xticklabels([\"Todos los PRs\"])\n",
    "\n",
    "# Identificar outliers\n",
    "Q1 = df_prs_merged[\"Tiempo_Resolucion\"].quantile(0.25)\n",
    "Q3 = df_prs_merged[\"Tiempo_Resolucion\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df_prs_merged[df_prs_merged[\"Tiempo_Resolucion\"] > Q3 + 1.5 * IQR]\n",
    "\n",
    "ax5.text(\n",
    "    1.2,\n",
    "    Q3 + 1.5 * IQR,\n",
    "    f\"Outliers: {len(outliers)}\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    ")\n",
    "\n",
    "# GrÃ¡fico 6: Consistencia vs Velocidad\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "if len(efficiency_relevant) > 0:\n",
    "    scatter2 = ax6.scatter(\n",
    "        efficiency_relevant[\"Tiempo_Medio\"],\n",
    "        efficiency_relevant[\"Score_Consistencia\"],\n",
    "        c=efficiency_relevant[\"Total_PRs\"],\n",
    "        cmap=\"plasma\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax6.set_xlabel(\"Tiempo Promedio (dÃ­as)\")\n",
    "    ax6.set_ylabel(\"Score de Consistencia\")\n",
    "    ax6.set_title(\n",
    "        \"ðŸŽ¯ Consistencia vs Velocidad\\n(TamaÃ±o = Total PRs)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    # Agregar lÃ­neas de referencia\n",
    "    ax6.axhline(\n",
    "        y=efficiency_relevant[\"Score_Consistencia\"].mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax6.axvline(\n",
    "        x=efficiency_relevant[\"Tiempo_Medio\"].mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    plt.colorbar(scatter2, ax=ax6, shrink=0.8, label=\"Total PRs\")\n",
    "\n",
    "# GrÃ¡fico 7: EvoluciÃ³n de calidad (estandarizaciones) en el tiempo\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "if len(df_prs_merged) > 0:\n",
    "    # Agrupar por mes y calcular promedio de estandarizaciones\n",
    "    df_prs_merged[\"mes\"] = df_prs_merged[\"Fecha_Creacion\"].dt.to_period(\"M\")\n",
    "    quality_evolution = (\n",
    "        df_prs_merged.groupby(\"mes\")[\"Estandarizaciones_Codigo\"].mean().tail(8)\n",
    "    )\n",
    "\n",
    "    ax7.plot(\n",
    "        quality_evolution.index.astype(str),\n",
    "        quality_evolution.values,\n",
    "        \"g-o\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "    )\n",
    "    ax7.set_title(\n",
    "        \"ðŸ“ˆ EvoluciÃ³n de Calidad\\n(Estandarizaciones/PR)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax7.set_ylabel(\"Promedio Estandarizaciones\")\n",
    "    ax7.set_xlabel(\"Mes\")\n",
    "    plt.setp(ax7.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Agregar lÃ­nea de tendencia\n",
    "    if len(quality_evolution) > 1:\n",
    "        z = np.polyfit(range(len(quality_evolution)), quality_evolution.values, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax7.plot(\n",
    "            quality_evolution.index.astype(str),\n",
    "            p(range(len(quality_evolution))),\n",
    "            \"r--\",\n",
    "            alpha=0.8,\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "# Tabla de desarrolladores que necesitan soporte\n",
    "ax8 = fig.add_subplot(gs[3, :])\n",
    "ax8.axis(\"tight\")\n",
    "ax8.axis(\"off\")\n",
    "\n",
    "if len(necesitan_soporte) > 0:\n",
    "    # Preparar datos para la tabla\n",
    "    support_data = []\n",
    "    for author in necesitan_soporte.head(5).index:  # Top 5 que mÃ¡s necesitan soporte\n",
    "        tiempo = necesitan_soporte.loc[author, \"Tiempo_Medio\"]\n",
    "        consistencia = necesitan_soporte.loc[author, \"Score_Consistencia\"]\n",
    "        total_prs = necesitan_soporte.loc[author, \"Total_PRs\"]\n",
    "\n",
    "        # Determinar recomendaciÃ³n\n",
    "        if tiempo > efficiency_relevant[\"Tiempo_Medio\"].quantile(0.75):\n",
    "            recomendacion = \"ðŸŒ Mejorar velocidad de desarrollo\"\n",
    "        elif consistencia < efficiency_relevant[\"Score_Consistencia\"].quantile(0.25):\n",
    "            recomendacion = \"ðŸ“Š Trabajar en consistencia\"\n",
    "        else:\n",
    "            recomendacion = \"ðŸ”„ RevisiÃ³n general de proceso\"\n",
    "\n",
    "        support_data.append(\n",
    "            [\n",
    "                author[:25] + \"...\" if len(author) > 25 else author,\n",
    "                f\"{tiempo:.1f} dÃ­as\",\n",
    "                f\"{consistencia:.1f}%\",\n",
    "                f\"{total_prs} PRs\",\n",
    "                recomendacion,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table_support = ax8.table(\n",
    "        cellText=support_data,\n",
    "        colLabels=[\n",
    "            \"Desarrollador\",\n",
    "            \"Tiempo Promedio\",\n",
    "            \"Consistencia\",\n",
    "            \"Total PRs\",\n",
    "            \"RecomendaciÃ³n\",\n",
    "        ],\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        colWidths=[0.25, 0.15, 0.15, 0.1, 0.35],\n",
    "    )\n",
    "\n",
    "    table_support.auto_set_font_size(False)\n",
    "    table_support.set_fontsize(10)\n",
    "    table_support.scale(1, 2)\n",
    "\n",
    "    # Estilizar tabla\n",
    "    for i in range(len(support_data) + 1):\n",
    "        for j in range(5):\n",
    "            cell = table_support[(i, j)]\n",
    "            if i == 0:  # Header\n",
    "                cell.set_facecolor(\"#e74c3c\")\n",
    "                cell.set_text_props(weight=\"bold\", color=\"white\")\n",
    "            else:\n",
    "                cell.set_facecolor(\"#fff3cd\" if i % 2 == 0 else \"#ffeaa7\")\n",
    "\n",
    "ax8.set_title(\n",
    "    \"âš ï¸ DESARROLLADORES QUE NECESITAN SOPORTE PRIORITARIO\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"ðŸ” ANÃLISIS DE EFICIENCIA Y CALIDAD DEL EQUIPO\",\n",
    "    fontsize=20,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.98,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Resumen ejecutivo de insights\n",
    "print(\"\\n\\nðŸ’¡ INSIGHTS Y RECOMENDACIONES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# CorrelaciÃ³n mÃ¡s fuerte\n",
    "max_corr = corr_matrix.abs().unstack().sort_values(ascending=False)\n",
    "max_corr = max_corr[max_corr < 1.0].iloc[0]\n",
    "corr_vars = corr_matrix.abs().unstack().sort_values(ascending=False).index[1]\n",
    "\n",
    "print(f\"ðŸ”— CorrelaciÃ³n mÃ¡s fuerte: {corr_vars[0]} vs {corr_vars[1]} ({max_corr:.2f})\")\n",
    "print(f\"âš¡ Desarrolladores mÃ¡s eficientes: {len(eficientes)}\")\n",
    "print(f\"âš ï¸  Desarrolladores que necesitan soporte: {len(necesitan_soporte)}\")\n",
    "print(\n",
    "    f\"ðŸ“Š Tiempo promedio del equipo: {efficiency_relevant['Tiempo_Medio'].mean():.1f} dÃ­as\"\n",
    ")\n",
    "print(\n",
    "    f\"ðŸŽ¯ Coeficiente de variaciÃ³n promedio: {efficiency_relevant['Coef_Variacion_Tiempo'].mean():.1f}%\"\n",
    ")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(\n",
    "        f\"ðŸš¨ PRs outliers detectados: {len(outliers)} ({len(outliers) / len(df_prs_merged) * 100:.1f}% del total)\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis de Eficiencia y Calidad completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d6c73",
   "metadata": {},
   "source": [
    "## ðŸ” REPORTE 4: MÃ©tricas de Calidad del CÃ³digo (Previas a QA/RevisiÃ³n Senior)\n",
    "\n",
    "Este reporte analiza especÃ­ficamente las **devoluciones por PR**, proporcionando insights sobre la calidad inicial del cÃ³digo antes de pasar por controles de calidad y revisiones senior. Las devoluciones son un indicador clave de cuÃ¡ntos PRs no cumplen los estÃ¡ndares esperados en el primer intento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORTE 4: MÃ‰TRICAS DE CALIDAD DEL CÃ“DIGO (DEVOLUCIONES)\n",
    "print(\"ðŸ” MÃ‰TRICAS DE CALIDAD DEL CÃ“DIGO - ANÃLISIS DE DEVOLUCIONES\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# 1. EstadÃ­sticas bÃ¡sicas de devoluciones\n",
    "print(\"\\nðŸ“Š ESTADÃSTICAS BÃSICAS DE DEVOLUCIONES:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "devoluciones_stats = df_prs_merged[\"Devoluciones\"].describe()\n",
    "print(f\"Total de PRs analizados: {len(df_prs_merged):,}\")\n",
    "print(f\"Total de devoluciones: {df_prs_merged['Devoluciones'].sum():,}\")\n",
    "print(f\"Promedio de devoluciones por PR: {devoluciones_stats['mean']:.2f}\")\n",
    "print(f\"Mediana: {devoluciones_stats['50%']:.2f}\")\n",
    "print(f\"DesviaciÃ³n estÃ¡ndar: {devoluciones_stats['std']:.2f}\")\n",
    "print(f\"MÃ­nimo: {int(devoluciones_stats['min'])}\")\n",
    "print(f\"MÃ¡ximo: {int(devoluciones_stats['max'])}\")\n",
    "\n",
    "# 2. AnÃ¡lisis de calidad inicial\n",
    "prs_sin_devoluciones = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] == 0])\n",
    "prs_con_devoluciones = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 0])\n",
    "porcentaje_sin_devoluciones = (prs_sin_devoluciones / len(df_prs_merged)) * 100\n",
    "porcentaje_con_devoluciones = (prs_con_devoluciones / len(df_prs_merged)) * 100\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ANÃLISIS DE CALIDAD INICIAL:\")\n",
    "print(\"-\" * 35)\n",
    "print(\n",
    "    f\"PRs aprobados al primer intento: {prs_sin_devoluciones:,} ({porcentaje_sin_devoluciones:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"PRs que requirieron correcciones: {prs_con_devoluciones:,} ({porcentaje_con_devoluciones:.1f}%)\"\n",
    ")\n",
    "\n",
    "# InterpretaciÃ³n de calidad\n",
    "if porcentaje_sin_devoluciones >= 70:\n",
    "    calidad_general = \"EXCELENTE\"\n",
    "    color_calidad = \"ðŸŸ¢\"\n",
    "elif porcentaje_sin_devoluciones >= 50:\n",
    "    calidad_general = \"BUENA\"\n",
    "    color_calidad = \"ðŸŸ¡\"\n",
    "else:\n",
    "    calidad_general = \"REQUIERE MEJORA\"\n",
    "    color_calidad = \"ðŸ”´\"\n",
    "\n",
    "print(f\"Calidad inicial del cÃ³digo: {color_calidad} {calidad_general}\")\n",
    "\n",
    "# 3. DistribuciÃ³n de devoluciones\n",
    "print(f\"\\nðŸ“ˆ DISTRIBUCIÃ“N DE DEVOLUCIONES:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Crear categorÃ­as para las devoluciones\n",
    "dev_bins = [-0.1, 0, 1, 3, 5, float(\"inf\")]\n",
    "dev_labels = [\n",
    "    \"Sin devoluciones\",\n",
    "    \"Baja (1)\",\n",
    "    \"Media (2-3)\",\n",
    "    \"Alta (4-5)\",\n",
    "    \"Muy Alta (>5)\",\n",
    "]\n",
    "df_prs_merged[\"Devoluciones_Categoria\"] = pd.cut(\n",
    "    df_prs_merged[\"Devoluciones\"], bins=dev_bins, labels=dev_labels, right=True\n",
    ")\n",
    "\n",
    "dev_distribution = df_prs_merged[\"Devoluciones_Categoria\"].value_counts()\n",
    "dev_percentages = (dev_distribution / len(df_prs_merged) * 100).round(1)\n",
    "\n",
    "for categoria, count in dev_distribution.items():\n",
    "    percentage = dev_percentages[categoria]\n",
    "    print(f\"{categoria}: {count:,} PRs ({percentage}%)\")\n",
    "\n",
    "print(\"\\nâœ… EstadÃ­sticas bÃ¡sicas de devoluciones completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c347faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. AnÃ¡lisis por desarrollador\n",
    "print(\"\\nðŸ‘¨â€ðŸ’» ANÃLISIS POR DESARROLLADOR:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# EstadÃ­sticas por autor\n",
    "dev_por_autor = df_prs_merged.groupby('Autor')['Devoluciones'].agg([\n",
    "    'count', 'sum', 'mean', 'std'\n",
    "]).round(2)\n",
    "dev_por_autor.columns = ['PRs_Total', 'Dev_Total', 'Dev_Promedio', 'Dev_Std']\n",
    "dev_por_autor['Tasa_Exito'] = ((dev_por_autor['PRs_Total'] - df_prs_merged.groupby('Autor')['Devoluciones'].apply(lambda x: (x > 0).sum())) / dev_por_autor['PRs_Total'] * 100).round(1)\n",
    "dev_por_autor = dev_por_autor.sort_values('Dev_Promedio', ascending=True)\n",
    "\n",
    "print(\"ðŸ† TOP 10 DESARROLLADORES CON MEJOR CALIDAD INICIAL (Menos Devoluciones):\")\n",
    "mejores_devs = dev_por_autor[dev_por_autor['PRs_Total'] >= 3].head(10)\n",
    "for autor, data in mejores_devs.iterrows():\n",
    "    print(f\"{autor}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de Ã©xito\")\n",
    "\n",
    "print(\"\\nâš ï¸  DESARROLLADORES QUE REQUIEREN ATENCIÃ“N (MÃ¡s Devoluciones):\")\n",
    "devs_atencion = dev_por_autor[dev_por_autor['PRs_Total'] >= 3].tail(5)\n",
    "for autor, data in devs_atencion.iterrows():\n",
    "    print(f\"{autor}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de Ã©xito\")\n",
    "\n",
    "# 5. AnÃ¡lisis por repositorio\n",
    "print(\"\\nðŸ“¦ ANÃLISIS POR REPOSITORIO:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "dev_por_repo = df_prs_merged.groupby('Repositorio')['Devoluciones'].agg([\n",
    "    'count', 'sum', 'mean', 'std'\n",
    "]).round(2)\n",
    "dev_por_repo.columns = ['PRs_Total', 'Dev_Total', 'Dev_Promedio', 'Dev_Std']\n",
    "dev_por_repo['Tasa_Exito'] = ((dev_por_repo['PRs_Total'] - df_prs_merged.groupby('Repositorio')['Devoluciones'].apply(lambda x: (x > 0).sum())) / dev_por_repo['PRs_Total'] * 100).round(1)\n",
    "dev_por_repo = dev_por_repo.sort_values('Dev_Promedio', ascending=True)\n",
    "\n",
    "print(\"ðŸ† REPOSITORIOS CON MEJOR CALIDAD DE CÃ“DIGO:\")\n",
    "mejores_repos = dev_por_repo[dev_por_repo['PRs_Total'] >= 3].head(5)\n",
    "for repo, data in mejores_repos.iterrows():\n",
    "    print(f\"{repo}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de Ã©xito ({int(data['PRs_Total'])} PRs)\")\n",
    "\n",
    "print(\"âš ï¸  REPOSITORIOS QUE REQUIEREN ATENCIÃ“N:\")\n",
    "repos_atencion = dev_por_repo[dev_por_repo['PRs_Total'] >= 3].tail(3)\n",
    "for repo, data in repos_atencion.iterrows():\n",
    "    print(f\"{repo}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de Ã©xito ({int(data['PRs_Total'])} PRs)\")\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis por desarrollador y repositorio completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f41bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear visualizaciones especÃ­ficas para devoluciones\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = plt.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Histograma principal de devoluciones (seaborn)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "import seaborn as sns\n",
    "sns.histplot(data=df_prs_merged, x='Devoluciones', bins=15, kde=True, alpha=0.7, \n",
    "             color='skyblue', ax=ax1)\n",
    "ax1.set_title('ðŸ“Š DistribuciÃ³n de Devoluciones por PR\\n(Histograma con Densidad)', \n",
    "             fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('NÃºmero de Devoluciones')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax1.axvline(df_prs_merged['Devoluciones'].mean(), color='red', \n",
    "           linestyle='--', linewidth=2, label=f'Promedio: {df_prs_merged[\"Devoluciones\"].mean():.1f}')\n",
    "ax1.axvline(df_prs_merged['Devoluciones'].median(), color='orange', \n",
    "           linestyle='--', linewidth=2, label=f'Mediana: {df_prs_merged[\"Devoluciones\"].median():.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Agregar anotaciones de insights\n",
    "max_freq = ax1.patches[0].get_height()\n",
    "for patch in ax1.patches:\n",
    "    max_freq = max(max_freq, patch.get_height())\n",
    "\n",
    "# Insight sobre cola larga\n",
    "devoluciones_altas = len(df_prs_merged[df_prs_merged['Devoluciones'] > 3])\n",
    "if devoluciones_altas > 0:\n",
    "    ax1.text(0.7, 0.9, f'âš ï¸ Cola larga detectada:\\n{devoluciones_altas} PRs con >3 devoluciones\\n(Posibles problemas de calidad)', \n",
    "             transform=ax1.transAxes, bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.7),\n",
    "             fontsize=10, verticalalignment='top')\n",
    "\n",
    "# 2. GrÃ¡fico de barras por categorÃ­as\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "categories_order = ['Sin devoluciones', 'Baja (1)', 'Media (2-3)', 'Alta (4-5)', 'Muy Alta (>5)']\n",
    "valid_categories = [cat for cat in categories_order if cat in dev_distribution.index]\n",
    "bars = ax2.bar(range(len(valid_categories)), \n",
    "               [dev_distribution[cat] for cat in valid_categories],\n",
    "               color=['green', 'lightgreen', 'yellow', 'orange', 'red'][:len(valid_categories)])\n",
    "\n",
    "ax2.set_xticks(range(len(valid_categories)))\n",
    "ax2.set_xticklabels([cat.replace(' ', '\\n') for cat in valid_categories], fontsize=9)\n",
    "ax2.set_title('ðŸ“ˆ PRs por CategorÃ­a\\nde Devoluciones', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('NÃºmero de PRs')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar, cat in zip(bars, valid_categories):\n",
    "    height = bar.get_height()\n",
    "    percentage = dev_percentages[cat]\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, height + 0.5, \n",
    "            f'{int(height)}\\n({percentage:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 3. Top desarrolladores con mejor calidad\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "top_devs = mejores_devs.head(8)\n",
    "bars = ax3.barh(range(len(top_devs)), top_devs['Tasa_Exito'], \n",
    "                color='lightgreen', edgecolor='darkgreen')\n",
    "ax3.set_yticks(range(len(top_devs)))\n",
    "ax3.set_yticklabels([dev[:15] + '...' if len(dev) > 15 else dev for dev in top_devs.index])\n",
    "ax3.set_title('ðŸ† Top Desarrolladores\\n(Tasa de Ã‰xito %)', fontweight='bold', fontsize=12)\n",
    "ax3.set_xlabel('Tasa de Ã‰xito (%)')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars, top_devs['Tasa_Exito'])):\n",
    "    ax3.text(value + 1, i, f'{value:.0f}%', va='center', fontsize=9)\n",
    "\n",
    "# 4. Desarrolladores que requieren atenciÃ³n\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "devs_problemas = devs_atencion\n",
    "bars = ax4.barh(range(len(devs_problemas)), devs_problemas['Dev_Promedio'], \n",
    "                color='lightcoral', edgecolor='darkred')\n",
    "ax4.set_yticks(range(len(devs_problemas)))\n",
    "ax4.set_yticklabels([dev[:15] + '...' if len(dev) > 15 else dev for dev in devs_problemas.index])\n",
    "ax4.set_title('âš ï¸ Desarrolladores que\\nRequieren AtenciÃ³n', fontweight='bold', fontsize=12)\n",
    "ax4.set_xlabel('Promedio de Devoluciones')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars, devs_problemas['Dev_Promedio'])):\n",
    "    ax4.text(value + 0.05, i, f'{value:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# 5. AnÃ¡lisis de repositorios\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "repos_chart = mejores_repos\n",
    "bars = ax5.bar(range(len(repos_chart)), repos_chart['Tasa_Exito'], \n",
    "               color='lightblue', edgecolor='darkblue')\n",
    "ax5.set_xticks(range(len(repos_chart)))\n",
    "ax5.set_xticklabels([repo[:8] + '...' if len(repo) > 8 else repo \n",
    "                    for repo in repos_chart.index], rotation=45, ha='right')\n",
    "ax5.set_title('ðŸ“¦ Repositorios con\\nMejor Calidad', fontweight='bold', fontsize=12)\n",
    "ax5.set_ylabel('Tasa de Ã‰xito (%)')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar, value in zip(bars, repos_chart['Tasa_Exito']):\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{value:.0f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 6. CorrelaciÃ³n devoluciones vs otras mÃ©tricas\n",
    "ax6 = fig.add_subplot(gs[2, 0])\n",
    "if 'Tiempo_Resolucion' in df_prs_merged.columns:\n",
    "    scatter = ax6.scatter(df_prs_merged['Devoluciones'], \n",
    "                         df_prs_merged['Tiempo_Resolucion'],\n",
    "                         alpha=0.6, color='purple')\n",
    "    ax6.set_title('ðŸ”— Devoluciones vs\\nTiempo de ResoluciÃ³n', fontweight='bold', fontsize=12)\n",
    "    ax6.set_xlabel('NÃºmero de Devoluciones')\n",
    "    ax6.set_ylabel('Tiempo de ResoluciÃ³n (dÃ­as)')\n",
    "    \n",
    "    # LÃ­nea de tendencia\n",
    "    z = np.polyfit(df_prs_merged['Devoluciones'], df_prs_merged['Tiempo_Resolucion'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax6.plot(df_prs_merged['Devoluciones'], p(df_prs_merged['Devoluciones']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    corr = df_prs_merged['Devoluciones'].corr(df_prs_merged['Tiempo_Resolucion'])\n",
    "    ax6.text(0.05, 0.95, f'CorrelaciÃ³n: {corr:.3f}', transform=ax6.transAxes, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# 7. CorrelaciÃ³n devoluciones vs estandarizaciones\n",
    "ax7 = fig.add_subplot(gs[2, 1])\n",
    "scatter = ax7.scatter(df_prs_merged['Devoluciones'], \n",
    "                     df_prs_merged['Estandarizaciones_Codigo'],\n",
    "                     alpha=0.6, color='orange')\n",
    "ax7.set_title('ðŸ”— Devoluciones vs\\nEstandarizaciones', fontweight='bold', fontsize=12)\n",
    "ax7.set_xlabel('NÃºmero de Devoluciones')\n",
    "ax7.set_ylabel('Estandarizaciones de CÃ³digo')\n",
    "\n",
    "# LÃ­nea de tendencia\n",
    "z = np.polyfit(df_prs_merged['Devoluciones'], df_prs_merged['Estandarizaciones_Codigo'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax7.plot(df_prs_merged['Devoluciones'], p(df_prs_merged['Devoluciones']), \"r--\", alpha=0.8)\n",
    "\n",
    "corr = df_prs_merged['Devoluciones'].corr(df_prs_merged['Estandarizaciones_Codigo'])\n",
    "ax7.text(0.05, 0.95, f'CorrelaciÃ³n: {corr:.3f}', transform=ax7.transAxes, \n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# 8. Box plot comparativo por repositorio\n",
    "ax8 = fig.add_subplot(gs[2, 2])\n",
    "repos_principales = df_prs_merged['Repositorio'].value_counts().head(4).index\n",
    "box_data = [df_prs_merged[df_prs_merged['Repositorio'] == repo]['Devoluciones'].values \n",
    "           for repo in repos_principales]\n",
    "\n",
    "bp = ax8.boxplot(box_data, labels=[repo[:8] + '...' if len(repo) > 8 else repo \n",
    "                                  for repo in repos_principales], patch_artist=True)\n",
    "colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightcoral']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax8.set_title('ðŸ“¦ DistribuciÃ³n de Devoluciones\\npor Repositorio', fontweight='bold', fontsize=12)\n",
    "ax8.set_ylabel('NÃºmero de Devoluciones')\n",
    "ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('ðŸ” ANÃLISIS COMPLETO DE MÃ‰TRICAS DE CALIDAD - DEVOLUCIONES', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Visualizaciones de mÃ©tricas de calidad (devoluciones) completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Insights especÃ­ficos y recomendaciones\n",
    "print(\"\\n\\nðŸ’¡ INSIGHTS Y RECOMENDACIONES DE CALIDAD:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# MÃ©tricas clave\n",
    "total_dev = df_prs_merged[\"Devoluciones\"].sum()\n",
    "promedio_dev = df_prs_merged[\"Devoluciones\"].mean()\n",
    "tasa_exito_general = porcentaje_sin_devoluciones\n",
    "\n",
    "print(f\"ðŸ“Š MÃ‰TRICAS CLAVE DE CALIDAD:\")\n",
    "print(f\"   â€¢ Total de devoluciones: {total_dev:,}\")\n",
    "print(f\"   â€¢ Promedio por PR: {promedio_dev:.2f}\")\n",
    "print(f\"   â€¢ Tasa de Ã©xito general: {tasa_exito_general:.1f}%\")\n",
    "print(f\"   â€¢ Estado de calidad: {color_calidad} {calidad_general}\")\n",
    "\n",
    "# AnÃ¡lisis de cola larga\n",
    "prs_cola_larga = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 3])\n",
    "porcentaje_cola_larga = (prs_cola_larga / len(df_prs_merged)) * 100\n",
    "\n",
    "print(f\"\\nðŸ” ANÃLISIS DE COLA LARGA:\")\n",
    "if prs_cola_larga > 0:\n",
    "    print(\n",
    "        f\"   â€¢ PRs con >3 devoluciones: {prs_cola_larga} ({porcentaje_cola_larga:.1f}%)\"\n",
    "    )\n",
    "    if porcentaje_cola_larga > 15:\n",
    "        print(f\"   âš ï¸  ALERTA: Cola larga significativa detectada\")\n",
    "        print(\n",
    "            f\"   ðŸ“ Sugiere: Problemas sistemÃ¡ticos de calidad o criterios poco claros\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   âœ… Cola larga dentro de parÃ¡metros normales\")\n",
    "else:\n",
    "    print(f\"   âœ… No se detecta cola larga problemÃ¡tica\")\n",
    "\n",
    "# Correlaciones importantes\n",
    "corr_tiempo = (\n",
    "    df_prs_merged[\"Devoluciones\"].corr(df_prs_merged[\"Tiempo_Resolucion\"])\n",
    "    if \"Tiempo_Resolucion\" in df_prs_merged.columns\n",
    "    else 0\n",
    ")\n",
    "corr_est = df_prs_merged[\"Devoluciones\"].corr(df_prs_merged[\"Estandarizaciones_Codigo\"])\n",
    "\n",
    "print(f\"\\nðŸ”— CORRELACIONES IMPORTANTES:\")\n",
    "if abs(corr_tiempo) > 0.3:\n",
    "    print(f\"   â€¢ Devoluciones vs Tiempo: {corr_tiempo:.3f} (correlaciÃ³n significativa)\")\n",
    "    print(f\"     â†’ MÃ¡s devoluciones = Mayor tiempo de resoluciÃ³n\")\n",
    "else:\n",
    "    print(f\"   â€¢ Devoluciones vs Tiempo: {corr_tiempo:.3f} (correlaciÃ³n dÃ©bil)\")\n",
    "\n",
    "if abs(corr_est) > 0.3:\n",
    "    print(\n",
    "        f\"   â€¢ Devoluciones vs Estandarizaciones: {corr_est:.3f} (correlaciÃ³n significativa)\"\n",
    "    )\n",
    "    if corr_est > 0:\n",
    "        print(\n",
    "            f\"     â†’ MÃ¡s devoluciones = MÃ¡s estandarizaciones aplicadas posteriormente\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"   â€¢ Devoluciones vs Estandarizaciones: {corr_est:.3f} (correlaciÃ³n dÃ©bil)\")\n",
    "\n",
    "# Generar alertas especÃ­ficas\n",
    "alertas_calidad = []\n",
    "\n",
    "if tasa_exito_general < 50:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"CRÃTICA\",\n",
    "            \"mensaje\": f\"Tasa de Ã©xito muy baja ({tasa_exito_general:.1f}%)\",\n",
    "            \"accion\": \"Revisar proceso completo de desarrollo y criterios de calidad\",\n",
    "        }\n",
    "    )\n",
    "elif tasa_exito_general < 70:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"ALTA\",\n",
    "            \"mensaje\": f\"Tasa de Ã©xito baja ({tasa_exito_general:.1f}%)\",\n",
    "            \"accion\": \"Implementar mejores prÃ¡cticas de cÃ³digo y revisiones previas\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "if porcentaje_cola_larga > 15:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"ALTA\",\n",
    "            \"mensaje\": f\"Cola larga detectada ({porcentaje_cola_larga:.1f}% con >3 devoluciones)\",\n",
    "            \"accion\": \"Clarificar criterios de calidad y mejorar capacitaciÃ³n\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "if promedio_dev > 2:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"MEDIA\",\n",
    "            \"mensaje\": f\"Promedio alto de devoluciones ({promedio_dev:.1f})\",\n",
    "            \"accion\": \"Implementar checklist de calidad antes de PR\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Mostrar alertas\n",
    "if len(alertas_calidad) > 0:\n",
    "    print(f\"\\nðŸš¨ ALERTAS DE CALIDAD:\")\n",
    "    for i, alerta in enumerate(alertas_calidad, 1):\n",
    "        icono = (\n",
    "            \"ðŸ”´\"\n",
    "            if alerta[\"nivel\"] == \"CRÃTICA\"\n",
    "            else \"ðŸŸ \"\n",
    "            if alerta[\"nivel\"] == \"ALTA\"\n",
    "            else \"ðŸŸ¡\"\n",
    "        )\n",
    "        print(f\"   {i}. {icono} {alerta['nivel']}: {alerta['mensaje']}\")\n",
    "        print(f\"      â†’ AcciÃ³n: {alerta['accion']}\")\n",
    "else:\n",
    "    print(f\"\\nâœ… No se detectaron alertas crÃ­ticas de calidad\")\n",
    "\n",
    "# Mejores prÃ¡cticas identificadas\n",
    "print(f\"\\nðŸ† MEJORES PRÃCTICAS IDENTIFICADAS:\")\n",
    "if len(mejores_devs) > 0:\n",
    "    mejor_dev = mejores_devs.index[0]\n",
    "    mejor_tasa = mejores_devs.iloc[0][\"Tasa_Exito\"]\n",
    "    print(f\"   â€¢ Mejor desarrollador: {mejor_dev} ({mejor_tasa:.0f}% tasa de Ã©xito)\")\n",
    "\n",
    "if len(mejores_repos) > 0:\n",
    "    mejor_repo = mejores_repos.index[0]\n",
    "    mejor_repo_tasa = mejores_repos.iloc[0][\"Tasa_Exito\"]\n",
    "    print(\n",
    "        f\"   â€¢ Mejor repositorio: {mejor_repo} ({mejor_repo_tasa:.0f}% tasa de Ã©xito)\"\n",
    "    )\n",
    "\n",
    "# Recomendaciones prioritarias\n",
    "print(f\"\\nðŸŽ¯ RECOMENDACIONES PRIORITARIAS:\")\n",
    "\n",
    "if tasa_exito_general < 70:\n",
    "    print(f\"   1. ðŸ”§ Implementar cÃ³digo de revisiÃ³n peer-to-peer antes de PR\")\n",
    "    print(f\"   2. ðŸ“š Crear guÃ­as de estÃ¡ndares de cÃ³digo mÃ¡s claras\")\n",
    "    print(f\"   3. ðŸŽ“ Programa de capacitaciÃ³n en mejores prÃ¡cticas\")\n",
    "\n",
    "if len(devs_atencion) > 0:\n",
    "    print(f\"   4. ðŸ‘¥ Mentoring especÃ­fico para desarrolladores con baja tasa de Ã©xito\")\n",
    "    print(f\"   5. ðŸ” RevisiÃ³n de criterios de calidad para uniformidad\")\n",
    "\n",
    "if porcentaje_cola_larga > 10:\n",
    "    print(f\"   6. ðŸ“‹ Checklist obligatorio de calidad antes de enviar PR\")\n",
    "    print(f\"   7. ðŸ¤– Herramientas automatizadas de anÃ¡lisis de cÃ³digo\")\n",
    "\n",
    "print(f\"\\nðŸ“‹ RESUMEN EJECUTIVO:\")\n",
    "print(f\"   â€¢ Calidad inicial: {color_calidad} {calidad_general}\")\n",
    "print(f\"   â€¢ Tasa de Ã©xito: {tasa_exito_general:.1f}%\")\n",
    "print(\n",
    "    f\"   â€¢ Desarrolladores destacados: {len(mejores_devs[mejores_devs['Tasa_Exito'] > 80])}\"\n",
    ")\n",
    "print(\n",
    "    f\"   â€¢ Repositorios con buena calidad: {len(mejores_repos[mejores_repos['Tasa_Exito'] > 80])}\"\n",
    ")\n",
    "\n",
    "# InterpretaciÃ³n de cola larga especÃ­fica\n",
    "if prs_cola_larga > 0:\n",
    "    print(f\"   â€¢ Cola larga: {prs_cola_larga} PRs requieren atenciÃ³n especial\")\n",
    "    if porcentaje_cola_larga > 15:\n",
    "        print(f\"   ðŸ”´ Indica problemas sistemÃ¡ticos de calidad\")\n",
    "    else:\n",
    "        print(f\"   ðŸŸ¡ Dentro de parÃ¡metros normales pero monitoreable\")\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis de MÃ©tricas de Calidad del CÃ³digo COMPLETADO!\")\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33776faf",
   "metadata": {},
   "source": [
    "## ðŸ‘¥ REPORTE 5: AnÃ¡lisis de Devoluciones por Autor\n",
    "\n",
    "Este reporte se enfoca especÃ­ficamente en el anÃ¡lisis de **devoluciones por desarrollador**, identificando patrones de calidad individual y proporcionando insights sobre quÃ© desarrolladores entregan cÃ³digo que cumple los criterios de QA versus aquellos que requieren mÃºltiples iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ef109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORTE 5: ANÃLISIS DE DEVOLUCIONES POR AUTOR\n",
    "print(\"ðŸ‘¥ ANÃLISIS DETALLADO DE DEVOLUCIONES POR AUTOR\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# 1. EstadÃ­sticas completas por autor\n",
    "print(\"\\nðŸ“Š ESTADÃSTICAS DETALLADAS POR DESARROLLADOR:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Crear anÃ¡lisis completo por autor\n",
    "autor_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"]\n",
    "    .agg(\n",
    "        [\n",
    "            \"count\",  # Total de PRs\n",
    "            \"sum\",  # Total de devoluciones\n",
    "            \"mean\",  # Promedio de devoluciones\n",
    "            \"median\",  # Mediana de devoluciones\n",
    "            \"std\",  # DesviaciÃ³n estÃ¡ndar\n",
    "            \"min\",  # MÃ­nimo de devoluciones\n",
    "            \"max\",  # MÃ¡ximo de devoluciones\n",
    "        ]\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "autor_stats.columns = [\n",
    "    \"PRs_Total\",\n",
    "    \"Dev_Total\",\n",
    "    \"Dev_Promedio\",\n",
    "    \"Dev_Mediana\",\n",
    "    \"Dev_Std\",\n",
    "    \"Dev_Min\",\n",
    "    \"Dev_Max\",\n",
    "]\n",
    "\n",
    "# Calcular mÃ©tricas adicionales\n",
    "autor_stats[\"Tasa_Exito\"] = (\n",
    "    (\n",
    "        autor_stats[\"PRs_Total\"]\n",
    "        - df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"].apply(lambda x: (x > 0).sum())\n",
    "    )\n",
    "    / autor_stats[\"PRs_Total\"]\n",
    "    * 100\n",
    ").round(1)\n",
    "autor_stats[\"Coef_Variacion\"] = (\n",
    "    (autor_stats[\"Dev_Std\"] / autor_stats[\"Dev_Promedio\"] * 100).fillna(0).round(1)\n",
    ")\n",
    "autor_stats[\"PRs_Sin_Dev\"] = df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"].apply(\n",
    "    lambda x: (x == 0).sum()\n",
    ")\n",
    "autor_stats[\"PRs_Con_Dev\"] = autor_stats[\"PRs_Total\"] - autor_stats[\"PRs_Sin_Dev\"]\n",
    "\n",
    "# Filtrar autores con al menos 3 PRs para anÃ¡lisis mÃ¡s representativo\n",
    "autor_stats_filtered = autor_stats[autor_stats[\"PRs_Total\"] >= 3].copy()\n",
    "\n",
    "print(f\"Total de desarrolladores analizados: {len(autor_stats)}\")\n",
    "print(f\"Desarrolladores con â‰¥3 PRs: {len(autor_stats_filtered)}\")\n",
    "print(f\"Promedio general de devoluciones: {df_prs_merged['Devoluciones'].mean():.2f}\")\n",
    "\n",
    "# 2. ClasificaciÃ³n de desarrolladores por calidad\n",
    "print(f\"\\nðŸ† CLASIFICACIÃ“N POR CALIDAD DE CÃ“DIGO:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Clasificar desarrolladores\n",
    "excelentes = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 80)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 1)\n",
    "]\n",
    "buenos = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 60)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 2)\n",
    "]\n",
    "regulares = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 40)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 3)\n",
    "]\n",
    "necesitan_atencion = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] < 40)\n",
    "    | (autor_stats_filtered[\"Dev_Promedio\"] > 3)\n",
    "]\n",
    "\n",
    "print(f\"ðŸŸ¢ EXCELENTES (Tasa â‰¥80%, Prom â‰¤1): {len(excelentes)} desarrolladores\")\n",
    "for dev in excelentes.head(3).index:\n",
    "    data = excelentes.loc[dev]\n",
    "    print(\n",
    "        f\"   â€¢ {dev}: {data['Tasa_Exito']:.0f}% Ã©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸŸ¡ BUENOS (Tasa â‰¥60%, Prom â‰¤2): {len(buenos)} desarrolladores\")\n",
    "for dev in buenos.head(3).index:\n",
    "    data = buenos.loc[dev]\n",
    "    print(\n",
    "        f\"   â€¢ {dev}: {data['Tasa_Exito']:.0f}% Ã©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸŸ  REGULARES: {len(regulares)} desarrolladores\")\n",
    "for dev in regulares.head(3).index:\n",
    "    data = regulares.loc[dev]\n",
    "    print(\n",
    "        f\"   â€¢ {dev}: {data['Tasa_Exito']:.0f}% Ã©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸ”´ NECESITAN ATENCIÃ“N: {len(necesitan_atencion)} desarrolladores\")\n",
    "for dev in necesitan_atencion.index:\n",
    "    data = necesitan_atencion.loc[dev]\n",
    "    print(\n",
    "        f\"   â€¢ {dev}: {data['Tasa_Exito']:.0f}% Ã©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis estadÃ­stico por autor completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14580e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crear visualizaciones especÃ­ficas por autor\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = plt.GridSpec(4, 2, figure=fig, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# 1. GrÃ¡fico de barras principal: Promedio de devoluciones por autor (seaborn)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "# Ordenar por promedio de devoluciones para mejor visualizaciÃ³n\n",
    "autor_stats_sorted = autor_stats_filtered.sort_values(\"Dev_Promedio\")\n",
    "\n",
    "# Crear colores basados en la clasificaciÃ³n\n",
    "colors_clasificacion = []\n",
    "for autor in autor_stats_sorted.index:\n",
    "    if autor in excelentes.index:\n",
    "        colors_clasificacion.append(\"green\")\n",
    "    elif autor in buenos.index:\n",
    "        colors_clasificacion.append(\"gold\")\n",
    "    elif autor in regulares.index:\n",
    "        colors_clasificacion.append(\"orange\")\n",
    "    else:\n",
    "        colors_clasificacion.append(\"red\")\n",
    "\n",
    "bars = sns.barplot(\n",
    "    data=df_prs_merged[df_prs_merged[\"Autor\"].isin(autor_stats_sorted.index)],\n",
    "    x=\"Autor\",\n",
    "    y=\"Devoluciones\",\n",
    "    estimator=np.mean,\n",
    "    order=autor_stats_sorted.index,\n",
    "    palette=colors_clasificacion,\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_title(\n",
    "    \"ðŸ“Š PROMEDIO DE DEVOLUCIONES POR DESARROLLADOR\\n(Verde=Excelente, Amarillo=Bueno, Naranja=Regular, Rojo=Necesita AtenciÃ³n)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax1.set_xlabel(\"Desarrollador\")\n",
    "ax1.set_ylabel(\"Promedio de Devoluciones\")\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Agregar lÃ­nea de promedio general\n",
    "promedio_general = df_prs_merged[\"Devoluciones\"].mean()\n",
    "ax1.axhline(\n",
    "    y=promedio_general,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=f\"Promedio General: {promedio_general:.2f}\",\n",
    ")\n",
    "ax1.legend()\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, autor) in enumerate(zip(bars.patches, autor_stats_sorted.index)):\n",
    "    valor = autor_stats_sorted.loc[autor, \"Dev_Promedio\"]\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.05,\n",
    "        f\"{valor:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# 2. Box plot: DistribuciÃ³n de devoluciones por autor (seaborn)\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "# Limitar a desarrolladores mÃ¡s activos para mejor visualizaciÃ³n\n",
    "top_devs_boxplot = (\n",
    "    autor_stats_filtered.sort_values(\"PRs_Total\", ascending=False).head(8).index\n",
    ")\n",
    "df_boxplot = df_prs_merged[df_prs_merged[\"Autor\"].isin(top_devs_boxplot)]\n",
    "\n",
    "sns.boxplot(data=df_boxplot, x=\"Autor\", y=\"Devoluciones\", ax=ax2)\n",
    "ax2.set_title(\n",
    "    \"ðŸ“¦ DISTRIBUCIÃ“N DE DEVOLUCIONES POR DESARROLLADOR (Top 8 mÃ¡s activos)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax2.set_xlabel(\"Desarrollador\")\n",
    "ax2.set_ylabel(\"NÃºmero de Devoluciones\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 3. GrÃ¡fico de dispersiÃ³n: PRs vs Promedio de devoluciones\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "scatter = ax3.scatter(\n",
    "    autor_stats_filtered[\"PRs_Total\"],\n",
    "    autor_stats_filtered[\"Dev_Promedio\"],\n",
    "    c=[\n",
    "        colors_clasificacion[list(autor_stats_sorted.index).index(autor)]\n",
    "        if autor in autor_stats_sorted.index\n",
    "        else \"gray\"\n",
    "        for autor in autor_stats_filtered.index\n",
    "    ],\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "\n",
    "ax3.set_title(\n",
    "    \"ðŸŽ¯ Experiencia vs Calidad\\n(PRs Total vs Promedio Devoluciones)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax3.set_xlabel(\"Total de PRs\")\n",
    "ax3.set_ylabel(\"Promedio de Devoluciones\")\n",
    "\n",
    "# Agregar nombres de desarrolladores problemÃ¡ticos\n",
    "for autor in necesitan_atencion.index:\n",
    "    if autor in autor_stats_filtered.index:\n",
    "        x = autor_stats_filtered.loc[autor, \"PRs_Total\"]\n",
    "        y = autor_stats_filtered.loc[autor, \"Dev_Promedio\"]\n",
    "        ax3.annotate(\n",
    "            autor[:10],\n",
    "            (x, y),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "# 4. GrÃ¡fico de barras: Tasa de Ã©xito por desarrollador\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "autor_stats_exito = autor_stats_filtered.sort_values(\"Tasa_Exito\", ascending=False)\n",
    "bars_exito = ax4.bar(\n",
    "    range(len(autor_stats_exito)),\n",
    "    autor_stats_exito[\"Tasa_Exito\"],\n",
    "    color=[\n",
    "        colors_clasificacion[list(autor_stats_sorted.index).index(autor)]\n",
    "        if autor in autor_stats_sorted.index\n",
    "        else \"gray\"\n",
    "        for autor in autor_stats_exito.index\n",
    "    ],\n",
    ")\n",
    "\n",
    "ax4.set_xticks(range(len(autor_stats_exito)))\n",
    "ax4.set_xticklabels(\n",
    "    [\n",
    "        autor[:10] + \"...\" if len(autor) > 10 else autor\n",
    "        for autor in autor_stats_exito.index\n",
    "    ],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "ax4.set_title(\n",
    "    \"ðŸ† Tasa de Ã‰xito por Desarrollador\\n(% PRs sin devoluciones)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax4.set_ylabel(\"Tasa de Ã‰xito (%)\")\n",
    "ax4.axhline(y=70, color=\"orange\", linestyle=\"--\", alpha=0.7, label=\"Meta: 70%\")\n",
    "ax4.legend()\n",
    "\n",
    "# 5. Heatmap de mÃ©tricas por desarrollador\n",
    "ax5 = fig.add_subplot(gs[3, :])\n",
    "# Seleccionar mÃ©tricas clave para el heatmap\n",
    "metrics_heatmap = autor_stats_filtered[\n",
    "    [\"Dev_Promedio\", \"Tasa_Exito\", \"Coef_Variacion\", \"PRs_Total\"]\n",
    "].copy()\n",
    "metrics_heatmap_norm = metrics_heatmap.copy()\n",
    "\n",
    "# Normalizar para el heatmap (invertir donde menor es mejor)\n",
    "metrics_heatmap_norm[\"Dev_Promedio\"] = 100 - (\n",
    "    metrics_heatmap[\"Dev_Promedio\"] / metrics_heatmap[\"Dev_Promedio\"].max() * 100\n",
    ")\n",
    "metrics_heatmap_norm[\"Coef_Variacion\"] = 100 - (\n",
    "    metrics_heatmap[\"Coef_Variacion\"] / metrics_heatmap[\"Coef_Variacion\"].max() * 100\n",
    ")\n",
    "metrics_heatmap_norm[\"PRs_Total\"] = (\n",
    "    metrics_heatmap[\"PRs_Total\"] / metrics_heatmap[\"PRs_Total\"].max() * 100\n",
    ")\n",
    "\n",
    "# Limitar a top 10 desarrolladores por PRs para mejor visualizaciÃ³n\n",
    "top_10_devs = metrics_heatmap_norm.sort_values(\"PRs_Total\", ascending=False).head(10)\n",
    "\n",
    "im = ax5.imshow(top_10_devs.T.values, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=100)\n",
    "ax5.set_xticks(range(len(top_10_devs)))\n",
    "ax5.set_xticklabels(\n",
    "    [dev[:12] + \"...\" if len(dev) > 12 else dev for dev in top_10_devs.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "ax5.set_yticks(range(len(top_10_devs.columns)))\n",
    "ax5.set_yticklabels(\n",
    "    [\"Calidad CÃ³digo\", \"Tasa Ã‰xito (%)\", \"Consistencia\", \"Experiencia (PRs)\"]\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"ðŸ”¥ MAPA DE CALOR: MÃ‰TRICAS DE DESARROLLADORES\\n(Verde=Excelente, Amarillo=Bueno, Rojo=Necesita Mejora)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "\n",
    "# Agregar valores en el heatmap\n",
    "for i in range(len(top_10_devs.columns)):\n",
    "    for j in range(len(top_10_devs)):\n",
    "        value = top_10_devs.iloc[j, i]\n",
    "        ax5.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{value:.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=9,\n",
    "            color=\"white\" if value < 50 else \"black\",\n",
    "        )\n",
    "\n",
    "# Agregar colorbar\n",
    "cbar = plt.colorbar(im, ax=ax5, shrink=0.8)\n",
    "cbar.set_label(\"PuntuaciÃ³n de Calidad (0-100)\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"ðŸ‘¥ ANÃLISIS COMPLETO DE DEVOLUCIONES POR DESARROLLADOR\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.98,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Visualizaciones de anÃ¡lisis por autor completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aedee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Insights especÃ­ficos y planes de acciÃ³n por desarrollador\n",
    "print(\"\\n\\nðŸ’¡ INSIGHTS DETALLADOS Y PLANES DE ACCIÃ“N:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# AnÃ¡lisis de patrones por categorÃ­a\n",
    "print(f\"ðŸ“Š RESUMEN POR CATEGORÃAS:\")\n",
    "print(\n",
    "    f\"   ðŸŸ¢ Desarrolladores EXCELENTES: {len(excelentes)} ({len(excelentes) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸŸ¡ Desarrolladores BUENOS: {len(buenos)} ({len(buenos) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸŸ  Desarrolladores REGULARES: {len(regulares)} ({len(regulares) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   ðŸ”´ Desarrolladores que NECESITAN ATENCIÃ“N: {len(necesitan_atencion)} ({len(necesitan_atencion) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# AnÃ¡lisis de problemÃ¡ticas especÃ­ficas\n",
    "print(f\"\\nðŸ” ANÃLISIS DE PROBLEMÃTICAS ESPECÃFICAS:\")\n",
    "\n",
    "# Desarrolladores con alta variabilidad\n",
    "alta_variabilidad = autor_stats_filtered[autor_stats_filtered[\"Coef_Variacion\"] > 100]\n",
    "if len(alta_variabilidad) > 0:\n",
    "    print(f\"\\nâš ï¸  DESARROLLADORES CON ALTA VARIABILIDAD ({len(alta_variabilidad)}):\")\n",
    "    print(\"   â†’ Posible falta de comprensiÃ³n consistente de requisitos\")\n",
    "    for dev in alta_variabilidad.index:\n",
    "        cv = alta_variabilidad.loc[dev, \"Coef_Variacion\"]\n",
    "        prom = alta_variabilidad.loc[dev, \"Dev_Promedio\"]\n",
    "        print(f\"   â€¢ {dev}: CV={cv:.0f}%, Promedio={prom:.1f}\")\n",
    "\n",
    "# Desarrolladores con muchos PRs pero alta tasa de devoluciones\n",
    "experimentados_problematicos = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"PRs_Total\"] >= 5)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] > 2)\n",
    "]\n",
    "if len(experimentados_problematicos) > 0:\n",
    "    print(\n",
    "        f\"\\nâš ï¸  DESARROLLADORES EXPERIMENTADOS CON PROBLEMAS DE CALIDAD ({len(experimentados_problematicos)}):\"\n",
    "    )\n",
    "    print(\n",
    "        \"   â†’ Posibles malos hÃ¡bitos establecidos o falta de actualizaciÃ³n en estÃ¡ndares\"\n",
    "    )\n",
    "    for dev in experimentados_problematicos.index:\n",
    "        prs = experimentados_problematicos.loc[dev, \"PRs_Total\"]\n",
    "        prom = experimentados_problematicos.loc[dev, \"Dev_Promedio\"]\n",
    "        tasa = experimentados_problematicos.loc[dev, \"Tasa_Exito\"]\n",
    "        print(f\"   â€¢ {dev}: {int(prs)} PRs, {prom:.1f} prom dev, {tasa:.0f}% Ã©xito\")\n",
    "\n",
    "# Desarrolladores nuevos con potencial\n",
    "nuevos_prometedores = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"PRs_Total\"] <= 5)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 1.5)\n",
    "]\n",
    "if len(nuevos_prometedores) > 0:\n",
    "    print(f\"\\nðŸŒŸ DESARROLLADORES NUEVOS CON POTENCIAL ({len(nuevos_prometedores)}):\")\n",
    "    print(\"   â†’ Mantener buenas prÃ¡cticas y mentoring\")\n",
    "    for dev in nuevos_prometedores.index:\n",
    "        prs = nuevos_prometedores.loc[dev, \"PRs_Total\"]\n",
    "        prom = nuevos_prometedores.loc[dev, \"Dev_Promedio\"]\n",
    "        print(f\"   â€¢ {dev}: {int(prs)} PRs, {prom:.1f} prom dev\")\n",
    "\n",
    "# Generar planes de acciÃ³n especÃ­ficos\n",
    "print(f\"\\nðŸŽ¯ PLANES DE ACCIÃ“N ESPECÃFICOS:\")\n",
    "\n",
    "# Para desarrolladores que necesitan atenciÃ³n\n",
    "if len(necesitan_atencion) > 0:\n",
    "    print(f\"\\nðŸ”´ PLAN PARA DESARROLLADORES QUE NECESITAN ATENCIÃ“N:\")\n",
    "    for dev in necesitan_atencion.index:\n",
    "        data = necesitan_atencion.loc[dev]\n",
    "        print(f\"\\n   ðŸ‘¤ {dev}:\")\n",
    "        print(\n",
    "            f\"      ðŸ“Š MÃ©tricas: {data['Tasa_Exito']:.0f}% Ã©xito, {data['Dev_Promedio']:.1f} prom dev\"\n",
    "        )\n",
    "\n",
    "        # DiagnÃ³stico especÃ­fico\n",
    "        if data[\"Dev_Promedio\"] > 3:\n",
    "            print(f\"      ðŸ” DiagnÃ³stico: Promedio muy alto de devoluciones\")\n",
    "            print(f\"      ðŸ’¡ Recomendaciones:\")\n",
    "            print(f\"         - RevisiÃ³n exhaustiva de estÃ¡ndares de cÃ³digo\")\n",
    "            print(f\"         - Mentoring 1:1 con desarrollador senior\")\n",
    "            print(f\"         - Implementar checklist personal antes de PR\")\n",
    "\n",
    "        if data[\"Tasa_Exito\"] < 30:\n",
    "            print(f\"      ðŸ” DiagnÃ³stico: Muy baja tasa de Ã©xito al primer intento\")\n",
    "            print(f\"      ðŸ’¡ Recomendaciones:\")\n",
    "            print(f\"         - CapacitaciÃ³n especÃ­fica en testing\")\n",
    "            print(f\"         - RevisiÃ³n de comprensiÃ³n de requisitos\")\n",
    "            print(f\"         - Pair programming con desarrolladores excelentes\")\n",
    "\n",
    "        if data[\"Coef_Variacion\"] > 150:\n",
    "            print(f\"      ðŸ” DiagnÃ³stico: Alta inconsistencia en calidad\")\n",
    "            print(f\"      ðŸ’¡ Recomendaciones:\")\n",
    "            print(f\"         - Estandarizar proceso personal de desarrollo\")\n",
    "            print(f\"         - CapacitaciÃ³n en metodologÃ­as de calidad\")\n",
    "\n",
    "# Para desarrolladores excelentes\n",
    "if len(excelentes) > 0:\n",
    "    print(f\"\\nðŸŸ¢ PLAN PARA DESARROLLADORES EXCELENTES:\")\n",
    "    print(f\"   ðŸŽ¯ Acciones:\")\n",
    "    print(f\"      - Asignar como mentores de desarrolladores que necesitan atenciÃ³n\")\n",
    "    print(f\"      - Documentar sus mejores prÃ¡cticas\")\n",
    "    print(f\"      - Considerar para roles de liderazgo tÃ©cnico\")\n",
    "    print(f\"      - Asignar PRs mÃ¡s complejos o crÃ­ticos\")\n",
    "\n",
    "# MÃ©tricas de seguimiento recomendadas\n",
    "print(f\"\\nðŸ“ˆ MÃ‰TRICAS DE SEGUIMIENTO RECOMENDADAS:\")\n",
    "print(f\"   ðŸ“Š Semanales:\")\n",
    "print(f\"      â€¢ Tasa de Ã©xito por desarrollador\")\n",
    "print(f\"      â€¢ Promedio de devoluciones en PRs nuevos\")\n",
    "print(f\"   ðŸ“Š Mensuales:\")\n",
    "print(f\"      â€¢ EvoluciÃ³n de coeficiente de variaciÃ³n\")\n",
    "print(f\"      â€¢ ComparaciÃ³n con benchmarks del equipo\")\n",
    "print(f\"   ðŸ“Š Trimestrales:\")\n",
    "print(f\"      â€¢ ReclasificaciÃ³n de desarrolladores\")\n",
    "print(f\"      â€¢ EvaluaciÃ³n de efectividad de planes de mejora\")\n",
    "\n",
    "# Impacto en el equipo\n",
    "promedio_team = autor_stats_filtered[\"Dev_Promedio\"].mean()\n",
    "desarrolladores_sobre_promedio = len(\n",
    "    autor_stats_filtered[autor_stats_filtered[\"Dev_Promedio\"] > promedio_team]\n",
    ")\n",
    "impacto_mejora = desarrolladores_sobre_promedio / len(autor_stats_filtered) * 100\n",
    "\n",
    "print(f\"\\nðŸ’° IMPACTO POTENCIAL:\")\n",
    "print(\n",
    "    f\"   â€¢ {desarrolladores_sobre_promedio} desarrolladores estÃ¡n sobre el promedio del equipo\"\n",
    ")\n",
    "print(\n",
    "    f\"   â€¢ Mejorando estos desarrolladores se podrÃ­a reducir {impacto_mejora:.1f}% las devoluciones\"\n",
    ")\n",
    "print(\n",
    "    f\"   â€¢ Tiempo estimado ahorrado: ~{impacto_mejora * 0.5:.1f} horas/semana en re-trabajo\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… AnÃ¡lisis de Devoluciones por Autor COMPLETADO!\")\n",
    "print(\"=\" * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
