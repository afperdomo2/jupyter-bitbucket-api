{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db4f799",
   "metadata": {},
   "source": [
    "# üìä Reporte de Pull Requests Merged en Bitbucket\n",
    "\n",
    "Este reporte proporciona una vista completa de todos los pull requests que han sido exitosamente merged en los repositorios de Bitbucket, incluyendo informaci√≥n detallada sobre comentarios, tiempos de resoluci√≥n y m√©tricas de productividad para an√°lisis hist√≥rico y mejora de procesos de desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d315bf9",
   "metadata": {},
   "source": [
    "## üîß Configuraci√≥n e Importaci√≥n de Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1e6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv requests pandas matplotlib seaborn\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbcfb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar credenciales de Bitbucket\n",
    "username = os.getenv(\"BITBUCKET_USERNAME\")\n",
    "app_password = os.getenv(\"BITBUCKET_APP_PASSWORD\")\n",
    "workspace = os.getenv(\"BITBUCKET_WORKSPACE\")\n",
    "\n",
    "# Verificar que las credenciales est√©n configuradas\n",
    "if not all([username, app_password, workspace]):\n",
    "    print(\"‚ùå Error: Aseg√∫rate de tener configuradas las variables de entorno:\")\n",
    "    print(\"- BITBUCKET_USERNAME\")\n",
    "    print(\"- BITBUCKET_APP_PASSWORD\")\n",
    "    print(\"- BITBUCKET_WORKSPACE\")\n",
    "else:\n",
    "    print(f\"‚úÖ Credenciales configuradas correctamente para el workspace: {workspace}\")\n",
    "    print(f\"   Usuario: {username}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd024f",
   "metadata": {},
   "source": [
    "## üì¶ Obtener Repositorios y Funciones de Utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa134506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener todos los elementos paginados de la API de Bitbucket\n",
    "def get_all_items(url, params=None):\n",
    "    \"\"\"\n",
    "    Obtiene todos los elementos de una URL paginada de la API de Bitbucket\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    while url:\n",
    "        response = requests.get(url, params=params, auth=(username, app_password))\n",
    "        if response.status_code != 200:\n",
    "            print(\n",
    "                f\"‚ùå Error al obtener datos: {response.status_code} - {response.text}\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "        items.extend(data.get(\"values\", []))\n",
    "\n",
    "        # Obtener la siguiente p√°gina si existe\n",
    "        url = data.get(\"next\")\n",
    "        params = None  # Los par√°metros ya est√°n incluidos en la URL 'next'\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "# Funci√≥n para obtener comentarios de un pull request\n",
    "def get_pr_comments(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene todos los comentarios de un pull request espec√≠fico\n",
    "    \"\"\"\n",
    "    comments_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}/comments\"\n",
    "    return get_all_items(comments_url)\n",
    "\n",
    "\n",
    "# Funci√≥n para convertir fechas a formato \"para humanos\" en espa√±ol\n",
    "def fecha_para_humanos(fecha_str):\n",
    "    \"\"\"\n",
    "    Convierte una fecha en formato datetime o string a texto legible en espa√±ol\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Si ya es string formateado, intentar parsearlo\n",
    "        if isinstance(fecha_str, str):\n",
    "            # Intentar varios formatos posibles\n",
    "            try:\n",
    "                fecha = pd.to_datetime(fecha_str, format=\"%Y-%m-%d %H:%M\")\n",
    "            except:\n",
    "                fecha = pd.to_datetime(fecha_str)\n",
    "        else:\n",
    "            # Si es un objeto datetime de pandas\n",
    "            fecha = pd.to_datetime(fecha_str)\n",
    "\n",
    "        # Asegurar que la fecha tenga zona horaria UTC para comparaci√≥n\n",
    "        if fecha.tz is None:\n",
    "            fecha = fecha.tz_localize(\"UTC\")\n",
    "\n",
    "        # Obtener tiempo actual en UTC\n",
    "        ahora = pd.Timestamp.now(tz=\"UTC\")\n",
    "\n",
    "        # Calcular diferencia\n",
    "        diff = ahora - fecha\n",
    "\n",
    "        # Obtener componentes\n",
    "        dias = diff.days\n",
    "        segundos_totales = diff.total_seconds()\n",
    "        horas = int(segundos_totales // 3600)\n",
    "        minutos = int((segundos_totales % 3600) // 60)\n",
    "\n",
    "        if dias > 0:\n",
    "            if dias == 1:\n",
    "                return \"hace 1 d√≠a\"\n",
    "            elif dias < 7:\n",
    "                return f\"hace {dias} d√≠as\"\n",
    "            elif dias < 30:\n",
    "                semanas = dias // 7\n",
    "                if semanas == 1:\n",
    "                    return \"hace 1 semana\"\n",
    "                else:\n",
    "                    return f\"hace {semanas} semanas\"\n",
    "            elif dias < 365:\n",
    "                meses = dias // 30\n",
    "                if meses == 1:\n",
    "                    return \"hace 1 mes\"\n",
    "                else:\n",
    "                    return f\"hace {meses} meses\"\n",
    "            else:\n",
    "                a√±os = dias // 365\n",
    "                if a√±os == 1:\n",
    "                    return \"hace 1 a√±o\"\n",
    "                else:\n",
    "                    return f\"hace {a√±os} a√±os\"\n",
    "        elif horas > 0:\n",
    "            if horas == 1:\n",
    "                return \"hace 1 hora\"\n",
    "            else:\n",
    "                return f\"hace {horas} horas\"\n",
    "        elif minutos > 0:\n",
    "            if minutos == 1:\n",
    "                return \"hace 1 minuto\"\n",
    "            else:\n",
    "                return f\"hace {minutos} minutos\"\n",
    "        else:\n",
    "            return \"hace menos de 1 minuto\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando fecha {fecha_str}: {e}\")\n",
    "        return str(fecha_str)  # Si hay error, devolver la fecha original como string\n",
    "\n",
    "\n",
    "# Funci√≥n para analizar comentarios del pull request seg√∫n las nuevas reglas\n",
    "def analyze_pr_comments(comments, pr_author_name):\n",
    "    \"\"\"\n",
    "    Analiza los comentarios de un PR y los clasifica seg√∫n las nuevas reglas (mutuamente excluyentes):\n",
    "    - Devoluciones: Comentarios normales de usuarios diferentes al autor del PR (NO inline)\n",
    "    - Estandarizaciones_Codigo: Comentarios inline de usuarios diferentes al autor del PR\n",
    "    \"\"\"\n",
    "    comm_pullrequest = 0\n",
    "    estandarizaciones_codigo = 0\n",
    "\n",
    "    for comment in comments:\n",
    "        # Solo procesar comentarios no eliminados\n",
    "        if comment.get(\"deleted\", False):\n",
    "            continue\n",
    "\n",
    "        # Obtener el nombre del usuario que hizo el comentario\n",
    "        comment_author = None\n",
    "        if \"user\" in comment and comment[\"user\"]:\n",
    "            # Priorizar display_name, luego nickname\n",
    "            comment_author = comment[\"user\"].get(\"display_name\") or comment[\"user\"].get(\n",
    "                \"nickname\"\n",
    "            )\n",
    "\n",
    "        # Solo contar si el comentario es de un usuario diferente al autor del PR\n",
    "        if comment_author and comment_author != pr_author_name:\n",
    "            # Verificar si es comentario inline (desarrollador) o normal (pull request)\n",
    "            if \"inline\" in comment and comment[\"inline\"]:\n",
    "                # Es un comentario inline -> comentario de estandarizaci√≥n de c√≥digo\n",
    "                estandarizaciones_codigo += 1\n",
    "            else:\n",
    "                # Es un comentario normal -> comentario del pull request\n",
    "                comm_pullrequest += 1\n",
    "\n",
    "    return comm_pullrequest, estandarizaciones_codigo\n",
    "\n",
    "\n",
    "# Funci√≥n para acortar nombres largos\n",
    "def acortar_nombre(nombre_completo):\n",
    "    \"\"\"\n",
    "    Acorta nombres largos para mostrar solo primer nombre + primera letra del segundo nombre\n",
    "    Ejemplo: \"Daniel Felipe Leal Chaves\" -> \"DanielF.\"\n",
    "    \"\"\"\n",
    "    if not nombre_completo or not isinstance(nombre_completo, str):\n",
    "        return nombre_completo\n",
    "\n",
    "    # Dividir el nombre en partes\n",
    "    partes = nombre_completo.strip().split()\n",
    "\n",
    "    if len(partes) == 1:\n",
    "        # Solo tiene un nombre\n",
    "        return partes[0]\n",
    "    elif len(partes) >= 2:\n",
    "        # Tiene al menos dos nombres\n",
    "        primer_nombre = partes[0]\n",
    "        segunda_parte = partes[1]\n",
    "\n",
    "        # Devolver primer nombre + primera letra del segundo en may√∫scula + punto (sin espacios)\n",
    "        return f\"{primer_nombre}{segunda_parte[0].upper()}.\"\n",
    "\n",
    "    return nombre_completo\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# FUNCIONES DE PRESENTACI√ìN (SEPARAR DATOS DE VISTA)\n",
    "# =====================================================\n",
    "\n",
    "\n",
    "def get_devoluciones_icon(count):\n",
    "    \"\"\"\n",
    "    Convierte n√∫mero de devoluciones a indicador visual con emoji\n",
    "    \"\"\"\n",
    "    return f\"{count} {'üî¥' if count >= 5 else 'üü°' if count >= 3 else 'üü¢'}\"\n",
    "\n",
    "\n",
    "def get_codigo_comentarios_icon(count):\n",
    "    \"\"\"\n",
    "    Convierte n√∫mero de comentarios de c√≥digo a indicador visual con emoji\n",
    "    \"\"\"\n",
    "    return f\"{count} {'üî¥' if count >= 10 else 'üü°' if count >= 4 else 'üü¢'}\"\n",
    "\n",
    "\n",
    "def get_codigo_comentarios_category(count):\n",
    "    \"\"\"\n",
    "    Categoriza comentarios de c√≥digo para an√°lisis (sin emojis)\n",
    "    \"\"\"\n",
    "    if count >= 10:\n",
    "        return \"Alto\"\n",
    "    elif count >= 4:\n",
    "        return \"Medio\"\n",
    "    else:\n",
    "        return \"Bajo\"\n",
    "\n",
    "\n",
    "def get_tiempo_resolucion_icon(dias):\n",
    "    \"\"\"\n",
    "    Convierte d√≠as de resoluci√≥n a indicador visual con emoji (solo muestra √≠cono si es lento)\n",
    "    \"\"\"\n",
    "    return f\"üêå {dias}\" if dias >= 7 else str(dias)\n",
    "\n",
    "\n",
    "def get_tiempo_resolucion_category(dias):\n",
    "    \"\"\"\n",
    "    Categoriza tiempo de resoluci√≥n para an√°lisis: solo \"Normal\" y \"Lento\"\n",
    "    \"\"\"\n",
    "    if dias >= 7:\n",
    "        return \"Lento\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Funciones de utilidad y presentaci√≥n definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bf370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener participantes de un pull request\n",
    "def get_pr_participants(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene los participantes de un pull request espec√≠fico con sus estados de revisi√≥n\n",
    "    \"\"\"\n",
    "    participants_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}/participants\"\n",
    "    participants = get_all_items(participants_url)\n",
    "    return participants\n",
    "\n",
    "# Funci√≥n para obtener informaci√≥n detallada de un pull request\n",
    "def get_pr_details(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene informaci√≥n detallada de un pull request espec√≠fico\n",
    "    \"\"\"\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}\"\n",
    "    response = requests.get(pr_url, auth=(username, app_password))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Funci√≥n para obtener informaci√≥n detallada de un pull request incluyendo participants\n",
    "def get_pr_details_with_participants(workspace, repo_slug, pr_id):\n",
    "    \"\"\"\n",
    "    Obtiene informaci√≥n detallada de un pull request espec√≠fico incluyendo participants\n",
    "    \"\"\"\n",
    "    pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests/{pr_id}\"\n",
    "    response = requests.get(pr_url, auth=(username, app_password))\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "# Funci√≥n para analizar los estados de revisi√≥n de los reviewers\n",
    "def analyze_reviewer_statuses(participants, reviewers_basic):\n",
    "    \"\"\"\n",
    "    Analiza los estados de revisi√≥n de los participantes y reviewers\n",
    "    Retorna conteos de aprobaciones y solicitudes de cambio\n",
    "    \"\"\"\n",
    "    approvals = 0\n",
    "    changes_requested = 0\n",
    "    reviewers_info = []\n",
    "    \n",
    "    # Crear un diccionario para facilitar la b√∫squeda\n",
    "    participants_dict = {}\n",
    "    for participant in participants:\n",
    "        if participant.get('user'):\n",
    "            username = participant['user'].get('nickname') or participant['user'].get('display_name')\n",
    "            if username:\n",
    "                participants_dict[username] = participant\n",
    "    \n",
    "    # Analizar cada reviewer\n",
    "    for reviewer in reviewers_basic:\n",
    "        reviewer_info = {\"name\": reviewer, \"status\": \"pending\"}\n",
    "        \n",
    "        # Buscar el reviewer en los participantes\n",
    "        if reviewer in participants_dict:\n",
    "            participant = participants_dict[reviewer]\n",
    "            if participant.get('approved'):\n",
    "                approvals += 1\n",
    "                reviewer_info[\"status\"] = \"approved\"\n",
    "            elif participant.get('state') == 'changes_requested':\n",
    "                changes_requested += 1\n",
    "                reviewer_info[\"status\"] = \"changes_requested\"\n",
    "        \n",
    "        reviewers_info.append(reviewer_info)\n",
    "    \n",
    "    return approvals, changes_requested, reviewers_info\n",
    "\n",
    "# Funci√≥n para analizar los estados de revisi√≥n desde los datos del PR\n",
    "def analyze_pr_review_statuses(pr_data):\n",
    "    \"\"\"\n",
    "    Analiza los estados de revisi√≥n desde los datos completos del PR\n",
    "    Extrae informaci√≥n de reviewers y participants si est√° disponible\n",
    "    \"\"\"\n",
    "    approvals = 0\n",
    "    changes_requested = 0\n",
    "    reviewers_info = []\n",
    "    \n",
    "    # Primero obtener reviewers b√°sicos\n",
    "    reviewers_basic = []\n",
    "    if \"reviewers\" in pr_data and pr_data[\"reviewers\"]:\n",
    "        for reviewer in pr_data[\"reviewers\"]:\n",
    "            if \"nickname\" in reviewer:\n",
    "                reviewers_basic.append(reviewer[\"nickname\"])\n",
    "            elif \"display_name\" in reviewer:\n",
    "                reviewers_basic.append(reviewer[\"display_name\"])\n",
    "    \n",
    "    # Buscar informaci√≥n de participants si est√° disponible en el PR\n",
    "    participants = pr_data.get(\"participants\", [])\n",
    "    \n",
    "    # Crear diccionario de participantes para facilitar b√∫squeda\n",
    "    participants_dict = {}\n",
    "    for participant in participants:\n",
    "        if participant.get('user'):\n",
    "            user_name = participant['user'].get('nickname') or participant['user'].get('display_name')\n",
    "            if user_name:\n",
    "                participants_dict[user_name] = participant\n",
    "    \n",
    "    # Analizar cada reviewer\n",
    "    for reviewer in reviewers_basic:\n",
    "        reviewer_info = {\"name\": reviewer, \"status\": \"pending\"}\n",
    "        \n",
    "        # Buscar el reviewer en los participantes\n",
    "        if reviewer in participants_dict:\n",
    "            participant = participants_dict[reviewer]\n",
    "            # Verificar estados de aprobaci√≥n\n",
    "            if participant.get('approved'):\n",
    "                approvals += 1\n",
    "                reviewer_info[\"status\"] = \"approved\"\n",
    "            elif participant.get('state') == 'changes_requested':\n",
    "                changes_requested += 1\n",
    "                reviewer_info[\"status\"] = \"changes_requested\"\n",
    "        \n",
    "        reviewers_info.append(reviewer_info)\n",
    "    \n",
    "    return approvals, changes_requested, reviewers_info, reviewers_basic\n",
    "\n",
    "# Funci√≥n para analizar todos los participants\n",
    "def analyze_participants_reviewers(pr_data):\n",
    "    \"\"\"\n",
    "    Analiza todos los participants del PR y extrae su estado de aprobaci√≥n\n",
    "    - Aprobado: cuando 'approved' es True\n",
    "    - No aprobado/Pendiente: cuando 'state' es 'changes_requested'\n",
    "    \"\"\"\n",
    "    participants_reviewers = []\n",
    "    \n",
    "    # Obtener participants del PR\n",
    "    participants = pr_data.get(\"participants\", [])\n",
    "    \n",
    "    # Procesar todos los participants (sin filtrar por role)\n",
    "    for participant in participants:\n",
    "        user_info = participant.get('user', {})\n",
    "        user_name = user_info.get('display_name') or user_info.get('nickname', 'Usuario Desconocido')\n",
    "        \n",
    "        # Verificar el estado seg√∫n las nuevas reglas\n",
    "        is_approved = participant.get('approved', False)\n",
    "        state = participant.get('state', '')\n",
    "        \n",
    "        participant_info = {\n",
    "            \"name\": user_name,\n",
    "            \"approved\": is_approved,\n",
    "            \"state\": state\n",
    "        }\n",
    "        \n",
    "        participants_reviewers.append(participant_info)\n",
    "    \n",
    "    return participants_reviewers\n",
    "\n",
    "print(\"‚úÖ Funciones actualizadas para usar todos los participants con nuevas reglas de estado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener lista de repositorios\n",
    "url_repos = f\"https://api.bitbucket.org/2.0/repositories/{workspace}\"\n",
    "\n",
    "print(\"üîÑ Obteniendo lista de repositorios...\")\n",
    "repositorios_data = get_all_items(url_repos)\n",
    "\n",
    "if repositorios_data:\n",
    "    repos_list = []\n",
    "    for repo in repositorios_data:\n",
    "        repos_list.append(\n",
    "            {\n",
    "                \"Nombre\": repo.get(\"name\"),\n",
    "                \"URL\": repo.get(\"links\", {}).get(\"html\", {}).get(\"href\"),\n",
    "                \"Descripci√≥n\": repo.get(\"description\", \"\"),\n",
    "                \"Privado\": repo.get(\"is_private\", False),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    repos_df = pd.DataFrame(repos_list)\n",
    "    repos_df = repos_df.sort_values(by=\"Nombre\")\n",
    "\n",
    "    # Filtrar repositorios (excluir algunos como en el archivo original)\n",
    "    repositorios_excluir = [\"pgp\", \"Pruebas_erp\", \"Inventario\", \"b2c\", \"efi\"]\n",
    "    repositorios_activos = [\n",
    "        repo[\"Nombre\"]\n",
    "        for repo in repos_list\n",
    "        if repo[\"Nombre\"] not in repositorios_excluir\n",
    "    ]\n",
    "\n",
    "    print(f\"‚úÖ Total de repositorios encontrados: {len(repositorios_data)}\")\n",
    "    print(f\"‚úÖ Repositorios activos para an√°lisis: {len(repositorios_activos)}\")\n",
    "\n",
    "    # Mostrar algunos repositorios\n",
    "    display(repos_df.head(10))\n",
    "else:\n",
    "    print(\"‚ùå No se pudieron obtener los repositorios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c74dad3",
   "metadata": {},
   "source": [
    "## üîç Obtener Pull Requests Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1604a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener PRs de un repositorio individual\n",
    "def obtener_prs_repositorio(repo_slug, workspace, repo_index, total_repos):\n",
    "    \"\"\"\n",
    "    Obtiene los pull requests merged de un repositorio espec√≠fico.\n",
    "    Esta funci√≥n est√° dise√±ada para ser ejecutada en paralelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"   üîÑ Procesando repositorio {repo_index}/{total_repos}: {repo_slug}\")\n",
    "        \n",
    "        # URL para obtener PRs merged\n",
    "        pr_url = f\"https://api.bitbucket.org/2.0/repositories/{workspace}/{repo_slug}/pullrequests\"\n",
    "        \n",
    "        # Obtener solo PRs merged (sin declined)\n",
    "        params = {\"state\": \"MERGED\"}\n",
    "        prs = get_all_items(pr_url, params=params)\n",
    "        \n",
    "        # Limitar a los √∫ltimos 50 PRs por repositorio para optimizar\n",
    "        if len(prs) > 50:\n",
    "            prs = prs[:50]\n",
    "        \n",
    "        # Agregar informaci√≥n del repositorio a cada PR\n",
    "        for pr in prs:\n",
    "            pr[\"repository\"] = repo_slug\n",
    "        \n",
    "        print(f\"   ‚úÖ Repositorio {repo_slug}: {len(prs)} PRs encontrados\")\n",
    "        return prs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error procesando repositorio {repo_slug}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Obtener todos los pull requests merged EN PARALELO\n",
    "print(\"üîÑ Obteniendo pull requests merged de todos los repositorios...\")\n",
    "print(\"üöÄ Usando procesamiento paralelo para acelerar las consultas...\")\n",
    "\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "start_time = time.time()\n",
    "pull_requests_merged = []\n",
    "total_repos = len(repositorios_activos)\n",
    "\n",
    "# Usar ThreadPoolExecutor para consultas paralelas\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    # Enviar todas las tareas al pool de threads\n",
    "    futures = []\n",
    "    for i, repo_slug in enumerate(repositorios_activos, 1):\n",
    "        future = executor.submit(obtener_prs_repositorio, repo_slug, workspace, i, total_repos)\n",
    "        futures.append(future)\n",
    "    \n",
    "    # Recopilar resultados conforme van complet√°ndose\n",
    "    for future in futures:\n",
    "        repo_prs = future.result()\n",
    "        if repo_prs:  # Solo agregar si hay PRs encontrados\n",
    "            pull_requests_merged.extend(repo_prs)\n",
    "\n",
    "# Calcular tiempo de consulta\n",
    "end_time = time.time()\n",
    "tiempo_consulta = end_time - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Consulta paralela completada en {tiempo_consulta:.1f} segundos\")\n",
    "print(f\"‚úÖ Total de pull requests merged encontrados: {len(pull_requests_merged)}\")\n",
    "print(f\"üöÄ Mejora de rendimiento: {(total_repos * 2 / tiempo_consulta):.1f}x m√°s r√°pido estimado\")\n",
    "\n",
    "if len(pull_requests_merged) == 0:\n",
    "    print(\"‚ÑπÔ∏è  No hay pull requests merged en el per√≠odo consultado\")\n",
    "else:\n",
    "    print(\"üîÑ Procesando informaci√≥n adicional de los pull requests...\")\n",
    "\n",
    "    # Filtrar por fecha si es necesario (√∫ltimos 30 d√≠as por defecto)\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    fecha_limite = datetime.now() - timedelta(days=30)\n",
    "\n",
    "    # Filtrar PRs por fecha de merge\n",
    "    prs_filtrados = []\n",
    "    for pr in pull_requests_merged:\n",
    "        fecha_updated = pd.to_datetime(pr[\"updated_on\"])\n",
    "        if fecha_updated.tz_localize(None) >= fecha_limite:\n",
    "            prs_filtrados.append(pr)\n",
    "\n",
    "    pull_requests_merged = prs_filtrados\n",
    "    print(f\"üîÑ PRs filtrados por √∫ltimos 30 d√≠as: {len(pull_requests_merged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86841796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para procesar un PR individual de manera thread-safe\n",
    "def procesar_pr_individual(pr, progress_dict, total_prs):\n",
    "    try:\n",
    "        # Extraer informaci√≥n del autor del PR\n",
    "        autor = \"Desconocido\"\n",
    "        if \"author\" in pr and pr[\"author\"]:\n",
    "            if \"display_name\" in pr[\"author\"]:\n",
    "                autor = pr[\"author\"][\"display_name\"]\n",
    "            elif \"nickname\" in pr[\"author\"]:\n",
    "                autor = pr[\"author\"][\"nickname\"]\n",
    "        autor = acortar_nombre(autor)\n",
    "\n",
    "        # Obtener comentarios del PR y analizarlos\n",
    "        try:\n",
    "            comentarios = get_pr_comments(workspace, pr[\"repository\"], pr[\"id\"])\n",
    "            comm_pullrequest, estandarizaciones_codigo = analyze_pr_comments(\n",
    "                comentarios, autor\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ö†Ô∏è  Error obteniendo comentarios para PR {pr['id']}: {str(e)}\")\n",
    "            comm_pullrequest = 0\n",
    "            estandarizaciones_codigo = 0\n",
    "\n",
    "        # Calcular tiempo de resoluci√≥n\n",
    "        created_on = pd.to_datetime(pr[\"created_on\"])\n",
    "        updated_on = pd.to_datetime(pr[\"updated_on\"])\n",
    "        tiempo_resolucion = (updated_on - created_on).days\n",
    "\n",
    "        # Informaci√≥n sobre quien merged el PR\n",
    "        merged_por = \"Desconocido\"\n",
    "        if \"closed_by\" in pr and pr[\"closed_by\"]:\n",
    "            if \"display_name\" in pr[\"closed_by\"]:\n",
    "                merged_por = pr[\"closed_by\"][\"display_name\"]\n",
    "            elif \"nickname\" in pr[\"closed_by\"]:\n",
    "                merged_por = pr[\"closed_by\"][\"nickname\"]\n",
    "\n",
    "        # Crear registro procesado\n",
    "        pr_procesado = {\n",
    "            \"ID\": pr[\"id\"],\n",
    "            \"T√≠tulo\": pr.get(\"title\", \"Sin t√≠tulo\"),\n",
    "            \"Repositorio\": pr[\"repository\"],\n",
    "            \"Autor\": autor,\n",
    "            \"Merged_Por\": merged_por,\n",
    "            \"Devoluciones\": comm_pullrequest,\n",
    "            \"Estandarizaciones_Codigo\": estandarizaciones_codigo,\n",
    "            \"Fecha_Creacion\": created_on,\n",
    "            \"Fecha_Merge\": updated_on,\n",
    "            \"Tiempo_Resolucion\": tiempo_resolucion,\n",
    "            \"Descripcion\": (\n",
    "                pr.get(\"description\", \"Sin descripci√≥n\")[:100] + \"...\"\n",
    "                if pr.get(\"description\", \"\")\n",
    "                else \"Sin descripci√≥n\"\n",
    "            ),\n",
    "            \"URL\": pr.get(\"links\", {}).get(\"html\", {}).get(\"href\", \"\"),\n",
    "            \"Rama_Origen\": pr.get(\"source\", {})\n",
    "            .get(\"branch\", {})\n",
    "            .get(\"name\", \"Desconocida\"),\n",
    "            \"Rama_Destino\": pr.get(\"destination\", {})\n",
    "            .get(\"branch\", {})\n",
    "            .get(\"name\", \"Desconocida\"),\n",
    "        }\n",
    "\n",
    "        # Actualizar progreso de manera thread-safe\n",
    "        with progress_dict['lock']:\n",
    "            progress_dict['procesados'] += 1\n",
    "            current = progress_dict['procesados']\n",
    "            print(f\"   ‚úÖ PR {current}/{total_prs} procesado: {pr.get('title', 'Sin t√≠tulo')[:50]}...\")\n",
    "\n",
    "        return pr_procesado\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error procesando PR {pr.get('id', 'unknown')}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Procesar informaci√≥n detallada de cada pull request merged con threading\n",
    "if len(pull_requests_merged) > 0:\n",
    "    print(f\"üöÄ Iniciando procesamiento con threading de {len(pull_requests_merged)} PRs...\")\n",
    "    \n",
    "    # Medir tiempo de procesamiento\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Variables para tracking del progreso thread-safe\n",
    "    progress_dict = {\n",
    "        'procesados': 0,\n",
    "        'lock': threading.Lock()\n",
    "    }\n",
    "    \n",
    "    # Usar ThreadPoolExecutor para procesamiento paralelo\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        # Enviar todas las tareas al pool de threads\n",
    "        futures = []\n",
    "        for pr in pull_requests_merged:\n",
    "            future = executor.submit(procesar_pr_individual, pr, progress_dict, len(pull_requests_merged))\n",
    "            futures.append(future)\n",
    "        \n",
    "        # Recopilar resultados\n",
    "        prs_procesados = []\n",
    "        for future in futures:\n",
    "            resultado = future.result()\n",
    "            if resultado is not None:\n",
    "                prs_procesados.append(resultado)\n",
    "    \n",
    "    # Calcular tiempo transcurrido\n",
    "    end_time = time.time()\n",
    "    tiempo_total = end_time - start_time\n",
    "    \n",
    "    # Crear DataFrame con los datos procesados\n",
    "    df_prs_merged = pd.DataFrame(prs_procesados)\n",
    "\n",
    "    # Ordenar por fecha de merge (m√°s recientes primero)\n",
    "    df_prs_merged = df_prs_merged.sort_values(\"Fecha_Merge\", ascending=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Procesamiento completado en {tiempo_total:.1f} segundos\")\n",
    "    print(f\"üìä {len(df_prs_merged)} pull requests procesados exitosamente\")\n",
    "    if len(prs_procesados) < len(pull_requests_merged):\n",
    "        print(f\"‚ö†Ô∏è  {len(pull_requests_merged) - len(prs_procesados)} PRs fallaron en el procesamiento\")\n",
    "else:\n",
    "    df_prs_merged = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40875abf",
   "metadata": {},
   "source": [
    "## üìä Reportes y An√°lisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen ejecutivo\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìà RESUMEN EJECUTIVO - PULL REQUESTS MERGED\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    total_prs = len(df_prs_merged)\n",
    "\n",
    "    prs_con_comentarios = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 0])\n",
    "    total_comentarios = df_prs_merged[\"Devoluciones\"].sum()\n",
    "    total_estandarizaciones_codigo = df_prs_merged[\"Estandarizaciones_Codigo\"].sum()\n",
    "\n",
    "    promedio_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].mean()\n",
    "    max_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].max()\n",
    "    min_tiempo_resolucion = df_prs_merged[\"Tiempo_Resolucion\"].min()\n",
    "\n",
    "    print(f\"üî¢ Total de Pull Requests Merged: {total_prs}\")\n",
    "    print(f\"üí¨ PRs con Comentarios: {prs_con_comentarios}\")\n",
    "    print(f\"üìä Total de Comentarios: {total_comentarios}\")\n",
    "    print(\n",
    "        f\"üë®‚Äçüíª Estandarizaciones de C√≥digo (inline): {total_estandarizaciones_codigo}\"\n",
    "    )\n",
    "    print(f\"‚è±Ô∏è  Tiempo Promedio de Resoluci√≥n: {promedio_tiempo_resolucion:.1f} d√≠as\")\n",
    "    print(f\"üöÄ Resoluci√≥n m√°s R√°pida: {min_tiempo_resolucion} d√≠as\")\n",
    "    print(f\"üêå Resoluci√≥n m√°s Lenta: {max_tiempo_resolucion} d√≠as\")\n",
    "\n",
    "    # Repositorios con m√°s PRs merged\n",
    "    repos_prs = df_prs_merged[\"Repositorio\"].value_counts()\n",
    "    print(f\"\\nüèÜ Repositorios con m√°s PRs merged:\")\n",
    "    for i, (repo, count) in enumerate(repos_prs.head(5).items(), 1):\n",
    "        print(f\"   {i}. {repo}: {count} PRs\")\n",
    "\n",
    "    # Autores con m√°s PRs merged\n",
    "    autores_prs = df_prs_merged[\"Autor\"].value_counts()\n",
    "    print(f\"\\nüë• Autores con m√°s PRs merged:\")\n",
    "    for i, (autor, count) in enumerate(autores_prs.head(5).items(), 1):\n",
    "        print(f\"   {i}. {autor}: {count} PRs\")\n",
    "\n",
    "    # Personas que m√°s hacen merge\n",
    "    merged_por = df_prs_merged[\"Merged_Por\"].value_counts()\n",
    "    print(f\"\\nüîÄ Quienes m√°s hacen merge de PRs:\")\n",
    "    for i, (persona, count) in enumerate(merged_por.head(5).items(), 1):\n",
    "        print(f\"   {i}. {persona}: {count} PRs\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    print(\n",
    "        \"‚ÑπÔ∏è  No hay pull requests merged en el per√≠odo consultado para mostrar en el resumen\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tabla detallada de Pull Requests merged\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"\\nüìã DETALLE DE PULL REQUESTS MERGED\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Mostrar rango temporal de los datos analizados\n",
    "    fecha_primer_pr = df_prs_merged[\"Fecha_Creacion\"].min()\n",
    "    fecha_ultimo_pr = df_prs_merged[\"Fecha_Creacion\"].max()\n",
    "\n",
    "    print(f\"üìÖ Fecha primer pull request: {fecha_primer_pr.strftime('%d/%m/%Y %H:%M')}\")\n",
    "    print(f\"üìÖ Fecha √∫ltimo pull request: {fecha_ultimo_pr.strftime('%d/%m/%Y %H:%M')}\")\n",
    "\n",
    "    # Calcular per√≠odo total\n",
    "    periodo_total = (fecha_ultimo_pr - fecha_primer_pr).days\n",
    "    print(\n",
    "        f\"‚è±Ô∏è  Per√≠odo total analizado: {periodo_total} d√≠as ({periodo_total / 30:.1f} meses)\"\n",
    "    )\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Crear una versi√≥n de la tabla optimizada para visualizaci√≥n (sin Merged_Por)\n",
    "    df_display = df_prs_merged[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Repositorio\",\n",
    "            \"T√≠tulo\",\n",
    "            \"Autor\",\n",
    "            \"Devoluciones\",\n",
    "            \"Estandarizaciones_Codigo\",\n",
    "            \"Tiempo_Resolucion\",\n",
    "            \"Rama_Origen\",\n",
    "            \"Fecha_Creacion\",\n",
    "            \"Fecha_Merge\",\n",
    "        ]\n",
    "    ].copy()\n",
    "\n",
    "    # Ordenar por fecha de merge (m√°s recientes primero)\n",
    "    df_display = df_display.sort_values(\"Fecha_Merge\", ascending=False)\n",
    "\n",
    "    # Convertir fechas a formato \"para humanos\"\n",
    "    df_display[\"Creado\"] = df_display[\"Fecha_Creacion\"].apply(fecha_para_humanos)\n",
    "    df_display[\"Merged\"] = df_display[\"Fecha_Merge\"].apply(fecha_para_humanos)\n",
    "\n",
    "    # Eliminar las columnas de fecha originales\n",
    "    df_display = df_display.drop(columns=[\"Fecha_Creacion\", \"Fecha_Merge\"])\n",
    "\n",
    "    # ===================================================================\n",
    "    # MEJORES PR√ÅCTICAS: Crear columnas categ√≥ricas para an√°lisis futuro\n",
    "    # ===================================================================\n",
    "\n",
    "    # Categorizar comentarios de c√≥digo (para an√°lisis/filtros)\n",
    "    df_display[\"Estandarizaciones_Codigo_Categoria\"] = df_display[\n",
    "        \"Estandarizaciones_Codigo\"\n",
    "    ].apply(get_codigo_comentarios_category)\n",
    "\n",
    "    # Categorizar tiempo de resoluci√≥n (para an√°lisis/filtros) - Solo \"Normal\" y \"Lento\"\n",
    "    df_display[\"Tiempo_Resolucion_Categoria\"] = df_display[\"Tiempo_Resolucion\"].apply(\n",
    "        get_tiempo_resolucion_category\n",
    "    )\n",
    "\n",
    "    # Renombrar columnas para mayor claridad\n",
    "    df_display = df_display.rename(columns={\"Rama_Origen\": \"Branch\"})\n",
    "\n",
    "    # ===================================================================\n",
    "    # APLICAR PRESENTACI√ìN VISUAL SOLO PARA MOSTRAR (NO PARA ALMACENAR)\n",
    "    # ===================================================================\n",
    "\n",
    "    # Crear copia temporal solo para visualizaci√≥n\n",
    "    df_show = df_display.copy()\n",
    "\n",
    "    # Aplicar iconos solo en la copia de visualizaci√≥n\n",
    "    df_show[\"Devoluciones\"] = df_show[\"Devoluciones\"].apply(get_devoluciones_icon)\n",
    "\n",
    "    # Aplicar iconos solo en la copia de visualizaci√≥n\n",
    "    df_show[\"Estandarizaciones_Codigo\"] = df_show[\"Estandarizaciones_Codigo\"].apply(\n",
    "        get_codigo_comentarios_icon\n",
    "    )\n",
    "    df_show[\"Tiempo_Resolucion\"] = df_show[\"Tiempo_Resolucion\"].apply(\n",
    "        get_tiempo_resolucion_icon\n",
    "    )\n",
    "\n",
    "    # Renombrar columna de tiempo para mostrar\n",
    "    df_show = df_show.rename(columns={\"Tiempo_Resolucion\": \"D√≠as_Resoluci√≥n\"})\n",
    "\n",
    "    # Seleccionar columnas para mostrar (sin las categ√≥ricas internas)\n",
    "    df_show = df_show[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"Repositorio\",\n",
    "            \"T√≠tulo\",\n",
    "            \"Autor\",\n",
    "            \"Branch\",\n",
    "            \"Devoluciones\",\n",
    "            \"Estandarizaciones_Codigo\",\n",
    "            \"D√≠as_Resoluci√≥n\",\n",
    "            \"Creado\",\n",
    "            \"Merged\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Configurar pandas para mostrar todas las columnas\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.width\", None)\n",
    "    pd.set_option(\"display.max_colwidth\", 50)\n",
    "\n",
    "    # Mostrar la tabla (solo la versi√≥n con iconos)\n",
    "    display(df_show)\n",
    "\n",
    "    print(f\"\\nüìå Mostrando {len(df_display)} pull requests merged\")\n",
    "    print(\"üí° Tip: Los PRs est√°n ordenados por fecha de merge (m√°s recientes primero)\")\n",
    "    print(\"üêå Resoluci√≥n lenta: ‚â•7 d√≠as (sin √≠cono = resoluci√≥n normal)\")\n",
    "    print(\"üü¢ 0-2 devoluciones | üü° 3-4 comentarios | üî¥ 5+ comentarios\")\n",
    "    print(\"üü¢ 0-3 comentarios de c√≥digo | üü° 4-9 comentarios | üî¥ 10+ comentarios\")\n",
    "\n",
    "    print(f\"\\nüîç Para an√°lisis futuro usar:\")\n",
    "    print(\n",
    "        f\"   ‚Ä¢ df_display['Estandarizaciones_Codigo_Categoria'] -> 'Bajo', 'Medio', 'Alto'\"\n",
    "    )\n",
    "    print(f\"   ‚Ä¢ df_display['Tiempo_Resolucion_Categoria'] -> 'Normal', 'Lento'\")\n",
    "    print(f\"   ‚Ä¢ df_display['Estandarizaciones_Codigo'] -> valores num√©ricos puros\")\n",
    "    print(f\"   ‚Ä¢ df_display['Tiempo_Resolucion'] -> d√≠as num√©ricos puros\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No hay pull requests merged en el per√≠odo consultado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454526c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis espec√≠fico de los datos actuales para generar recomendaciones de reportes\n",
    "if not df_prs_merged.empty:\n",
    "    print(\"üîç AN√ÅLISIS DE DATOS DISPONIBLES Y RECOMENDACIONES DE REPORTES\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # An√°lisis b√°sico de los datos\n",
    "    total_prs = len(df_prs_merged)\n",
    "    autores_unicos = df_prs_merged[\"Autor\"].nunique()\n",
    "    repos_unicos = df_prs_merged[\"Repositorio\"].nunique()\n",
    "\n",
    "    print(f\"üìä Resumen de datos disponibles:\")\n",
    "    print(f\"   ‚Ä¢ Total PRs: {total_prs}\")\n",
    "    print(f\"   ‚Ä¢ Autores √∫nicos: {autores_unicos}\")\n",
    "    print(f\"   ‚Ä¢ Repositorios √∫nicos: {repos_unicos}\")\n",
    "    print(\n",
    "        f\"   ‚Ä¢ Rango de fechas: {df_prs_merged['Fecha_Creacion'].min().strftime('%Y-%m-%d')} a {df_prs_merged['Fecha_Merge'].max().strftime('%Y-%m-%d')}\"\n",
    "    )\n",
    "\n",
    "    # An√°lisis de distribuci√≥n de m√©tricas clave\n",
    "    print(f\"\\nüìà Distribuci√≥n de m√©tricas clave:\")\n",
    "\n",
    "    # Estandarizaciones de c√≥digo\n",
    "    est_stats = df_prs_merged[\"Estandarizaciones_Codigo\"].describe()\n",
    "    print(f\"   üîß Estandarizaciones de C√≥digo:\")\n",
    "    print(f\"      - Promedio: {est_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {est_stats['50%']:.1f}\")\n",
    "    print(f\"      - M√°ximo: {int(est_stats['max'])}\")\n",
    "\n",
    "    # Devoluciones\n",
    "    dev_stats = df_prs_merged[\"Devoluciones\"].describe()\n",
    "    print(f\"   üîÑ Devoluciones:\")\n",
    "    print(f\"      - Promedio: {dev_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {dev_stats['50%']:.1f}\")\n",
    "    print(f\"      - M√°ximo: {int(dev_stats['max'])}\")\n",
    "\n",
    "    # Tiempo de resoluci√≥n\n",
    "    tiempo_stats = df_prs_merged[\"Tiempo_Resolucion\"].describe()\n",
    "    print(f\"   ‚è±Ô∏è  Tiempo de Resoluci√≥n (d√≠as):\")\n",
    "    print(f\"      - Promedio: {tiempo_stats['mean']:.1f}\")\n",
    "    print(f\"      - Mediana: {tiempo_stats['50%']:.1f}\")\n",
    "    print(f\"      - M√°ximo: {int(tiempo_stats['max'])}\")\n",
    "\n",
    "    print(f\"\\nüéØ REPORTES RECOMENDADOS POR PRIORIDAD:\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Generar recomendaciones basadas en los datos\n",
    "    reportes_recomendados = []\n",
    "\n",
    "    # 1. Si hay variabilidad en autores, recomendar an√°lisis de productividad\n",
    "    if autores_unicos >= 3:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"üî¥ ALTA\",\n",
    "                \"nombre\": \"Dashboard de Productividad por Desarrollador\",\n",
    "                \"justificacion\": f\"Con {autores_unicos} desarrolladores activos, este reporte identificar√° patrones de rendimiento y oportunidades de mejora.\",\n",
    "                \"impacto\": \"Gesti√≥n de equipo y desarrollo profesional\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 2. Si hay alta variabilidad en estandarizaciones, recomendar an√°lisis de calidad\n",
    "    if est_stats[\"std\"] > 2:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"üî¥ ALTA\",\n",
    "                \"nombre\": \"An√°lisis de Calidad de C√≥digo\",\n",
    "                \"justificacion\": f\"Alta variabilidad en estandarizaciones (std: {est_stats['std']:.1f}) sugiere inconsistencias en calidad.\",\n",
    "                \"impacto\": \"Mejora de procesos de code review\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 3. Si hay m√∫ltiples repositorios, recomendar an√°lisis por repo\n",
    "    if repos_unicos >= 3:\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"üü° MEDIA\",\n",
    "                \"nombre\": \"Ranking de Repositorios por M√©tricas\",\n",
    "                \"justificacion\": f\"Con {repos_unicos} repositorios, podemos identificar cu√°les necesitan m√°s atenci√≥n.\",\n",
    "                \"impacto\": \"Priorizaci√≥n de esfuerzos de mejora t√©cnica\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 4. Si hay PRs lentos, recomendar an√°lisis de eficiencia\n",
    "    prs_lentos = len(df_prs_merged[df_prs_merged[\"Tiempo_Resolucion\"] > 7])\n",
    "    if prs_lentos > 0:\n",
    "        porcentaje_lentos = (prs_lentos / total_prs) * 100\n",
    "        reportes_recomendados.append(\n",
    "            {\n",
    "                \"prioridad\": \"üü° MEDIA\" if porcentaje_lentos < 20 else \"üî¥ ALTA\",\n",
    "                \"nombre\": \"An√°lisis de Eficiencia del Proceso\",\n",
    "                \"justificacion\": f\"{prs_lentos} PRs ({porcentaje_lentos:.1f}%) tardaron m√°s de 7 d√≠as en resolverse.\",\n",
    "                \"impacto\": \"Optimizaci√≥n del flujo de trabajo\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # 5. An√°lisis temporal siempre √∫til\n",
    "    reportes_recomendados.append(\n",
    "        {\n",
    "            \"prioridad\": \"üü¢ BAJA\",\n",
    "            \"nombre\": \"Tendencias Temporales\",\n",
    "            \"justificacion\": \"√ötil para identificar patrones estacionales y planificaci√≥n futura.\",\n",
    "            \"impacto\": \"Planificaci√≥n estrat√©gica\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Mostrar recomendaciones\n",
    "    for i, reporte in enumerate(reportes_recomendados, 1):\n",
    "        print(f\"\\n{i}. {reporte['prioridad']} - {reporte['nombre']}\")\n",
    "        print(f\"   üí° Justificaci√≥n: {reporte['justificacion']}\")\n",
    "        print(f\"   üéØ Impacto: {reporte['impacto']}\")\n",
    "\n",
    "    print(f\"\\nüöÄ PR√ìXIMOS PASOS SUGERIDOS:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"1. Comenzar con reportes de prioridad ALTA\")\n",
    "    print(\"2. Implementar dashboards autom√°ticos para seguimiento continuo\")\n",
    "    print(\"3. Definir umbrales de alerta para intervenci√≥n proactiva\")\n",
    "    print(\"4. Establecer revisiones peri√≥dicas de m√©tricas con el equipo\")\n",
    "\n",
    "    # Mostrar informaci√≥n sobre campos disponibles para cada reporte\n",
    "    print(f\"\\nüìã CAMPOS DISPONIBLES PARA AN√ÅLISIS:\")\n",
    "    print(\"=\" * 40)\n",
    "    campos_numericos = [\"Devoluciones\", \"Estandarizaciones_Codigo\", \"Tiempo_Resolucion\"]\n",
    "    campos_categoricos = [\n",
    "        \"Autor\",\n",
    "        \"Repositorio\",\n",
    "        \"Merged_Por\",\n",
    "        \"Rama_Origen\",\n",
    "        \"Rama_Destino\",\n",
    "    ]\n",
    "    campos_temporales = [\"Fecha_Creacion\", \"Fecha_Merge\"]\n",
    "    campos_derivados = [\n",
    "        \"Estandarizaciones_Codigo_Categoria\",\n",
    "        \"Tiempo_Resolucion_Categoria\",\n",
    "    ]\n",
    "\n",
    "    print(f\"üî¢ Campos num√©ricos: {', '.join(campos_numericos)}\")\n",
    "    print(f\"üè∑Ô∏è  Campos categ√≥ricos: {', '.join(campos_categoricos)}\")\n",
    "    print(f\"üìÖ Campos temporales: {', '.join(campos_temporales)}\")\n",
    "    print(f\"üìä Campos derivados: {', '.join(campos_derivados)}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No hay datos disponibles para generar recomendaciones de reportes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar las columnas disponibles en df_prs_merged\n",
    "print(\"üìã COLUMNAS DISPONIBLES EN df_prs_merged:\")\n",
    "print(list(df_prs_merged.columns))\n",
    "print(f\"\\nShape del DataFrame: {df_prs_merged.shape}\")\n",
    "\n",
    "# Verificar si existe la columna 'Autor' en lugar de 'author_name'\n",
    "if 'Autor' in df_prs_merged.columns:\n",
    "    print(\"‚úÖ La columna 'Autor' est√° disponible\")\n",
    "    print(f\"Autores √∫nicos: {df_prs_merged['Autor'].nunique()}\")\n",
    "else:\n",
    "    print(\"‚ùå La columna 'Autor' no est√° disponible\")\n",
    "\n",
    "# Verificar otras columnas necesarias\n",
    "columnas_necesarias = ['Tiempo_Resolucion', 'Devoluciones', 'Estandarizaciones_Codigo', 'Fecha_Creacion']\n",
    "for col in columnas_necesarias:\n",
    "    if col in df_prs_merged.columns:\n",
    "        print(f\"‚úÖ {col} disponible\")\n",
    "    else:\n",
    "        print(f\"‚ùå {col} NO disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b1199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si existe declined_prs, si no, crear un DataFrame vac√≠o\n",
    "if 'declined_prs' not in globals():\n",
    "    declined_prs = pd.DataFrame()  # DataFrame vac√≠o para evitar errores\n",
    "    print(\"‚ö†Ô∏è declined_prs no encontrado, creando DataFrame vac√≠o\")\n",
    "else:\n",
    "    print(f\"‚úÖ declined_prs encontrado con {len(declined_prs)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6eafe8",
   "metadata": {},
   "source": [
    "# üìà REPORTES Y VISUALIZACIONES IMPLEMENTADAS\n",
    "\n",
    "En esta secci√≥n implementamos los reportes prioritarios identificados en el an√°lisis anterior, proporcionando visualizaciones y m√©tricas que aportan valor directo al equipo de desarrollo para la toma de decisiones y mejora continua de procesos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bcb8a3",
   "metadata": {},
   "source": [
    "## üéØ REPORTE 1: Dashboard de Productividad del Equipo\n",
    "\n",
    "**Objetivo:** Proporcionar una vista consolidada de la productividad del equipo con m√©tricas clave de rendimiento.\n",
    "\n",
    "**M√©tricas incluidas:**\n",
    "- Volumen total de PRs procesados por desarrollador\n",
    "- Tiempo promedio de resoluci√≥n por desarrollador\n",
    "- Tasa de √©xito (PRs merged vs declined)\n",
    "- Distribuci√≥n de carga de trabajo\n",
    "- Ranking de productividad balanceada (velocidad + volumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1879a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# REPORTE 1: DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\n",
    "# ====================================================================================\n",
    "\n",
    "\n",
    "# Configurar el estilo de las visualizaciones\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Preparar datos para el dashboard de productividad\n",
    "print(\"üöÄ DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. M√©tricas generales de productividad\n",
    "metrics_productividad = {\n",
    "    \"Total PRs Procesados\": len(df_prs_merged),\n",
    "    \"Desarrolladores Activos\": len(df_prs_merged[\"Autor\"].unique()),\n",
    "    \"Tiempo Promedio Resoluci√≥n\": f\"{df_prs_merged['Tiempo_Resolucion'].mean():.1f} d√≠as\",\n",
    "    \"Tasa de √âxito Global\": f\"{(len(df_prs_merged) / (len(df_prs_merged) + len(declined_prs)) * 100):.1f}%\",\n",
    "    \"PRs/D√≠a (promedio)\": f\"{len(df_prs_merged) / ((df_prs_merged['Fecha_Creacion'].max() - df_prs_merged['Fecha_Creacion'].min()).days + 1):.1f}\",\n",
    "}\n",
    "\n",
    "# Mostrar m√©tricas principales\n",
    "print(\"\\nüìä M√âTRICAS PRINCIPALES:\")\n",
    "for metric, value in metrics_productividad.items():\n",
    "    print(f\"   {metric}: {value}\")\n",
    "\n",
    "# 2. An√°lisis de productividad por desarrollador\n",
    "print(\"\\n\\nüë• AN√ÅLISIS POR DESARROLLADOR:\")\n",
    "\n",
    "# Calcular m√©tricas detalladas por autor\n",
    "productivity_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"ID\": \"count\",  # Volumen de PRs\n",
    "            \"Tiempo_Resolucion\": [\"mean\", \"std\"],  # Tiempo promedio y variabilidad\n",
    "            \"Devoluciones\": \"mean\",  # Complejidad promedio\n",
    "            \"Estandarizaciones_Codigo\": \"mean\",  # Calidad del c√≥digo\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "productivity_stats.columns = [\n",
    "    \"PRs_Total\",\n",
    "    \"Tiempo_Promedio\",\n",
    "    \"Tiempo_Std\",\n",
    "    \"Devoluciones_Promedio\",\n",
    "    \"Estandarizaciones_Promedio\",\n",
    "]\n",
    "\n",
    "# Calcular score de productividad (balanceado entre volumen y velocidad)\n",
    "productivity_stats[\"Score_Volumen\"] = (\n",
    "    productivity_stats[\"PRs_Total\"] / productivity_stats[\"PRs_Total\"].max()\n",
    ") * 100\n",
    "productivity_stats[\"Score_Velocidad\"] = (\n",
    "    1\n",
    "    - (\n",
    "        productivity_stats[\"Tiempo_Promedio\"]\n",
    "        / productivity_stats[\"Tiempo_Promedio\"].max()\n",
    "    )\n",
    ") * 100\n",
    "productivity_stats[\"Score_Productividad\"] = (\n",
    "    productivity_stats[\"Score_Volumen\"] + productivity_stats[\"Score_Velocidad\"]\n",
    ") / 2\n",
    "\n",
    "# Ordenar por score de productividad\n",
    "productivity_stats = productivity_stats.sort_values(\n",
    "    \"Score_Productividad\", ascending=False\n",
    ")\n",
    "\n",
    "# Mostrar top 10 desarrolladores m√°s productivos\n",
    "print(f\"\\nüèÜ TOP 10 DESARROLLADORES M√ÅS PRODUCTIVOS:\")\n",
    "display(\n",
    "    productivity_stats.head(10)[[\"PRs_Total\", \"Tiempo_Promedio\", \"Score_Productividad\"]]\n",
    ")\n",
    "\n",
    "# 3. Crear visualizaci√≥n del dashboard\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs = fig.add_gridspec(4, 4, hspace=0.7, wspace=0.3)\n",
    "\n",
    "# Gr√°fico 1: Volumen de PRs por desarrollador (Top 15)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "top_15_volume = productivity_stats.head(15)\n",
    "bars1 = ax1.bar(\n",
    "    range(len(top_15_volume)), top_15_volume[\"PRs_Total\"], color=\"steelblue\", alpha=0.8\n",
    ")\n",
    "ax1.set_title(\n",
    "    \"üìä Volumen de PRs por Desarrollador (Top 15)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax1.set_ylabel(\"N√∫mero de PRs\")\n",
    "ax1.set_xticks(range(len(top_15_volume)))\n",
    "ax1.set_xticklabels(\n",
    "    [name[:15] + \"...\" if len(name) > 15 else name for name in top_15_volume.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.5,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Gr√°fico 2: Tiempo promedio de resoluci√≥n (Top 15)\n",
    "ax2 = fig.add_subplot(gs[0, 2:])\n",
    "bars2 = ax2.bar(\n",
    "    range(len(top_15_volume)),\n",
    "    top_15_volume[\"Tiempo_Promedio\"],\n",
    "    color=\"lightcoral\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax2.set_title(\n",
    "    \"‚è±Ô∏è Tiempo Promedio de Resoluci√≥n (Top 15)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax2.set_ylabel(\"D√≠as\")\n",
    "ax2.set_xticks(range(len(top_15_volume)))\n",
    "ax2.set_xticklabels(\n",
    "    [name[:15] + \"...\" if len(name) > 15 else name for name in top_15_volume.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{height:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Gr√°fico 3: Score de Productividad (Top 12)\n",
    "ax3 = fig.add_subplot(gs[1, :2])\n",
    "top_12_prod = productivity_stats.head(12)\n",
    "colors_grad = plt.cm.RdYlGn([x / 100 for x in top_12_prod[\"Score_Productividad\"]])\n",
    "bars3 = ax3.bar(\n",
    "    range(len(top_12_prod)),\n",
    "    top_12_prod[\"Score_Productividad\"],\n",
    "    color=colors_grad,\n",
    "    alpha=0.8,\n",
    ")\n",
    "ax3.set_title(\n",
    "    \"üèÜ Score de Productividad Balanceado (Top 12)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax3.set_ylabel(\"Score (0-100)\")\n",
    "ax3.set_xticks(range(len(top_12_prod)))\n",
    "ax3.set_xticklabels(\n",
    "    [name[:12] + \"...\" if len(name) > 12 else name for name in top_12_prod.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars3):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 1,\n",
    "        f\"{height:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# Gr√°fico 4: Distribuci√≥n de carga de trabajo\n",
    "ax4 = fig.add_subplot(gs[1, 2:])\n",
    "# Agrupar desarrolladores por rangos de volumen\n",
    "bins = [0, 5, 15, 30, 50, 999]\n",
    "labels = [\"1-5 PRs\", \"6-15 PRs\", \"16-30 PRs\", \"31-50 PRs\", \"50+ PRs\"]\n",
    "productivity_stats[\"Rango_Volumen\"] = pd.cut(\n",
    "    productivity_stats[\"PRs_Total\"], bins=bins, labels=labels, include_lowest=True\n",
    ")\n",
    "dist_carga = productivity_stats[\"Rango_Volumen\"].value_counts()\n",
    "\n",
    "wedges, texts, autotexts = ax4.pie(\n",
    "    dist_carga.values,\n",
    "    labels=dist_carga.index,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    colors=sns.color_palette(\"Set3\", len(dist_carga)),\n",
    ")\n",
    "ax4.set_title(\"üìà Distribuci√≥n de Carga de Trabajo\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Mejorar legibilidad del pie chart\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color(\"white\")\n",
    "    autotext.set_fontweight(\"bold\")\n",
    "\n",
    "# Gr√°fico 5: Correlaci√≥n Volumen vs Velocidad\n",
    "ax5 = fig.add_subplot(gs[2, :2])\n",
    "scatter = ax5.scatter(\n",
    "    productivity_stats[\"PRs_Total\"],\n",
    "    productivity_stats[\"Tiempo_Promedio\"],\n",
    "    c=productivity_stats[\"Score_Productividad\"],\n",
    "    cmap=\"RdYlGn\",\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "ax5.set_xlabel(\"Volumen de PRs\")\n",
    "ax5.set_ylabel(\"Tiempo Promedio (d√≠as)\")\n",
    "ax5.set_title(\"üéØ Relaci√≥n Volumen vs Velocidad\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Agregar colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax5)\n",
    "cbar.set_label(\"Score de Productividad\", rotation=270, labelpad=20)\n",
    "\n",
    "# Agregar l√≠nea de tendencia\n",
    "z = np.polyfit(\n",
    "    productivity_stats[\"PRs_Total\"], productivity_stats[\"Tiempo_Promedio\"], 1\n",
    ")\n",
    "p = np.poly1d(z)\n",
    "ax5.plot(\n",
    "    productivity_stats[\"PRs_Total\"],\n",
    "    p(productivity_stats[\"PRs_Total\"]),\n",
    "    \"r--\",\n",
    "    alpha=0.8,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "# Gr√°fico 6: Evoluci√≥n temporal de productividad (√∫ltimos 6 meses)\n",
    "ax6 = fig.add_subplot(gs[2, 2:])\n",
    "if len(df_prs_merged) > 0:\n",
    "    # Agrupar por mes\n",
    "    df_prs_merged[\"mes\"] = df_prs_merged[\"Fecha_Creacion\"].dt.to_period(\"M\")\n",
    "    productivity_monthly = (\n",
    "        df_prs_merged.groupby(\"mes\")\n",
    "        .agg({\"ID\": \"count\", \"Tiempo_Resolucion\": \"mean\"})\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Mostrar √∫ltimos 6 meses\n",
    "    productivity_monthly = productivity_monthly.tail(6)\n",
    "\n",
    "    ax6_twin = ax6.twinx()\n",
    "\n",
    "    # L√≠nea de volumen\n",
    "    line1 = ax6.plot(\n",
    "        productivity_monthly[\"mes\"].astype(str),\n",
    "        productivity_monthly[\"ID\"],\n",
    "        \"b-o\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        label=\"Volumen PRs\",\n",
    "    )\n",
    "    ax6.set_ylabel(\"N√∫mero de PRs\", color=\"blue\")\n",
    "    ax6.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    # L√≠nea de tiempo promedio\n",
    "    line2 = ax6_twin.plot(\n",
    "        productivity_monthly[\"mes\"].astype(str),\n",
    "        productivity_monthly[\"Tiempo_Resolucion\"],\n",
    "        \"r-s\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        label=\"Tiempo Promedio\",\n",
    "    )\n",
    "    ax6_twin.set_ylabel(\"Tiempo Promedio (d√≠as)\", color=\"red\")\n",
    "    ax6_twin.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    ax6.set_title(\n",
    "        \"üìÖ Evoluci√≥n Temporal de Productividad\", fontsize=14, fontweight=\"bold\"\n",
    "    )\n",
    "    ax6.set_xlabel(\"Mes\")\n",
    "    plt.setp(ax6.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Combinar leyendas\n",
    "    lines1, labels1 = ax6.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax6_twin.get_legend_handles_labels()\n",
    "    ax6.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "# Tabla resumen de insights\n",
    "ax7 = fig.add_subplot(gs[3, :])\n",
    "ax7.axis(\"tight\")\n",
    "ax7.axis(\"off\")\n",
    "\n",
    "# Generar insights autom√°ticos\n",
    "insights_data = [\n",
    "    [\n",
    "        \"üèÜ Desarrollador M√°s Productivo\",\n",
    "        productivity_stats.index[0],\n",
    "        f\"{productivity_stats.iloc[0]['Score_Productividad']:.1f} puntos\",\n",
    "    ],\n",
    "    [\n",
    "        \"‚ö° Desarrollador M√°s R√°pido\",\n",
    "        productivity_stats.nsmallest(1, \"Tiempo_Promedio\").index[0],\n",
    "        f\"{productivity_stats.nsmallest(1, 'Tiempo_Promedio').iloc[0]['Tiempo_Promedio']:.1f} d√≠as\",\n",
    "    ],\n",
    "    [\n",
    "        \"üéØ Desarrollador M√°s Volumen\",\n",
    "        productivity_stats.nlargest(1, \"PRs_Total\").index[0],\n",
    "        f\"{productivity_stats.nlargest(1, 'PRs_Total').iloc[0]['PRs_Total']} PRs\",\n",
    "    ],\n",
    "    [\n",
    "        \"üìä Promedio Equipo\",\n",
    "        \"Tiempo de Resoluci√≥n\",\n",
    "        f\"{productivity_stats['Tiempo_Promedio'].mean():.1f} d√≠as\",\n",
    "    ],\n",
    "    [\n",
    "        \"üîç Recomendaci√≥n\",\n",
    "        \"Desarrolladores a Analizar\",\n",
    "        f\"{len(productivity_stats[productivity_stats['Score_Productividad'] < 30])} con score < 30\",\n",
    "    ],\n",
    "]\n",
    "\n",
    "table = ax7.table(\n",
    "    cellText=insights_data,\n",
    "    colLabels=[\"M√©trica\", \"Valor\", \"Detalle\"],\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    "    colWidths=[0.3, 0.3, 0.4],\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Estilizar tabla\n",
    "for i in range(len(insights_data) + 1):\n",
    "    for j in range(3):\n",
    "        cell = table[(i, j)]\n",
    "        if i == 0:  # Header\n",
    "            cell.set_facecolor(\"#4CAF50\")\n",
    "            cell.set_text_props(weight=\"bold\", color=\"white\")\n",
    "        else:\n",
    "            cell.set_facecolor(\"#f8f9fa\" if i % 2 == 0 else \"white\")\n",
    "\n",
    "ax7.set_title(\n",
    "    \"üí° INSIGHTS Y RECOMENDACIONES CLAVE\", fontsize=16, fontweight=\"bold\", pad=20\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"üéØ DASHBOARD DE PRODUCTIVIDAD DEL EQUIPO\", fontsize=20, fontweight=\"bold\", y=0.98\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Dashboard de Productividad generado exitosamente!\")\n",
    "print(\n",
    "    f\"üìà Datos analizados: {len(df_prs_merged)} PRs de {len(productivity_stats)} desarrolladores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ac71a0",
   "metadata": {},
   "source": [
    "## üîç REPORTE 2: An√°lisis de Eficiencia y Calidad\n",
    "\n",
    "**Objetivo:** Evaluar la eficiencia en el proceso de revisi√≥n y la calidad del c√≥digo entregado.\n",
    "\n",
    "**M√©tricas incluidas:**\n",
    "- Tiempo de resoluci√≥n vs complejidad (comentarios/estandarizaciones)\n",
    "- Identificaci√≥n de desarrolladores que necesitan m√°s soporte\n",
    "- An√°lisis de patrones de trabajo y outliers\n",
    "- Correlaciones entre m√©tricas de calidad y eficiencia\n",
    "- Recomendaciones espec√≠ficas de mejora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1addddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================================\n",
    "# REPORTE 2: AN√ÅLISIS DE EFICIENCIA Y CALIDAD\n",
    "# ====================================================================================\n",
    "\n",
    "print(\"üîç AN√ÅLISIS DE EFICIENCIA Y CALIDAD\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. An√°lisis de correlaciones entre m√©tricas\n",
    "print(\"\\nüìä AN√ÅLISIS DE CORRELACIONES ENTRE M√âTRICAS:\")\n",
    "\n",
    "# Preparar datos para correlaciones\n",
    "correlation_data = df_prs_merged[\n",
    "    [\"Tiempo_Resolucion\", \"Devoluciones\", \"Estandarizaciones_Codigo\"]\n",
    "].copy()\n",
    "correlation_data.columns = [\n",
    "    \"Tiempo_Resoluci√≥n\",\n",
    "    \"Devoluciones\",\n",
    "    \"Estandarizaciones_C√≥digo\",\n",
    "]\n",
    "\n",
    "# Calcular matriz de correlaci√≥n\n",
    "corr_matrix = correlation_data.corr()\n",
    "print(\"\\nMatriz de Correlaci√≥n:\")\n",
    "display(corr_matrix.round(3))\n",
    "\n",
    "# 2. An√°lisis de eficiencia por desarrollador\n",
    "print(\"\\n\\n‚ö° AN√ÅLISIS DE EFICIENCIA POR DESARROLLADOR:\")\n",
    "\n",
    "# Calcular m√©tricas de eficiencia\n",
    "efficiency_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"Tiempo_Resolucion\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "            \"Devoluciones\": [\"mean\", \"std\"],\n",
    "            \"Estandarizaciones_Codigo\": [\"mean\", \"sum\"],\n",
    "            \"ID\": \"count\",\n",
    "        }\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "efficiency_stats.columns = [\n",
    "    \"Tiempo_Medio\",\n",
    "    \"Tiempo_Std\",\n",
    "    \"Tiempo_Min\",\n",
    "    \"Tiempo_Max\",\n",
    "    \"Devoluciones_Medio\",\n",
    "    \"Devoluciones_Std\",\n",
    "    \"Estandarizaciones_Medio\",\n",
    "    \"Estandarizaciones_Total\",\n",
    "    \"Total_PRs\",\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas de eficiencia\n",
    "efficiency_stats[\"Coef_Variacion_Tiempo\"] = (\n",
    "    efficiency_stats[\"Tiempo_Std\"] / efficiency_stats[\"Tiempo_Medio\"]\n",
    ") * 100\n",
    "efficiency_stats[\"Ratio_Estandarizaciones\"] = (\n",
    "    efficiency_stats[\"Estandarizaciones_Total\"] / efficiency_stats[\"Total_PRs\"]\n",
    ")\n",
    "efficiency_stats[\"Score_Consistencia\"] = 100 - efficiency_stats[\n",
    "    \"Coef_Variacion_Tiempo\"\n",
    "].fillna(0)\n",
    "efficiency_stats[\"Score_Calidad\"] = (\n",
    "    efficiency_stats[\"Ratio_Estandarizaciones\"]\n",
    "    / efficiency_stats[\"Ratio_Estandarizaciones\"].max()\n",
    ") * 100\n",
    "\n",
    "# Filtrar desarrolladores con al menos 3 PRs para an√°lisis m√°s confiable\n",
    "efficiency_relevant = efficiency_stats[efficiency_stats[\"Total_PRs\"] >= 3].copy()\n",
    "\n",
    "# Identificar categor√≠as de desarrolladores\n",
    "print(\"\\nüéØ CATEGORIZACI√ìN DE DESARROLLADORES:\")\n",
    "\n",
    "# Desarrolladores eficientes (r√°pidos y consistentes)\n",
    "eficientes = efficiency_relevant[\n",
    "    (\n",
    "        efficiency_relevant[\"Tiempo_Medio\"]\n",
    "        <= efficiency_relevant[\"Tiempo_Medio\"].quantile(0.25)\n",
    "    )\n",
    "    & (\n",
    "        efficiency_relevant[\"Score_Consistencia\"]\n",
    "        >= efficiency_relevant[\"Score_Consistencia\"].quantile(0.75)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Desarrolladores que necesitan soporte (lentos o inconsistentes)\n",
    "necesitan_soporte = efficiency_relevant[\n",
    "    (\n",
    "        efficiency_relevant[\"Tiempo_Medio\"]\n",
    "        >= efficiency_relevant[\"Tiempo_Medio\"].quantile(0.75)\n",
    "    )\n",
    "    | (\n",
    "        efficiency_relevant[\"Score_Consistencia\"]\n",
    "        <= efficiency_relevant[\"Score_Consistencia\"].quantile(0.25)\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Desarrolladores Eficientes: {len(eficientes)}\")\n",
    "print(f\"‚ö†Ô∏è  Desarrolladores que Necesitan Soporte: {len(necesitan_soporte)}\")\n",
    "print(\n",
    "    f\"üìä Desarrolladores Promedio: {len(efficiency_relevant) - len(eficientes) - len(necesitan_soporte)}\"\n",
    ")\n",
    "\n",
    "# 3. Crear visualizaci√≥n del an√°lisis de eficiencia\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.8, wspace=0.3)\n",
    "\n",
    "# Gr√°fico 1: Matriz de correlaci√≥n\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "im1 = ax1.imshow(corr_matrix, cmap=\"RdBu_r\", aspect=\"auto\", vmin=-1, vmax=1)\n",
    "ax1.set_xticks(range(len(corr_matrix.columns)))\n",
    "ax1.set_yticks(range(len(corr_matrix.columns)))\n",
    "ax1.set_xticklabels(corr_matrix.columns, rotation=45, ha=\"right\")\n",
    "ax1.set_yticklabels(corr_matrix.columns)\n",
    "ax1.set_title(\n",
    "    \"üîó Matriz de Correlaci√≥n\\nEntre M√©tricas\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "\n",
    "# Agregar valores en la matriz\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(len(corr_matrix.columns)):\n",
    "        text = ax1.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{corr_matrix.iloc[i, j]:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            color=\"white\" if abs(corr_matrix.iloc[i, j]) > 0.5 else \"black\",\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "# Colorbar para correlaci√≥n\n",
    "plt.colorbar(im1, ax=ax1, shrink=0.8)\n",
    "\n",
    "# Gr√°fico 2: Tiempo vs Complejidad (Devoluciones)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "scatter1 = ax2.scatter(\n",
    "    df_prs_merged[\"Devoluciones\"],\n",
    "    df_prs_merged[\"Tiempo_Resolucion\"],\n",
    "    c=df_prs_merged[\"Estandarizaciones_Codigo\"],\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.6,\n",
    "    s=50,\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.3,\n",
    ")\n",
    "ax2.set_xlabel(\"Devoluciones\")\n",
    "ax2.set_ylabel(\"Tiempo de Resoluci√≥n (d√≠as)\")\n",
    "ax2.set_title(\n",
    "    \"‚è±Ô∏è Tiempo vs Complejidad\\n(Color = Estandarizaciones)\",\n",
    "    fontsize=12,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.colorbar(scatter1, ax=ax2, shrink=0.8, label=\"Estandarizaciones\")\n",
    "\n",
    "# Agregar l√≠nea de tendencia\n",
    "if len(df_prs_merged) > 1:\n",
    "    z = np.polyfit(df_prs_merged[\"Devoluciones\"], df_prs_merged[\"Tiempo_Resolucion\"], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax2.plot(\n",
    "        df_prs_merged[\"Devoluciones\"],\n",
    "        p(df_prs_merged[\"Devoluciones\"]),\n",
    "        \"r--\",\n",
    "        alpha=0.8,\n",
    "        linewidth=2,\n",
    "    )\n",
    "\n",
    "# Gr√°fico 3: Distribuci√≥n de eficiencia por categor√≠as\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "categorias_count = [\n",
    "    len(eficientes),\n",
    "    len(necesitan_soporte),\n",
    "    len(efficiency_relevant) - len(eficientes) - len(necesitan_soporte),\n",
    "]\n",
    "categorias_labels = [\"Eficientes\", \"Necesitan\\nSoporte\", \"Promedio\"]\n",
    "colors_cat = [\"#2ecc71\", \"#e74c3c\", \"#f39c12\"]\n",
    "\n",
    "bars_cat = ax3.bar(categorias_labels, categorias_count, color=colors_cat, alpha=0.8)\n",
    "ax3.set_title(\n",
    "    \"üìä Distribuci√≥n por\\nCategor√≠a de Eficiencia\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax3.set_ylabel(\"N√∫mero de Desarrolladores\")\n",
    "\n",
    "# Agregar etiquetas en las barras\n",
    "for i, bar in enumerate(bars_cat):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(\n",
    "        bar.get_x() + bar.get_width() / 2.0,\n",
    "        height + 0.1,\n",
    "        f\"{int(height)}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# Gr√°fico 4: Top 10 m√°s eficientes\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "if len(efficiency_relevant) > 0:\n",
    "    # Calcular score combinado de eficiencia\n",
    "    efficiency_relevant[\"Score_Eficiencia\"] = (\n",
    "        (1 / efficiency_relevant[\"Tiempo_Medio\"])\n",
    "        / (1 / efficiency_relevant[\"Tiempo_Medio\"]).max()\n",
    "    ) * 50 + (efficiency_relevant[\"Score_Consistencia\"] / 100) * 50\n",
    "\n",
    "    top_10_eff = efficiency_relevant.nlargest(10, \"Score_Eficiencia\")\n",
    "\n",
    "    x_pos = range(len(top_10_eff))\n",
    "    bars_eff = ax4.bar(\n",
    "        x_pos,\n",
    "        top_10_eff[\"Score_Eficiencia\"],\n",
    "        color=plt.cm.RdYlGn([x / 100 for x in top_10_eff[\"Score_Eficiencia\"]]),\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax4.set_title(\n",
    "        \"üèÜ TOP 10 DESARROLLADORES M√ÅS EFICIENTES (Velocidad + Consistencia)\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax4.set_ylabel(\"Score de Eficiencia (0-100)\")\n",
    "    ax4.set_xticks(x_pos)\n",
    "    ax4.set_xticklabels(\n",
    "        [name[:20] + \"...\" if len(name) > 20 else name for name in top_10_eff.index],\n",
    "        rotation=45,\n",
    "        ha=\"right\",\n",
    "    )\n",
    "\n",
    "    # Agregar etiquetas con detalles\n",
    "    for i, bar in enumerate(bars_eff):\n",
    "        height = bar.get_height()\n",
    "        author = top_10_eff.index[i]\n",
    "        tiempo = top_10_eff.loc[author, \"Tiempo_Medio\"]\n",
    "        ax4.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 1,\n",
    "            f\"{height:.1f}\\n({tiempo:.1f}d)\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "# Gr√°fico 5: An√°lisis de outliers\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "# Boxplot de tiempos de resoluci√≥n\n",
    "bp = ax5.boxplot(\n",
    "    [df_prs_merged[\"Tiempo_Resolucion\"]],\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor=\"lightblue\", alpha=0.7),\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"üì¶ Detecci√≥n de Outliers\\nen Tiempo de Resoluci√≥n\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax5.set_ylabel(\"Tiempo (d√≠as)\")\n",
    "ax5.set_xticklabels([\"Todos los PRs\"])\n",
    "\n",
    "# Identificar outliers\n",
    "Q1 = df_prs_merged[\"Tiempo_Resolucion\"].quantile(0.25)\n",
    "Q3 = df_prs_merged[\"Tiempo_Resolucion\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df_prs_merged[df_prs_merged[\"Tiempo_Resolucion\"] > Q3 + 1.5 * IQR]\n",
    "\n",
    "ax5.text(\n",
    "    1.2,\n",
    "    Q3 + 1.5 * IQR,\n",
    "    f\"Outliers: {len(outliers)}\",\n",
    "    fontsize=10,\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
    ")\n",
    "\n",
    "# Gr√°fico 6: Consistencia vs Velocidad\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "if len(efficiency_relevant) > 0:\n",
    "    scatter2 = ax6.scatter(\n",
    "        efficiency_relevant[\"Tiempo_Medio\"],\n",
    "        efficiency_relevant[\"Score_Consistencia\"],\n",
    "        c=efficiency_relevant[\"Total_PRs\"],\n",
    "        cmap=\"plasma\",\n",
    "        s=100,\n",
    "        alpha=0.7,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "    ax6.set_xlabel(\"Tiempo Promedio (d√≠as)\")\n",
    "    ax6.set_ylabel(\"Score de Consistencia\")\n",
    "    ax6.set_title(\n",
    "        \"üéØ Consistencia vs Velocidad\\n(Tama√±o = Total PRs)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "    # Agregar l√≠neas de referencia\n",
    "    ax6.axhline(\n",
    "        y=efficiency_relevant[\"Score_Consistencia\"].mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax6.axvline(\n",
    "        x=efficiency_relevant[\"Tiempo_Medio\"].mean(),\n",
    "        color=\"red\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    plt.colorbar(scatter2, ax=ax6, shrink=0.8, label=\"Total PRs\")\n",
    "\n",
    "# Gr√°fico 7: Evoluci√≥n de calidad (estandarizaciones) en el tiempo\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "if len(df_prs_merged) > 0:\n",
    "    # Agrupar por mes y calcular promedio de estandarizaciones\n",
    "    df_prs_merged[\"mes\"] = df_prs_merged[\"Fecha_Creacion\"].dt.to_period(\"M\")\n",
    "    quality_evolution = (\n",
    "        df_prs_merged.groupby(\"mes\")[\"Estandarizaciones_Codigo\"].mean().tail(8)\n",
    "    )\n",
    "\n",
    "    ax7.plot(\n",
    "        quality_evolution.index.astype(str),\n",
    "        quality_evolution.values,\n",
    "        \"g-o\",\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "    )\n",
    "    ax7.set_title(\n",
    "        \"üìà Evoluci√≥n de Calidad\\n(Estandarizaciones/PR)\",\n",
    "        fontsize=12,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "    ax7.set_ylabel(\"Promedio Estandarizaciones\")\n",
    "    ax7.set_xlabel(\"Mes\")\n",
    "    plt.setp(ax7.xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "    # Agregar l√≠nea de tendencia\n",
    "    if len(quality_evolution) > 1:\n",
    "        z = np.polyfit(range(len(quality_evolution)), quality_evolution.values, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax7.plot(\n",
    "            quality_evolution.index.astype(str),\n",
    "            p(range(len(quality_evolution))),\n",
    "            \"r--\",\n",
    "            alpha=0.8,\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "# Tabla de desarrolladores que necesitan soporte\n",
    "ax8 = fig.add_subplot(gs[3, :])\n",
    "ax8.axis(\"tight\")\n",
    "ax8.axis(\"off\")\n",
    "\n",
    "if len(necesitan_soporte) > 0:\n",
    "    # Preparar datos para la tabla\n",
    "    support_data = []\n",
    "    for author in necesitan_soporte.head(5).index:  # Top 5 que m√°s necesitan soporte\n",
    "        tiempo = necesitan_soporte.loc[author, \"Tiempo_Medio\"]\n",
    "        consistencia = necesitan_soporte.loc[author, \"Score_Consistencia\"]\n",
    "        total_prs = necesitan_soporte.loc[author, \"Total_PRs\"]\n",
    "\n",
    "        # Determinar recomendaci√≥n\n",
    "        if tiempo > efficiency_relevant[\"Tiempo_Medio\"].quantile(0.75):\n",
    "            recomendacion = \"üêå Mejorar velocidad de desarrollo\"\n",
    "        elif consistencia < efficiency_relevant[\"Score_Consistencia\"].quantile(0.25):\n",
    "            recomendacion = \"üìä Trabajar en consistencia\"\n",
    "        else:\n",
    "            recomendacion = \"üîÑ Revisi√≥n general de proceso\"\n",
    "\n",
    "        support_data.append(\n",
    "            [\n",
    "                author[:25] + \"...\" if len(author) > 25 else author,\n",
    "                f\"{tiempo:.1f} d√≠as\",\n",
    "                f\"{consistencia:.1f}%\",\n",
    "                f\"{total_prs} PRs\",\n",
    "                recomendacion,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    table_support = ax8.table(\n",
    "        cellText=support_data,\n",
    "        colLabels=[\n",
    "            \"Desarrollador\",\n",
    "            \"Tiempo Promedio\",\n",
    "            \"Consistencia\",\n",
    "            \"Total PRs\",\n",
    "            \"Recomendaci√≥n\",\n",
    "        ],\n",
    "        cellLoc=\"center\",\n",
    "        loc=\"center\",\n",
    "        colWidths=[0.25, 0.15, 0.15, 0.1, 0.35],\n",
    "    )\n",
    "\n",
    "    table_support.auto_set_font_size(False)\n",
    "    table_support.set_fontsize(10)\n",
    "    table_support.scale(1, 2)\n",
    "\n",
    "    # Estilizar tabla\n",
    "    for i in range(len(support_data) + 1):\n",
    "        for j in range(5):\n",
    "            cell = table_support[(i, j)]\n",
    "            if i == 0:  # Header\n",
    "                cell.set_facecolor(\"#e74c3c\")\n",
    "                cell.set_text_props(weight=\"bold\", color=\"white\")\n",
    "            else:\n",
    "                cell.set_facecolor(\"#fff3cd\" if i % 2 == 0 else \"#ffeaa7\")\n",
    "\n",
    "ax8.set_title(\n",
    "    \"‚ö†Ô∏è DESARROLLADORES QUE NECESITAN SOPORTE PRIORITARIO\",\n",
    "    fontsize=16,\n",
    "    fontweight=\"bold\",\n",
    "    pad=20,\n",
    ")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"üîç AN√ÅLISIS DE EFICIENCIA Y CALIDAD DEL EQUIPO\",\n",
    "    fontsize=20,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.98,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Resumen ejecutivo de insights\n",
    "print(\"\\n\\nüí° INSIGHTS Y RECOMENDACIONES:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Correlaci√≥n m√°s fuerte\n",
    "max_corr = corr_matrix.abs().unstack().sort_values(ascending=False)\n",
    "max_corr = max_corr[max_corr < 1.0].iloc[0]\n",
    "corr_vars = corr_matrix.abs().unstack().sort_values(ascending=False).index[1]\n",
    "\n",
    "print(f\"üîó Correlaci√≥n m√°s fuerte: {corr_vars[0]} vs {corr_vars[1]} ({max_corr:.2f})\")\n",
    "print(f\"‚ö° Desarrolladores m√°s eficientes: {len(eficientes)}\")\n",
    "print(f\"‚ö†Ô∏è  Desarrolladores que necesitan soporte: {len(necesitan_soporte)}\")\n",
    "print(\n",
    "    f\"üìä Tiempo promedio del equipo: {efficiency_relevant['Tiempo_Medio'].mean():.1f} d√≠as\"\n",
    ")\n",
    "print(\n",
    "    f\"üéØ Coeficiente de variaci√≥n promedio: {efficiency_relevant['Coef_Variacion_Tiempo'].mean():.1f}%\"\n",
    ")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(\n",
    "        f\"üö® PRs outliers detectados: {len(outliers)} ({len(outliers) / len(df_prs_merged) * 100:.1f}% del total)\"\n",
    "    )\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis de Eficiencia y Calidad completado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d6c73",
   "metadata": {},
   "source": [
    "## üîç REPORTE 4: M√©tricas de Calidad del C√≥digo (Previas a QA/Revisi√≥n Senior)\n",
    "\n",
    "Este reporte analiza espec√≠ficamente las **devoluciones por PR**, proporcionando insights sobre la calidad inicial del c√≥digo antes de pasar por controles de calidad y revisiones senior. Las devoluciones son un indicador clave de cu√°ntos PRs no cumplen los est√°ndares esperados en el primer intento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORTE 4: M√âTRICAS DE CALIDAD DEL C√ìDIGO (DEVOLUCIONES)\n",
    "print(\"üîç M√âTRICAS DE CALIDAD DEL C√ìDIGO - AN√ÅLISIS DE DEVOLUCIONES\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# 1. Estad√≠sticas b√°sicas de devoluciones\n",
    "print(\"\\nüìä ESTAD√çSTICAS B√ÅSICAS DE DEVOLUCIONES:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "devoluciones_stats = df_prs_merged[\"Devoluciones\"].describe()\n",
    "print(f\"Total de PRs analizados: {len(df_prs_merged):,}\")\n",
    "print(f\"Total de devoluciones: {df_prs_merged['Devoluciones'].sum():,}\")\n",
    "print(f\"Promedio de devoluciones por PR: {devoluciones_stats['mean']:.2f}\")\n",
    "print(f\"Mediana: {devoluciones_stats['50%']:.2f}\")\n",
    "print(f\"Desviaci√≥n est√°ndar: {devoluciones_stats['std']:.2f}\")\n",
    "print(f\"M√≠nimo: {int(devoluciones_stats['min'])}\")\n",
    "print(f\"M√°ximo: {int(devoluciones_stats['max'])}\")\n",
    "\n",
    "# 2. An√°lisis de calidad inicial\n",
    "prs_sin_devoluciones = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] == 0])\n",
    "prs_con_devoluciones = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 0])\n",
    "porcentaje_sin_devoluciones = (prs_sin_devoluciones / len(df_prs_merged)) * 100\n",
    "porcentaje_con_devoluciones = (prs_con_devoluciones / len(df_prs_merged)) * 100\n",
    "\n",
    "print(f\"\\nüéØ AN√ÅLISIS DE CALIDAD INICIAL:\")\n",
    "print(\"-\" * 35)\n",
    "print(\n",
    "    f\"PRs aprobados al primer intento: {prs_sin_devoluciones:,} ({porcentaje_sin_devoluciones:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"PRs que requirieron correcciones: {prs_con_devoluciones:,} ({porcentaje_con_devoluciones:.1f}%)\"\n",
    ")\n",
    "\n",
    "# Interpretaci√≥n de calidad\n",
    "if porcentaje_sin_devoluciones >= 70:\n",
    "    calidad_general = \"EXCELENTE\"\n",
    "    color_calidad = \"üü¢\"\n",
    "elif porcentaje_sin_devoluciones >= 50:\n",
    "    calidad_general = \"BUENA\"\n",
    "    color_calidad = \"üü°\"\n",
    "else:\n",
    "    calidad_general = \"REQUIERE MEJORA\"\n",
    "    color_calidad = \"üî¥\"\n",
    "\n",
    "print(f\"Calidad inicial del c√≥digo: {color_calidad} {calidad_general}\")\n",
    "\n",
    "# 3. Distribuci√≥n de devoluciones\n",
    "print(f\"\\nüìà DISTRIBUCI√ìN DE DEVOLUCIONES:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Crear categor√≠as para las devoluciones\n",
    "dev_bins = [-0.1, 0, 1, 3, 5, float(\"inf\")]\n",
    "dev_labels = [\n",
    "    \"Sin devoluciones\",\n",
    "    \"Baja (1)\",\n",
    "    \"Media (2-3)\",\n",
    "    \"Alta (4-5)\",\n",
    "    \"Muy Alta (>5)\",\n",
    "]\n",
    "df_prs_merged[\"Devoluciones_Categoria\"] = pd.cut(\n",
    "    df_prs_merged[\"Devoluciones\"], bins=dev_bins, labels=dev_labels, right=True\n",
    ")\n",
    "\n",
    "dev_distribution = df_prs_merged[\"Devoluciones_Categoria\"].value_counts()\n",
    "dev_percentages = (dev_distribution / len(df_prs_merged) * 100).round(1)\n",
    "\n",
    "for categoria, count in dev_distribution.items():\n",
    "    percentage = dev_percentages[categoria]\n",
    "    print(f\"{categoria}: {count:,} PRs ({percentage}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Estad√≠sticas b√°sicas de devoluciones completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c347faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. An√°lisis por desarrollador\n",
    "print(\"\\nüë®‚Äçüíª AN√ÅLISIS POR DESARROLLADOR:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Estad√≠sticas por autor\n",
    "dev_por_autor = df_prs_merged.groupby('Autor')['Devoluciones'].agg([\n",
    "    'count', 'sum', 'mean', 'std'\n",
    "]).round(2)\n",
    "dev_por_autor.columns = ['PRs_Total', 'Dev_Total', 'Dev_Promedio', 'Dev_Std']\n",
    "dev_por_autor['Tasa_Exito'] = ((dev_por_autor['PRs_Total'] - df_prs_merged.groupby('Autor')['Devoluciones'].apply(lambda x: (x > 0).sum())) / dev_por_autor['PRs_Total'] * 100).round(1)\n",
    "dev_por_autor = dev_por_autor.sort_values('Dev_Promedio', ascending=True)\n",
    "\n",
    "print(\"üèÜ TOP 10 DESARROLLADORES CON MEJOR CALIDAD INICIAL (Menos Devoluciones):\")\n",
    "mejores_devs = dev_por_autor[dev_por_autor['PRs_Total'] >= 3].head(10)\n",
    "for autor, data in mejores_devs.iterrows():\n",
    "    print(f\"{autor}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de √©xito\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  DESARROLLADORES QUE REQUIEREN ATENCI√ìN (M√°s Devoluciones):\")\n",
    "devs_atencion = dev_por_autor[dev_por_autor['PRs_Total'] >= 3].tail(5)\n",
    "for autor, data in devs_atencion.iterrows():\n",
    "    print(f\"{autor}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de √©xito\")\n",
    "\n",
    "# 5. An√°lisis por repositorio\n",
    "print(\"\\nüì¶ AN√ÅLISIS POR REPOSITORIO:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "dev_por_repo = df_prs_merged.groupby('Repositorio')['Devoluciones'].agg([\n",
    "    'count', 'sum', 'mean', 'std'\n",
    "]).round(2)\n",
    "dev_por_repo.columns = ['PRs_Total', 'Dev_Total', 'Dev_Promedio', 'Dev_Std']\n",
    "dev_por_repo['Tasa_Exito'] = ((dev_por_repo['PRs_Total'] - df_prs_merged.groupby('Repositorio')['Devoluciones'].apply(lambda x: (x > 0).sum())) / dev_por_repo['PRs_Total'] * 100).round(1)\n",
    "dev_por_repo = dev_por_repo.sort_values('Dev_Promedio', ascending=True)\n",
    "\n",
    "print(\"üèÜ REPOSITORIOS CON MEJOR CALIDAD DE C√ìDIGO:\")\n",
    "mejores_repos = dev_por_repo[dev_por_repo['PRs_Total'] >= 3].head(5)\n",
    "for repo, data in mejores_repos.iterrows():\n",
    "    print(f\"{repo}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de √©xito ({int(data['PRs_Total'])} PRs)\")\n",
    "\n",
    "print(\"‚ö†Ô∏è  REPOSITORIOS QUE REQUIEREN ATENCI√ìN:\")\n",
    "repos_atencion = dev_por_repo[dev_por_repo['PRs_Total'] >= 3].tail(3)\n",
    "for repo, data in repos_atencion.iterrows():\n",
    "    print(f\"{repo}: {data['Dev_Promedio']:.1f} promedio, {data['Tasa_Exito']:.0f}% tasa de √©xito ({int(data['PRs_Total'])} PRs)\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis por desarrollador y repositorio completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f41bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Crear visualizaciones espec√≠ficas para devoluciones\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = plt.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Histograma principal de devoluciones (seaborn)\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "import seaborn as sns\n",
    "sns.histplot(data=df_prs_merged, x='Devoluciones', bins=15, kde=True, alpha=0.7, \n",
    "             color='skyblue', ax=ax1)\n",
    "ax1.set_title('üìä Distribuci√≥n de Devoluciones por PR\\n(Histograma con Densidad)', \n",
    "             fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('N√∫mero de Devoluciones')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax1.axvline(df_prs_merged['Devoluciones'].mean(), color='red', \n",
    "           linestyle='--', linewidth=2, label=f'Promedio: {df_prs_merged[\"Devoluciones\"].mean():.1f}')\n",
    "ax1.axvline(df_prs_merged['Devoluciones'].median(), color='orange', \n",
    "           linestyle='--', linewidth=2, label=f'Mediana: {df_prs_merged[\"Devoluciones\"].median():.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Agregar anotaciones de insights\n",
    "max_freq = ax1.patches[0].get_height()\n",
    "for patch in ax1.patches:\n",
    "    max_freq = max(max_freq, patch.get_height())\n",
    "\n",
    "# Insight sobre cola larga\n",
    "devoluciones_altas = len(df_prs_merged[df_prs_merged['Devoluciones'] > 3])\n",
    "if devoluciones_altas > 0:\n",
    "    ax1.text(0.7, 0.9, f'‚ö†Ô∏è Cola larga detectada:\\n{devoluciones_altas} PRs con >3 devoluciones\\n(Posibles problemas de calidad)', \n",
    "             transform=ax1.transAxes, bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.7),\n",
    "             fontsize=10, verticalalignment='top')\n",
    "\n",
    "# 2. Gr√°fico de barras por categor√≠as\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "categories_order = ['Sin devoluciones', 'Baja (1)', 'Media (2-3)', 'Alta (4-5)', 'Muy Alta (>5)']\n",
    "valid_categories = [cat for cat in categories_order if cat in dev_distribution.index]\n",
    "bars = ax2.bar(range(len(valid_categories)), \n",
    "               [dev_distribution[cat] for cat in valid_categories],\n",
    "               color=['green', 'lightgreen', 'yellow', 'orange', 'red'][:len(valid_categories)])\n",
    "\n",
    "ax2.set_xticks(range(len(valid_categories)))\n",
    "ax2.set_xticklabels([cat.replace(' ', '\\n') for cat in valid_categories], fontsize=9)\n",
    "ax2.set_title('üìà PRs por Categor√≠a\\nde Devoluciones', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('N√∫mero de PRs')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar, cat in zip(bars, valid_categories):\n",
    "    height = bar.get_height()\n",
    "    percentage = dev_percentages[cat]\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, height + 0.5, \n",
    "            f'{int(height)}\\n({percentage:.1f}%)', \n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# 3. Top desarrolladores con mejor calidad\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "top_devs = mejores_devs.head(8)\n",
    "bars = ax3.barh(range(len(top_devs)), top_devs['Tasa_Exito'], \n",
    "                color='lightgreen', edgecolor='darkgreen')\n",
    "ax3.set_yticks(range(len(top_devs)))\n",
    "ax3.set_yticklabels([dev[:15] + '...' if len(dev) > 15 else dev for dev in top_devs.index])\n",
    "ax3.set_title('üèÜ Top Desarrolladores\\n(Tasa de √âxito %)', fontweight='bold', fontsize=12)\n",
    "ax3.set_xlabel('Tasa de √âxito (%)')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars, top_devs['Tasa_Exito'])):\n",
    "    ax3.text(value + 1, i, f'{value:.0f}%', va='center', fontsize=9)\n",
    "\n",
    "# 4. Desarrolladores que requieren atenci√≥n\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "devs_problemas = devs_atencion\n",
    "bars = ax4.barh(range(len(devs_problemas)), devs_problemas['Dev_Promedio'], \n",
    "                color='lightcoral', edgecolor='darkred')\n",
    "ax4.set_yticks(range(len(devs_problemas)))\n",
    "ax4.set_yticklabels([dev[:15] + '...' if len(dev) > 15 else dev for dev in devs_problemas.index])\n",
    "ax4.set_title('‚ö†Ô∏è Desarrolladores que\\nRequieren Atenci√≥n', fontweight='bold', fontsize=12)\n",
    "ax4.set_xlabel('Promedio de Devoluciones')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, value) in enumerate(zip(bars, devs_problemas['Dev_Promedio'])):\n",
    "    ax4.text(value + 0.05, i, f'{value:.1f}', va='center', fontsize=9)\n",
    "\n",
    "# 5. An√°lisis de repositorios\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "repos_chart = mejores_repos\n",
    "bars = ax5.bar(range(len(repos_chart)), repos_chart['Tasa_Exito'], \n",
    "               color='lightblue', edgecolor='darkblue')\n",
    "ax5.set_xticks(range(len(repos_chart)))\n",
    "ax5.set_xticklabels([repo[:8] + '...' if len(repo) > 8 else repo \n",
    "                    for repo in repos_chart.index], rotation=45, ha='right')\n",
    "ax5.set_title('üì¶ Repositorios con\\nMejor Calidad', fontweight='bold', fontsize=12)\n",
    "ax5.set_ylabel('Tasa de √âxito (%)')\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for bar, value in zip(bars, repos_chart['Tasa_Exito']):\n",
    "    ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{value:.0f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 6. Correlaci√≥n devoluciones vs otras m√©tricas\n",
    "ax6 = fig.add_subplot(gs[2, 0])\n",
    "if 'Tiempo_Resolucion' in df_prs_merged.columns:\n",
    "    scatter = ax6.scatter(df_prs_merged['Devoluciones'], \n",
    "                         df_prs_merged['Tiempo_Resolucion'],\n",
    "                         alpha=0.6, color='purple')\n",
    "    ax6.set_title('üîó Devoluciones vs\\nTiempo de Resoluci√≥n', fontweight='bold', fontsize=12)\n",
    "    ax6.set_xlabel('N√∫mero de Devoluciones')\n",
    "    ax6.set_ylabel('Tiempo de Resoluci√≥n (d√≠as)')\n",
    "    \n",
    "    # L√≠nea de tendencia\n",
    "    z = np.polyfit(df_prs_merged['Devoluciones'], df_prs_merged['Tiempo_Resolucion'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax6.plot(df_prs_merged['Devoluciones'], p(df_prs_merged['Devoluciones']), \"r--\", alpha=0.8)\n",
    "    \n",
    "    corr = df_prs_merged['Devoluciones'].corr(df_prs_merged['Tiempo_Resolucion'])\n",
    "    ax6.text(0.05, 0.95, f'Correlaci√≥n: {corr:.3f}', transform=ax6.transAxes, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# 7. Correlaci√≥n devoluciones vs estandarizaciones\n",
    "ax7 = fig.add_subplot(gs[2, 1])\n",
    "scatter = ax7.scatter(df_prs_merged['Devoluciones'], \n",
    "                     df_prs_merged['Estandarizaciones_Codigo'],\n",
    "                     alpha=0.6, color='orange')\n",
    "ax7.set_title('üîó Devoluciones vs\\nEstandarizaciones', fontweight='bold', fontsize=12)\n",
    "ax7.set_xlabel('N√∫mero de Devoluciones')\n",
    "ax7.set_ylabel('Estandarizaciones de C√≥digo')\n",
    "\n",
    "# L√≠nea de tendencia\n",
    "z = np.polyfit(df_prs_merged['Devoluciones'], df_prs_merged['Estandarizaciones_Codigo'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax7.plot(df_prs_merged['Devoluciones'], p(df_prs_merged['Devoluciones']), \"r--\", alpha=0.8)\n",
    "\n",
    "corr = df_prs_merged['Devoluciones'].corr(df_prs_merged['Estandarizaciones_Codigo'])\n",
    "ax7.text(0.05, 0.95, f'Correlaci√≥n: {corr:.3f}', transform=ax7.transAxes, \n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# 8. Box plot comparativo por repositorio\n",
    "ax8 = fig.add_subplot(gs[2, 2])\n",
    "repos_principales = df_prs_merged['Repositorio'].value_counts().head(4).index\n",
    "box_data = [df_prs_merged[df_prs_merged['Repositorio'] == repo]['Devoluciones'].values \n",
    "           for repo in repos_principales]\n",
    "\n",
    "bp = ax8.boxplot(box_data, labels=[repo[:8] + '...' if len(repo) > 8 else repo \n",
    "                                  for repo in repos_principales], patch_artist=True)\n",
    "colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightcoral']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax8.set_title('üì¶ Distribuci√≥n de Devoluciones\\npor Repositorio', fontweight='bold', fontsize=12)\n",
    "ax8.set_ylabel('N√∫mero de Devoluciones')\n",
    "ax8.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('üîç AN√ÅLISIS COMPLETO DE M√âTRICAS DE CALIDAD - DEVOLUCIONES', \n",
    "             fontsize=18, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualizaciones de m√©tricas de calidad (devoluciones) completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Insights espec√≠ficos y recomendaciones\n",
    "print(\"\\n\\nüí° INSIGHTS Y RECOMENDACIONES DE CALIDAD:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# M√©tricas clave\n",
    "total_dev = df_prs_merged[\"Devoluciones\"].sum()\n",
    "promedio_dev = df_prs_merged[\"Devoluciones\"].mean()\n",
    "tasa_exito_general = porcentaje_sin_devoluciones\n",
    "\n",
    "print(f\"üìä M√âTRICAS CLAVE DE CALIDAD:\")\n",
    "print(f\"   ‚Ä¢ Total de devoluciones: {total_dev:,}\")\n",
    "print(f\"   ‚Ä¢ Promedio por PR: {promedio_dev:.2f}\")\n",
    "print(f\"   ‚Ä¢ Tasa de √©xito general: {tasa_exito_general:.1f}%\")\n",
    "print(f\"   ‚Ä¢ Estado de calidad: {color_calidad} {calidad_general}\")\n",
    "\n",
    "# An√°lisis de cola larga\n",
    "prs_cola_larga = len(df_prs_merged[df_prs_merged[\"Devoluciones\"] > 3])\n",
    "porcentaje_cola_larga = (prs_cola_larga / len(df_prs_merged)) * 100\n",
    "\n",
    "print(f\"\\nüîç AN√ÅLISIS DE COLA LARGA:\")\n",
    "if prs_cola_larga > 0:\n",
    "    print(\n",
    "        f\"   ‚Ä¢ PRs con >3 devoluciones: {prs_cola_larga} ({porcentaje_cola_larga:.1f}%)\"\n",
    "    )\n",
    "    if porcentaje_cola_larga > 15:\n",
    "        print(f\"   ‚ö†Ô∏è  ALERTA: Cola larga significativa detectada\")\n",
    "        print(\n",
    "            f\"   üìù Sugiere: Problemas sistem√°ticos de calidad o criterios poco claros\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Cola larga dentro de par√°metros normales\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ No se detecta cola larga problem√°tica\")\n",
    "\n",
    "# Correlaciones importantes\n",
    "corr_tiempo = (\n",
    "    df_prs_merged[\"Devoluciones\"].corr(df_prs_merged[\"Tiempo_Resolucion\"])\n",
    "    if \"Tiempo_Resolucion\" in df_prs_merged.columns\n",
    "    else 0\n",
    ")\n",
    "corr_est = df_prs_merged[\"Devoluciones\"].corr(df_prs_merged[\"Estandarizaciones_Codigo\"])\n",
    "\n",
    "print(f\"\\nüîó CORRELACIONES IMPORTANTES:\")\n",
    "if abs(corr_tiempo) > 0.3:\n",
    "    print(f\"   ‚Ä¢ Devoluciones vs Tiempo: {corr_tiempo:.3f} (correlaci√≥n significativa)\")\n",
    "    print(f\"     ‚Üí M√°s devoluciones = Mayor tiempo de resoluci√≥n\")\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Devoluciones vs Tiempo: {corr_tiempo:.3f} (correlaci√≥n d√©bil)\")\n",
    "\n",
    "if abs(corr_est) > 0.3:\n",
    "    print(\n",
    "        f\"   ‚Ä¢ Devoluciones vs Estandarizaciones: {corr_est:.3f} (correlaci√≥n significativa)\"\n",
    "    )\n",
    "    if corr_est > 0:\n",
    "        print(\n",
    "            f\"     ‚Üí M√°s devoluciones = M√°s estandarizaciones aplicadas posteriormente\"\n",
    "        )\n",
    "else:\n",
    "    print(f\"   ‚Ä¢ Devoluciones vs Estandarizaciones: {corr_est:.3f} (correlaci√≥n d√©bil)\")\n",
    "\n",
    "# Generar alertas espec√≠ficas\n",
    "alertas_calidad = []\n",
    "\n",
    "if tasa_exito_general < 50:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"CR√çTICA\",\n",
    "            \"mensaje\": f\"Tasa de √©xito muy baja ({tasa_exito_general:.1f}%)\",\n",
    "            \"accion\": \"Revisar proceso completo de desarrollo y criterios de calidad\",\n",
    "        }\n",
    "    )\n",
    "elif tasa_exito_general < 70:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"ALTA\",\n",
    "            \"mensaje\": f\"Tasa de √©xito baja ({tasa_exito_general:.1f}%)\",\n",
    "            \"accion\": \"Implementar mejores pr√°cticas de c√≥digo y revisiones previas\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "if porcentaje_cola_larga > 15:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"ALTA\",\n",
    "            \"mensaje\": f\"Cola larga detectada ({porcentaje_cola_larga:.1f}% con >3 devoluciones)\",\n",
    "            \"accion\": \"Clarificar criterios de calidad y mejorar capacitaci√≥n\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "if promedio_dev > 2:\n",
    "    alertas_calidad.append(\n",
    "        {\n",
    "            \"nivel\": \"MEDIA\",\n",
    "            \"mensaje\": f\"Promedio alto de devoluciones ({promedio_dev:.1f})\",\n",
    "            \"accion\": \"Implementar checklist de calidad antes de PR\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Mostrar alertas\n",
    "if len(alertas_calidad) > 0:\n",
    "    print(f\"\\nüö® ALERTAS DE CALIDAD:\")\n",
    "    for i, alerta in enumerate(alertas_calidad, 1):\n",
    "        icono = (\n",
    "            \"üî¥\"\n",
    "            if alerta[\"nivel\"] == \"CR√çTICA\"\n",
    "            else \"üü†\"\n",
    "            if alerta[\"nivel\"] == \"ALTA\"\n",
    "            else \"üü°\"\n",
    "        )\n",
    "        print(f\"   {i}. {icono} {alerta['nivel']}: {alerta['mensaje']}\")\n",
    "        print(f\"      ‚Üí Acci√≥n: {alerta['accion']}\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ No se detectaron alertas cr√≠ticas de calidad\")\n",
    "\n",
    "# Mejores pr√°cticas identificadas\n",
    "print(f\"\\nüèÜ MEJORES PR√ÅCTICAS IDENTIFICADAS:\")\n",
    "if len(mejores_devs) > 0:\n",
    "    mejor_dev = mejores_devs.index[0]\n",
    "    mejor_tasa = mejores_devs.iloc[0][\"Tasa_Exito\"]\n",
    "    print(f\"   ‚Ä¢ Mejor desarrollador: {mejor_dev} ({mejor_tasa:.0f}% tasa de √©xito)\")\n",
    "\n",
    "if len(mejores_repos) > 0:\n",
    "    mejor_repo = mejores_repos.index[0]\n",
    "    mejor_repo_tasa = mejores_repos.iloc[0][\"Tasa_Exito\"]\n",
    "    print(\n",
    "        f\"   ‚Ä¢ Mejor repositorio: {mejor_repo} ({mejor_repo_tasa:.0f}% tasa de √©xito)\"\n",
    "    )\n",
    "\n",
    "# Recomendaciones prioritarias\n",
    "print(f\"\\nüéØ RECOMENDACIONES PRIORITARIAS:\")\n",
    "\n",
    "if tasa_exito_general < 70:\n",
    "    print(f\"   1. üîß Implementar c√≥digo de revisi√≥n peer-to-peer antes de PR\")\n",
    "    print(f\"   2. üìö Crear gu√≠as de est√°ndares de c√≥digo m√°s claras\")\n",
    "    print(f\"   3. üéì Programa de capacitaci√≥n en mejores pr√°cticas\")\n",
    "\n",
    "if len(devs_atencion) > 0:\n",
    "    print(f\"   4. üë• Mentoring espec√≠fico para desarrolladores con baja tasa de √©xito\")\n",
    "    print(f\"   5. üîç Revisi√≥n de criterios de calidad para uniformidad\")\n",
    "\n",
    "if porcentaje_cola_larga > 10:\n",
    "    print(f\"   6. üìã Checklist obligatorio de calidad antes de enviar PR\")\n",
    "    print(f\"   7. ü§ñ Herramientas automatizadas de an√°lisis de c√≥digo\")\n",
    "\n",
    "print(f\"\\nüìã RESUMEN EJECUTIVO:\")\n",
    "print(f\"   ‚Ä¢ Calidad inicial: {color_calidad} {calidad_general}\")\n",
    "print(f\"   ‚Ä¢ Tasa de √©xito: {tasa_exito_general:.1f}%\")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Desarrolladores destacados: {len(mejores_devs[mejores_devs['Tasa_Exito'] > 80])}\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Repositorios con buena calidad: {len(mejores_repos[mejores_repos['Tasa_Exito'] > 80])}\"\n",
    ")\n",
    "\n",
    "# Interpretaci√≥n de cola larga espec√≠fica\n",
    "if prs_cola_larga > 0:\n",
    "    print(f\"   ‚Ä¢ Cola larga: {prs_cola_larga} PRs requieren atenci√≥n especial\")\n",
    "    if porcentaje_cola_larga > 15:\n",
    "        print(f\"   üî¥ Indica problemas sistem√°ticos de calidad\")\n",
    "    else:\n",
    "        print(f\"   üü° Dentro de par√°metros normales pero monitoreable\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis de M√©tricas de Calidad del C√≥digo COMPLETADO!\")\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33776faf",
   "metadata": {},
   "source": [
    "## üë• REPORTE 5: An√°lisis de Devoluciones por Autor\n",
    "\n",
    "Este reporte se enfoca espec√≠ficamente en el an√°lisis de **devoluciones por desarrollador**, identificando patrones de calidad individual y proporcionando insights sobre qu√© desarrolladores entregan c√≥digo que cumple los criterios de QA versus aquellos que requieren m√∫ltiples iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ef109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORTE 5: AN√ÅLISIS DE DEVOLUCIONES POR AUTOR\n",
    "print(\"üë• AN√ÅLISIS DETALLADO DE DEVOLUCIONES POR AUTOR\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# 1. Estad√≠sticas completas por autor\n",
    "print(\"\\nüìä ESTAD√çSTICAS DETALLADAS POR DESARROLLADOR:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Crear an√°lisis completo por autor\n",
    "autor_stats = (\n",
    "    df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"]\n",
    "    .agg(\n",
    "        [\n",
    "            \"count\",  # Total de PRs\n",
    "            \"sum\",  # Total de devoluciones\n",
    "            \"mean\",  # Promedio de devoluciones\n",
    "            \"median\",  # Mediana de devoluciones\n",
    "            \"std\",  # Desviaci√≥n est√°ndar\n",
    "            \"min\",  # M√≠nimo de devoluciones\n",
    "            \"max\",  # M√°ximo de devoluciones\n",
    "        ]\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "autor_stats.columns = [\n",
    "    \"PRs_Total\",\n",
    "    \"Dev_Total\",\n",
    "    \"Dev_Promedio\",\n",
    "    \"Dev_Mediana\",\n",
    "    \"Dev_Std\",\n",
    "    \"Dev_Min\",\n",
    "    \"Dev_Max\",\n",
    "]\n",
    "\n",
    "# Calcular m√©tricas adicionales\n",
    "autor_stats[\"Tasa_Exito\"] = (\n",
    "    (\n",
    "        autor_stats[\"PRs_Total\"]\n",
    "        - df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"].apply(lambda x: (x > 0).sum())\n",
    "    )\n",
    "    / autor_stats[\"PRs_Total\"]\n",
    "    * 100\n",
    ").round(1)\n",
    "autor_stats[\"Coef_Variacion\"] = (\n",
    "    (autor_stats[\"Dev_Std\"] / autor_stats[\"Dev_Promedio\"] * 100).fillna(0).round(1)\n",
    ")\n",
    "autor_stats[\"PRs_Sin_Dev\"] = df_prs_merged.groupby(\"Autor\")[\"Devoluciones\"].apply(\n",
    "    lambda x: (x == 0).sum()\n",
    ")\n",
    "autor_stats[\"PRs_Con_Dev\"] = autor_stats[\"PRs_Total\"] - autor_stats[\"PRs_Sin_Dev\"]\n",
    "\n",
    "# Filtrar autores con al menos 3 PRs para an√°lisis m√°s representativo\n",
    "autor_stats_filtered = autor_stats[autor_stats[\"PRs_Total\"] >= 3].copy()\n",
    "\n",
    "print(f\"Total de desarrolladores analizados: {len(autor_stats)}\")\n",
    "print(f\"Desarrolladores con ‚â•3 PRs: {len(autor_stats_filtered)}\")\n",
    "print(f\"Promedio general de devoluciones: {df_prs_merged['Devoluciones'].mean():.2f}\")\n",
    "\n",
    "# 2. Clasificaci√≥n de desarrolladores por calidad\n",
    "print(f\"\\nüèÜ CLASIFICACI√ìN POR CALIDAD DE C√ìDIGO:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Clasificar desarrolladores\n",
    "excelentes = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 80)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 1)\n",
    "]\n",
    "buenos = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 60)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 2)\n",
    "]\n",
    "regulares = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] >= 40)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 3)\n",
    "]\n",
    "necesitan_atencion = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"Tasa_Exito\"] < 40)\n",
    "    | (autor_stats_filtered[\"Dev_Promedio\"] > 3)\n",
    "]\n",
    "\n",
    "print(f\"üü¢ EXCELENTES (Tasa ‚â•80%, Prom ‚â§1): {len(excelentes)} desarrolladores\")\n",
    "for dev in excelentes.head(3).index:\n",
    "    data = excelentes.loc[dev]\n",
    "    print(\n",
    "        f\"   ‚Ä¢ {dev}: {data['Tasa_Exito']:.0f}% √©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nüü° BUENOS (Tasa ‚â•60%, Prom ‚â§2): {len(buenos)} desarrolladores\")\n",
    "for dev in buenos.head(3).index:\n",
    "    data = buenos.loc[dev]\n",
    "    print(\n",
    "        f\"   ‚Ä¢ {dev}: {data['Tasa_Exito']:.0f}% √©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nüü† REGULARES: {len(regulares)} desarrolladores\")\n",
    "for dev in regulares.head(3).index:\n",
    "    data = regulares.loc[dev]\n",
    "    print(\n",
    "        f\"   ‚Ä¢ {dev}: {data['Tasa_Exito']:.0f}% √©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nüî¥ NECESITAN ATENCI√ìN: {len(necesitan_atencion)} desarrolladores\")\n",
    "for dev in necesitan_atencion.index:\n",
    "    data = necesitan_atencion.loc[dev]\n",
    "    print(\n",
    "        f\"   ‚Ä¢ {dev}: {data['Tasa_Exito']:.0f}% √©xito, {data['Dev_Promedio']:.1f} prom ({int(data['PRs_Total'])} PRs)\"\n",
    "    )\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis estad√≠stico por autor completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14580e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Crear visualizaciones espec√≠ficas por autor\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = plt.GridSpec(4, 2, figure=fig, hspace=0.4, wspace=0.3)\n",
    "\n",
    "# 1. Gr√°fico de barras principal: Promedio de devoluciones por autor (seaborn)\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "# Ordenar por promedio de devoluciones para mejor visualizaci√≥n\n",
    "autor_stats_sorted = autor_stats_filtered.sort_values(\"Dev_Promedio\")\n",
    "\n",
    "# Crear colores basados en la clasificaci√≥n\n",
    "colors_clasificacion = []\n",
    "for autor in autor_stats_sorted.index:\n",
    "    if autor in excelentes.index:\n",
    "        colors_clasificacion.append(\"green\")\n",
    "    elif autor in buenos.index:\n",
    "        colors_clasificacion.append(\"gold\")\n",
    "    elif autor in regulares.index:\n",
    "        colors_clasificacion.append(\"orange\")\n",
    "    else:\n",
    "        colors_clasificacion.append(\"red\")\n",
    "\n",
    "bars = sns.barplot(\n",
    "    data=df_prs_merged[df_prs_merged[\"Autor\"].isin(autor_stats_sorted.index)],\n",
    "    x=\"Autor\",\n",
    "    y=\"Devoluciones\",\n",
    "    estimator=np.mean,\n",
    "    order=autor_stats_sorted.index,\n",
    "    palette=colors_clasificacion,\n",
    "    ax=ax1,\n",
    ")\n",
    "ax1.set_title(\n",
    "    \"üìä PROMEDIO DE DEVOLUCIONES POR DESARROLLADOR\\n(Verde=Excelente, Amarillo=Bueno, Naranja=Regular, Rojo=Necesita Atenci√≥n)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax1.set_xlabel(\"Desarrollador\")\n",
    "ax1.set_ylabel(\"Promedio de Devoluciones\")\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Agregar l√≠nea de promedio general\n",
    "promedio_general = df_prs_merged[\"Devoluciones\"].mean()\n",
    "ax1.axhline(\n",
    "    y=promedio_general,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=0.7,\n",
    "    label=f\"Promedio General: {promedio_general:.2f}\",\n",
    ")\n",
    "ax1.legend()\n",
    "\n",
    "# Agregar valores en las barras\n",
    "for i, (bar, autor) in enumerate(zip(bars.patches, autor_stats_sorted.index)):\n",
    "    valor = autor_stats_sorted.loc[autor, \"Dev_Promedio\"]\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.05,\n",
    "        f\"{valor:.1f}\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=9,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# 2. Box plot: Distribuci√≥n de devoluciones por autor (seaborn)\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "# Limitar a desarrolladores m√°s activos para mejor visualizaci√≥n\n",
    "top_devs_boxplot = (\n",
    "    autor_stats_filtered.sort_values(\"PRs_Total\", ascending=False).head(8).index\n",
    ")\n",
    "df_boxplot = df_prs_merged[df_prs_merged[\"Autor\"].isin(top_devs_boxplot)]\n",
    "\n",
    "sns.boxplot(data=df_boxplot, x=\"Autor\", y=\"Devoluciones\", ax=ax2)\n",
    "ax2.set_title(\n",
    "    \"üì¶ DISTRIBUCI√ìN DE DEVOLUCIONES POR DESARROLLADOR (Top 8 m√°s activos)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax2.set_xlabel(\"Desarrollador\")\n",
    "ax2.set_ylabel(\"N√∫mero de Devoluciones\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# 3. Gr√°fico de dispersi√≥n: PRs vs Promedio de devoluciones\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "scatter = ax3.scatter(\n",
    "    autor_stats_filtered[\"PRs_Total\"],\n",
    "    autor_stats_filtered[\"Dev_Promedio\"],\n",
    "    c=[\n",
    "        colors_clasificacion[list(autor_stats_sorted.index).index(autor)]\n",
    "        if autor in autor_stats_sorted.index\n",
    "        else \"gray\"\n",
    "        for autor in autor_stats_filtered.index\n",
    "    ],\n",
    "    s=100,\n",
    "    alpha=0.7,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "\n",
    "ax3.set_title(\n",
    "    \"üéØ Experiencia vs Calidad\\n(PRs Total vs Promedio Devoluciones)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax3.set_xlabel(\"Total de PRs\")\n",
    "ax3.set_ylabel(\"Promedio de Devoluciones\")\n",
    "\n",
    "# Agregar nombres de desarrolladores problem√°ticos\n",
    "for autor in necesitan_atencion.index:\n",
    "    if autor in autor_stats_filtered.index:\n",
    "        x = autor_stats_filtered.loc[autor, \"PRs_Total\"]\n",
    "        y = autor_stats_filtered.loc[autor, \"Dev_Promedio\"]\n",
    "        ax3.annotate(\n",
    "            autor[:10],\n",
    "            (x, y),\n",
    "            xytext=(5, 5),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=8,\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "# 4. Gr√°fico de barras: Tasa de √©xito por desarrollador\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "autor_stats_exito = autor_stats_filtered.sort_values(\"Tasa_Exito\", ascending=False)\n",
    "bars_exito = ax4.bar(\n",
    "    range(len(autor_stats_exito)),\n",
    "    autor_stats_exito[\"Tasa_Exito\"],\n",
    "    color=[\n",
    "        colors_clasificacion[list(autor_stats_sorted.index).index(autor)]\n",
    "        if autor in autor_stats_sorted.index\n",
    "        else \"gray\"\n",
    "        for autor in autor_stats_exito.index\n",
    "    ],\n",
    ")\n",
    "\n",
    "ax4.set_xticks(range(len(autor_stats_exito)))\n",
    "ax4.set_xticklabels(\n",
    "    [\n",
    "        autor[:10] + \"...\" if len(autor) > 10 else autor\n",
    "        for autor in autor_stats_exito.index\n",
    "    ],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "ax4.set_title(\n",
    "    \"üèÜ Tasa de √âxito por Desarrollador\\n(% PRs sin devoluciones)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=12,\n",
    ")\n",
    "ax4.set_ylabel(\"Tasa de √âxito (%)\")\n",
    "ax4.axhline(y=70, color=\"orange\", linestyle=\"--\", alpha=0.7, label=\"Meta: 70%\")\n",
    "ax4.legend()\n",
    "\n",
    "# 5. Heatmap de m√©tricas por desarrollador\n",
    "ax5 = fig.add_subplot(gs[3, :])\n",
    "# Seleccionar m√©tricas clave para el heatmap\n",
    "metrics_heatmap = autor_stats_filtered[\n",
    "    [\"Dev_Promedio\", \"Tasa_Exito\", \"Coef_Variacion\", \"PRs_Total\"]\n",
    "].copy()\n",
    "metrics_heatmap_norm = metrics_heatmap.copy()\n",
    "\n",
    "# Normalizar para el heatmap (invertir donde menor es mejor)\n",
    "metrics_heatmap_norm[\"Dev_Promedio\"] = 100 - (\n",
    "    metrics_heatmap[\"Dev_Promedio\"] / metrics_heatmap[\"Dev_Promedio\"].max() * 100\n",
    ")\n",
    "metrics_heatmap_norm[\"Coef_Variacion\"] = 100 - (\n",
    "    metrics_heatmap[\"Coef_Variacion\"] / metrics_heatmap[\"Coef_Variacion\"].max() * 100\n",
    ")\n",
    "metrics_heatmap_norm[\"PRs_Total\"] = (\n",
    "    metrics_heatmap[\"PRs_Total\"] / metrics_heatmap[\"PRs_Total\"].max() * 100\n",
    ")\n",
    "\n",
    "# Limitar a top 10 desarrolladores por PRs para mejor visualizaci√≥n\n",
    "top_10_devs = metrics_heatmap_norm.sort_values(\"PRs_Total\", ascending=False).head(10)\n",
    "\n",
    "im = ax5.imshow(top_10_devs.T.values, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=100)\n",
    "ax5.set_xticks(range(len(top_10_devs)))\n",
    "ax5.set_xticklabels(\n",
    "    [dev[:12] + \"...\" if len(dev) > 12 else dev for dev in top_10_devs.index],\n",
    "    rotation=45,\n",
    "    ha=\"right\",\n",
    ")\n",
    "ax5.set_yticks(range(len(top_10_devs.columns)))\n",
    "ax5.set_yticklabels(\n",
    "    [\"Calidad C√≥digo\", \"Tasa √âxito (%)\", \"Consistencia\", \"Experiencia (PRs)\"]\n",
    ")\n",
    "ax5.set_title(\n",
    "    \"üî• MAPA DE CALOR: M√âTRICAS DE DESARROLLADORES\\n(Verde=Excelente, Amarillo=Bueno, Rojo=Necesita Mejora)\",\n",
    "    fontweight=\"bold\",\n",
    "    fontsize=14,\n",
    ")\n",
    "\n",
    "# Agregar valores en el heatmap\n",
    "for i in range(len(top_10_devs.columns)):\n",
    "    for j in range(len(top_10_devs)):\n",
    "        value = top_10_devs.iloc[j, i]\n",
    "        ax5.text(\n",
    "            j,\n",
    "            i,\n",
    "            f\"{value:.0f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            fontsize=9,\n",
    "            color=\"white\" if value < 50 else \"black\",\n",
    "        )\n",
    "\n",
    "# Agregar colorbar\n",
    "cbar = plt.colorbar(im, ax=ax5, shrink=0.8)\n",
    "cbar.set_label(\"Puntuaci√≥n de Calidad (0-100)\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"üë• AN√ÅLISIS COMPLETO DE DEVOLUCIONES POR DESARROLLADOR\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    "    y=0.98,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualizaciones de an√°lisis por autor completadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aedee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Insights espec√≠ficos y planes de acci√≥n por desarrollador\n",
    "print(\"\\n\\nüí° INSIGHTS DETALLADOS Y PLANES DE ACCI√ìN:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# An√°lisis de patrones por categor√≠a\n",
    "print(f\"üìä RESUMEN POR CATEGOR√çAS:\")\n",
    "print(\n",
    "    f\"   üü¢ Desarrolladores EXCELENTES: {len(excelentes)} ({len(excelentes) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   üü° Desarrolladores BUENOS: {len(buenos)} ({len(buenos) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   üü† Desarrolladores REGULARES: {len(regulares)} ({len(regulares) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   üî¥ Desarrolladores que NECESITAN ATENCI√ìN: {len(necesitan_atencion)} ({len(necesitan_atencion) / len(autor_stats_filtered) * 100:.1f}%)\"\n",
    ")\n",
    "\n",
    "# An√°lisis de problem√°ticas espec√≠ficas\n",
    "print(f\"\\nüîç AN√ÅLISIS DE PROBLEM√ÅTICAS ESPEC√çFICAS:\")\n",
    "\n",
    "# Desarrolladores con alta variabilidad\n",
    "alta_variabilidad = autor_stats_filtered[autor_stats_filtered[\"Coef_Variacion\"] > 100]\n",
    "if len(alta_variabilidad) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  DESARROLLADORES CON ALTA VARIABILIDAD ({len(alta_variabilidad)}):\")\n",
    "    print(\"   ‚Üí Posible falta de comprensi√≥n consistente de requisitos\")\n",
    "    for dev in alta_variabilidad.index:\n",
    "        cv = alta_variabilidad.loc[dev, \"Coef_Variacion\"]\n",
    "        prom = alta_variabilidad.loc[dev, \"Dev_Promedio\"]\n",
    "        print(f\"   ‚Ä¢ {dev}: CV={cv:.0f}%, Promedio={prom:.1f}\")\n",
    "\n",
    "# Desarrolladores con muchos PRs pero alta tasa de devoluciones\n",
    "experimentados_problematicos = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"PRs_Total\"] >= 5)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] > 2)\n",
    "]\n",
    "if len(experimentados_problematicos) > 0:\n",
    "    print(\n",
    "        f\"\\n‚ö†Ô∏è  DESARROLLADORES EXPERIMENTADOS CON PROBLEMAS DE CALIDAD ({len(experimentados_problematicos)}):\"\n",
    "    )\n",
    "    print(\n",
    "        \"   ‚Üí Posibles malos h√°bitos establecidos o falta de actualizaci√≥n en est√°ndares\"\n",
    "    )\n",
    "    for dev in experimentados_problematicos.index:\n",
    "        prs = experimentados_problematicos.loc[dev, \"PRs_Total\"]\n",
    "        prom = experimentados_problematicos.loc[dev, \"Dev_Promedio\"]\n",
    "        tasa = experimentados_problematicos.loc[dev, \"Tasa_Exito\"]\n",
    "        print(f\"   ‚Ä¢ {dev}: {int(prs)} PRs, {prom:.1f} prom dev, {tasa:.0f}% √©xito\")\n",
    "\n",
    "# Desarrolladores nuevos con potencial\n",
    "nuevos_prometedores = autor_stats_filtered[\n",
    "    (autor_stats_filtered[\"PRs_Total\"] <= 5)\n",
    "    & (autor_stats_filtered[\"Dev_Promedio\"] <= 1.5)\n",
    "]\n",
    "if len(nuevos_prometedores) > 0:\n",
    "    print(f\"\\nüåü DESARROLLADORES NUEVOS CON POTENCIAL ({len(nuevos_prometedores)}):\")\n",
    "    print(\"   ‚Üí Mantener buenas pr√°cticas y mentoring\")\n",
    "    for dev in nuevos_prometedores.index:\n",
    "        prs = nuevos_prometedores.loc[dev, \"PRs_Total\"]\n",
    "        prom = nuevos_prometedores.loc[dev, \"Dev_Promedio\"]\n",
    "        print(f\"   ‚Ä¢ {dev}: {int(prs)} PRs, {prom:.1f} prom dev\")\n",
    "\n",
    "# Generar planes de acci√≥n espec√≠ficos\n",
    "print(f\"\\nüéØ PLANES DE ACCI√ìN ESPEC√çFICOS:\")\n",
    "\n",
    "# Para desarrolladores que necesitan atenci√≥n\n",
    "if len(necesitan_atencion) > 0:\n",
    "    print(f\"\\nüî¥ PLAN PARA DESARROLLADORES QUE NECESITAN ATENCI√ìN:\")\n",
    "    for dev in necesitan_atencion.index:\n",
    "        data = necesitan_atencion.loc[dev]\n",
    "        print(f\"\\n   üë§ {dev}:\")\n",
    "        print(\n",
    "            f\"      üìä M√©tricas: {data['Tasa_Exito']:.0f}% √©xito, {data['Dev_Promedio']:.1f} prom dev\"\n",
    "        )\n",
    "\n",
    "        # Diagn√≥stico espec√≠fico\n",
    "        if data[\"Dev_Promedio\"] > 3:\n",
    "            print(f\"      üîç Diagn√≥stico: Promedio muy alto de devoluciones\")\n",
    "            print(f\"      üí° Recomendaciones:\")\n",
    "            print(f\"         - Revisi√≥n exhaustiva de est√°ndares de c√≥digo\")\n",
    "            print(f\"         - Mentoring 1:1 con desarrollador senior\")\n",
    "            print(f\"         - Implementar checklist personal antes de PR\")\n",
    "\n",
    "        if data[\"Tasa_Exito\"] < 30:\n",
    "            print(f\"      üîç Diagn√≥stico: Muy baja tasa de √©xito al primer intento\")\n",
    "            print(f\"      üí° Recomendaciones:\")\n",
    "            print(f\"         - Capacitaci√≥n espec√≠fica en testing\")\n",
    "            print(f\"         - Revisi√≥n de comprensi√≥n de requisitos\")\n",
    "            print(f\"         - Pair programming con desarrolladores excelentes\")\n",
    "\n",
    "        if data[\"Coef_Variacion\"] > 150:\n",
    "            print(f\"      üîç Diagn√≥stico: Alta inconsistencia en calidad\")\n",
    "            print(f\"      üí° Recomendaciones:\")\n",
    "            print(f\"         - Estandarizar proceso personal de desarrollo\")\n",
    "            print(f\"         - Capacitaci√≥n en metodolog√≠as de calidad\")\n",
    "\n",
    "# Para desarrolladores excelentes\n",
    "if len(excelentes) > 0:\n",
    "    print(f\"\\nüü¢ PLAN PARA DESARROLLADORES EXCELENTES:\")\n",
    "    print(f\"   üéØ Acciones:\")\n",
    "    print(f\"      - Asignar como mentores de desarrolladores que necesitan atenci√≥n\")\n",
    "    print(f\"      - Documentar sus mejores pr√°cticas\")\n",
    "    print(f\"      - Considerar para roles de liderazgo t√©cnico\")\n",
    "    print(f\"      - Asignar PRs m√°s complejos o cr√≠ticos\")\n",
    "\n",
    "# M√©tricas de seguimiento recomendadas\n",
    "print(f\"\\nüìà M√âTRICAS DE SEGUIMIENTO RECOMENDADAS:\")\n",
    "print(f\"   üìä Semanales:\")\n",
    "print(f\"      ‚Ä¢ Tasa de √©xito por desarrollador\")\n",
    "print(f\"      ‚Ä¢ Promedio de devoluciones en PRs nuevos\")\n",
    "print(f\"   üìä Mensuales:\")\n",
    "print(f\"      ‚Ä¢ Evoluci√≥n de coeficiente de variaci√≥n\")\n",
    "print(f\"      ‚Ä¢ Comparaci√≥n con benchmarks del equipo\")\n",
    "print(f\"   üìä Trimestrales:\")\n",
    "print(f\"      ‚Ä¢ Reclasificaci√≥n de desarrolladores\")\n",
    "print(f\"      ‚Ä¢ Evaluaci√≥n de efectividad de planes de mejora\")\n",
    "\n",
    "# Impacto en el equipo\n",
    "promedio_team = autor_stats_filtered[\"Dev_Promedio\"].mean()\n",
    "desarrolladores_sobre_promedio = len(\n",
    "    autor_stats_filtered[autor_stats_filtered[\"Dev_Promedio\"] > promedio_team]\n",
    ")\n",
    "impacto_mejora = desarrolladores_sobre_promedio / len(autor_stats_filtered) * 100\n",
    "\n",
    "print(f\"\\nüí∞ IMPACTO POTENCIAL:\")\n",
    "print(\n",
    "    f\"   ‚Ä¢ {desarrolladores_sobre_promedio} desarrolladores est√°n sobre el promedio del equipo\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Mejorando estos desarrolladores se podr√≠a reducir {impacto_mejora:.1f}% las devoluciones\"\n",
    ")\n",
    "print(\n",
    "    f\"   ‚Ä¢ Tiempo estimado ahorrado: ~{impacto_mejora * 0.5:.1f} horas/semana en re-trabajo\"\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lisis de Devoluciones por Autor COMPLETADO!\")\n",
    "print(\"=\" * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
